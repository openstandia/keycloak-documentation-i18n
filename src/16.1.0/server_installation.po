msgid ""
msgstr ""
"Content-Type: text/plain; charset=UTF-8\n"

msgid "{installguide_name}"
msgstr ""

msgid "*{release_header_guide}* icon:angle-down[]"
msgstr ""

msgid "{gettingstarted_link}[{gettingstarted_name_short}]"
msgstr ""

msgid "{adapterguide_link}[{adapterguide_name_short}]"
msgstr ""

msgid "{adminguide_link}[{adminguide_name_short}]"
msgstr ""

msgid "{developerguide_link}[{developerguide_name_short}]"
msgstr ""

msgid "{authorizationguide_link}[{authorizationguide_name_short}]"
msgstr ""

msgid "{upgradingguide_link}[{upgradingguide_name_short}]"
msgstr ""

msgid "{releasenotes_link}[{releasenotes_name_short}]"
msgstr ""

msgid "Version *{project_version}* _{release_header_latest_link}[Click here for latest]_"
msgstr ""

msgid "Guide Overview"
msgstr ""

msgid "The purpose of this guide is to walk through the steps that need to be completed prior to booting up the {project_name} server for the first time.  If you just want to test drive {project_name}, it pretty much runs out of the box with its own embedded and local-only database.  For  actual deployments that are going to be run in production you'll need to decide how you want to manage server configuration  at runtime (standalone or domain mode), configure a shared database for {project_name} storage, set up encryption and HTTPS,  and finally set up {project_name} to run in a cluster.  This guide walks through each and every aspect of any pre-boot  decisions and setup you must do prior to deploying the server."
msgstr ""

msgid "One thing to particularly note is that {project_name} is derived from the {appserver_name} Application Server. Many aspects of configuring {project_name} revolve around {appserver_name} configuration elements.  Often this guide will direct you to documentation outside of the manual if you want to dive into more detail."
msgstr ""

msgid "Recommended additional external documentation"
msgstr ""

msgid "{project_name} is built on top of the {appserver_name} application server and its sub-projects like Infinispan (for caching) and Hibernate (for persistence). This guide only covers basics for infrastructure-level configuration.  It is highly recommended that you peruse the documentation for {appserver_name} and its sub projects. Here is the link to the documentation:"
msgstr ""

msgid "link:{appserver_admindoc_link}[_{appserver_admindoc_name}_]"
msgstr ""

msgid "Installing the software"
msgstr ""

msgid "Installing {project_name} is as simple as downloading it and unzipping it. This chapter reviews system requirements as well as the directory structure of the distribution."
msgstr ""

msgid "Installation prerequisites"
msgstr ""

msgid "These prerequisites exist for installing the {project_name} server:"
msgstr ""

msgid "Can run on any operating system that runs Java"
msgstr ""

msgid "Java 8 JRE or Java 11 JRE"
msgstr ""

msgid "zip or gzip and tar"
msgstr ""

msgid "At least 512M of RAM"
msgstr ""

msgid "At least 1G of diskspace"
msgstr ""

msgid "A shared external database like PostgreSQL, MySQL, Oracle, etc.  {project_name} requires an external shared database if you want to run in a cluster.   Please see the <<_database,database configuration>> section of this guide for more information."
msgstr ""

msgid "Network multicast support on your machine if you want to run in a cluster.  {project_name} can be clustered without multicast, but this requires a bunch of configuration changes.  Please see the <<_clustering,clustering>> section of this guide for more information."
msgstr ""

msgid "On Linux, it is recommended to use `/dev/urandom` as a source of random data to prevent {project_name} hanging due to lack of available entropy, unless `/dev/random` usage is mandated by your security policy. To achieve that on Oracle JDK 8 and OpenJDK 8, set the `java.security.egd` system property on startup to `file:/dev/urandom`."
msgstr ""

msgid "Installing the Keycloak server"
msgstr ""

msgid "The Keycloak Server has two downloadable distributions:"
msgstr ""

msgid "`keycloak-{project_version}.[zip|tar.gz]`"
msgstr ""

msgid "This file is the server only distribution.  It contains nothing other than the scripts and binaries to run the Keycloak Server."
msgstr ""

msgid "`keycloak-overlay-{project_version}.[zip|tar.gz]`"
msgstr ""

msgid "This file is a WildFly add-on that you can use to install the Keycloak Server on top of an existing WildFly distribution.  We do not support users who want to run their applications and Keycloak on the same server instance."
msgstr ""

msgid "Procedure"
msgstr ""

msgid "To install the Keycloak server, run your operating system's `unzip` or `gunzip` and `tar` utilities on the `keycloak-{project_version}.[zip|tar.gz]` file."
msgstr ""

msgid "To install the Keycloak Service Pack, it must be installed on a different server instance."
msgstr ""

msgid "Change to the root directory of your WildFly distribution."
msgstr ""

msgid "Unzip the `keycloak-overlay-{project_version}.[zip|tar.gz]` file."
msgstr ""

msgid "Open the bin directory in a shell."
msgstr ""

msgid "Run `./jboss-cli.[sh|bat] --file=keycloak-install.cli`."
msgstr ""

msgid "Important directories"
msgstr ""

msgid "The following are some important directories in the server distribution."
msgstr ""

msgid "_bin/_"
msgstr ""

msgid "This contains various scripts to either boot the server or perform some other management action on the server."
msgstr ""

msgid "_domain/_"
msgstr ""

msgid "This contains configuration files and working directory when running {project_name} in <<_domain-mode,domain mode>>."
msgstr ""

msgid "_modules/_"
msgstr ""

msgid "These are all the Java libraries used by the server."
msgstr ""

msgid "_standalone/_"
msgstr ""

msgid "This contains configuration files and working directory when running {project_name} in <<_standalone-mode,standalone mode>>."
msgstr ""

msgid "_standalone/deployments/_"
msgstr ""

msgid "If you are writing extensions to {project_name}, you can put your extensions here.  See the link:{developerguide_link}[{developerguide_name}] for more information on this."
msgstr ""

msgid "_themes/_"
msgstr ""

msgid "This directory contains all the html, style sheets, JavaScript files, and images used to display any UI screen displayed by the server. Here you can modify an existing theme or create your own.  See the link:{developerguide_link}[{developerguide_name}] for more information on this."
msgstr ""

msgid "Using operating modes"
msgstr ""

msgid "Before deploying {project_name} in a production environment you need to decide which type of operating mode you are going to use."
msgstr ""

msgid "Will you run {project_name} within a cluster?"
msgstr ""

msgid "Do you want a centralized way to manage your server configurations?"
msgstr ""

msgid "Your choice of operating mode affects how you configure databases, configure caching and even how you boot the server."
msgstr ""

msgid "The {project_name} is built on top of the {appserver_name} Application Server.  This guide will only      go over the basics for deployment within a specific mode.  If you want specific information on this, a better place      to go would be the link:{appserver_admindoc_link}[_{appserver_admindoc_name}_]."
msgstr ""

msgid "Using standalone mode"
msgstr ""

msgid "Standalone operating mode is only useful when you want to run one, and only one {project_name} server instance. It is not usable for clustered deployments and all caches are non-distributed and local-only.  It is not recommended that you use standalone mode in production as you will have a single point of failure.  If your standalone mode server goes down, users will not be able to log in.  This mode is really only useful to test drive and play with the features of {project_name}"
msgstr ""

msgid "Booting in standalone mode"
msgstr ""

msgid "When running the server in standalone mode, there is a specific script you need to boot the server depending on your operating system.  These scripts live in the _bin/_ directory of the server distribution."
msgstr ""

msgid "Standalone Boot Scripts"
msgstr ""

msgid "image:{project_images}/standalone-boot-files.png[]"
msgstr ""

msgid "To boot the server:"
msgstr ""

msgid "Linux/Unix"
msgstr ""

msgid "$ .../bin/standalone.sh"
msgstr ""

msgid "Windows"
msgstr ""

msgid "> ...\\bin\\standalone.bat"
msgstr ""

msgid "Standalone configuration"
msgstr ""

msgid "The bulk of this guide walks you through how to configure infrastructure level aspects of {project_name}.  These aspects are configured in a configuration file that is specific to the application server that {project_name} is a derivative of.  In the standalone operation mode, this file lives in _.../standalone/configuration/standalone.xml_.  This file is also used to configure non-infrastructure level things that are specific to {project_name} components."
msgstr ""

msgid "Standalone Config File"
msgstr ""

msgid "image:{project_images}/standalone-config-file.png[]"
msgstr ""

msgid "Any changes you make to this file while the server is running will not take effect and may even be overwritten       by the server.  Instead use the command line scripting or the web console of {appserver_name}.  See       the link:{appserver_admindoc_link}[_{appserver_admindoc_name}_] for more information."
msgstr ""

msgid "Using standalone clustered mode"
msgstr ""

msgid "Standalone clustered operation mode applies when you want to run {project_name} within a cluster.  This mode requires that you have a copy of the {project_name} distribution on each machine where you want to run a server instance. This mode can be very easy to deploy initially, but can become quite cumbersome. To make a configuration change, you modify each distribution on each machine.  For a large cluster, this mode can become time consuming and error prone."
msgstr ""

msgid "Standalone clustered configuration"
msgstr ""

msgid "The distribution has a mostly pre-configured app server configuration file for running within a cluster.  It has all the specific infrastructure settings for networking, databases, caches, and discovery.  This file resides in _.../standalone/configuration/standalone-ha.xml_.  There's a few things missing from this configuration. You can't run {project_name} in a cluster without configuring a shared database connection.  You also need to deploy some type of load balancer in front of the cluster.  The <<_clustering,clustering>> and <<_database,database>> sections of this guide walk you through these things."
msgstr ""

msgid "Standalone HA Config"
msgstr ""

msgid "image:{project_images}/standalone-ha-config-file.png[]"
msgstr ""

msgid "Booting in standalone clustered mode"
msgstr ""

msgid "You use the same boot scripts to start {project_name} as you do in standalone mode.  The difference is that you pass in an additional flag to point to the HA config file."
msgstr ""

msgid "Standalone Clustered Boot Scripts"
msgstr ""

msgid "$ .../bin/standalone.sh --server-config=standalone-ha.xml"
msgstr ""

msgid "> ...\\bin\\standalone.bat --server-config=standalone-ha.xml"
msgstr ""

msgid "Using domain clustered mode"
msgstr ""

msgid "Domain mode is a way to centrally manage and publish the configuration for your servers."
msgstr ""

msgid "Running a cluster in standard mode can quickly become aggravating as the cluster grows in size.  Every time you need to make a configuration change, you  perform it on each node in the cluster.  Domain mode solves this problem by providing a central place to store and publish configurations.  It can be quite complex to set up, but it is worth it in the end. This capability is built into the {appserver_name} Application Server which {project_name} derives from."
msgstr ""

msgid "The guide will go over the very basics of domain mode.  Detailed steps on how to set up domain mode in a cluster should be obtained from the        link:{appserver_admindoc_link}[_{appserver_admindoc_name}_]."
msgstr ""

msgid "Here are some of the basic concepts of running in domain mode."
msgstr ""

msgid "domain controller"
msgstr ""

msgid "The domain controller is a process that is responsible for storing, managing, and publishing the general configuration for each node in the cluster.  This process is the central point from which nodes in a cluster obtain their configuration."
msgstr ""

msgid "host controller"
msgstr ""

msgid "The host controller is responsible for managing server instances on a specific machine.  You configure it to run one or more server instances.  The domain controller can also interact with the host controllers on each machine to manage the cluster.  To reduce the number of running process, a domain controller also acts as a host controller on the machine it runs on."
msgstr ""

msgid "domain profile"
msgstr ""

msgid "A domain profile is a named set of configuration that can be used by a server to boot from.  A domain controller can define multiple domain profiles that are consumed by different servers."
msgstr ""

msgid "server group"
msgstr ""

msgid "A server group is a collection of servers.  They are managed and configured as one.  You can assign a domain profile to a server group and every service in that group will use that domain profile as their configuration."
msgstr ""

msgid "In domain mode, a domain controller is started on a master node.  The configuration for the cluster resides in the domain controller. Next a host controller is started on each machine in the cluster.  Each host controller deployment configuration specifies how many {project_name} server instances will be started on that machine.  When the host controller boots up, it starts as many {project_name} server instances as it was configured to do.  These server instances pull their configuration from the domain controller."
msgstr ""

msgid "In some environments, such as Microsoft Azure, the domain mode is not applicable. Please consult the {appserver_name} documentation."
msgstr ""

msgid "Domain configuration"
msgstr ""

msgid "Various other chapters in this guide walk you through configuring various aspects like databases, HTTP network connections, caches, and other infrastructure related things.  While standalone mode uses the _standalone.xml_ file to configure these things, domain mode uses the _.../domain/configuration/domain.xml_ configuration file.  This is where the domain profile and server group for the {project_name} server are defined."
msgstr ""

msgid "domain.xml"
msgstr ""

msgid "image:{project_images}/domain-file.png[]"
msgstr ""

msgid "Any changes you make to this file while the domain controller is running will not take effect and may even be overwritten       by the server.  Instead use the command line scripting or the web console of {appserver_name}.  See       the link:{appserver_admindoc_link}[_{appserver_admindoc_name}_] for more information."
msgstr ""

msgid "Let's look at some aspects of this _domain.xml_ file.  The `auth-server-standalone` and `auth-server-clustered` `profile` XML blocks are where you are going to make the bulk of your configuration decisions. You'll be configuring things here like network connections, caches, and database connections."
msgstr ""

msgid "auth-server profile"
msgstr ""

msgid ""
"    <profiles>\n"
"        <profile name=\"auth-server-standalone\">\n"
"            ...\n"
"        </profile>\n"
"        <profile name=\"auth-server-clustered\">\n"
"            ...\n"
"        </profile>"
msgstr ""

msgid "The `auth-server-standalone` profile is a non-clustered setup.  The `auth-server-clustered` profile is the clustered setup."
msgstr ""

msgid "If you scroll down further, you'll see various `socket-binding-groups` defined."
msgstr ""

msgid "socket-binding-groups"
msgstr ""

msgid ""
"    <socket-binding-groups>\n"
"        <socket-binding-group name=\"standard-sockets\" default-interface=\"public\">\n"
"           ...\n"
"        </socket-binding-group>\n"
"        <socket-binding-group name=\"ha-sockets\" default-interface=\"public\">\n"
"           ...\n"
"        </socket-binding-group>\n"
"        <!-- load-balancer-sockets should be removed in production systems and replaced with a better software or hardware based one -->\n"
"        <socket-binding-group name=\"load-balancer-sockets\" default-interface=\"public\">\n"
"           ...\n"
"        </socket-binding-group>\n"
"    </socket-binding-groups>"
msgstr ""

msgid "This configration defines the default port mappings for various connectors that are opened with each {project_name} server instance.  Any value that contains `${...}` is a value that can be overridden on the command line with the `-D` switch, i.e."
msgstr ""

msgid "$ domain.sh -Djboss.http.port=80"
msgstr ""

msgid "The definition of the server group for {project_name} resides in the `server-groups` XML block.  It specifies the domain profile that is used (`default`) and also some default boot arguments for the Java VM when the host controller boots an instance.  It also binds a `socket-binding-group` to the server group."
msgstr ""

msgid ""
"    <server-groups>\n"
"        <!-- load-balancer-group should be removed in production systems and replaced with a better software or hardware based one -->\n"
"        <server-group name=\"load-balancer-group\" profile=\"load-balancer\">\n"
"            <jvm name=\"default\">\n"
"                <heap size=\"64m\" max-size=\"512m\"/>\n"
"            </jvm>\n"
"            <socket-binding-group ref=\"load-balancer-sockets\"/>\n"
"        </server-group>\n"
"        <server-group name=\"auth-server-group\" profile=\"auth-server-clustered\">\n"
"            <jvm name=\"default\">\n"
"                <heap size=\"64m\" max-size=\"512m\"/>\n"
"            </jvm>\n"
"            <socket-binding-group ref=\"ha-sockets\"/>\n"
"        </server-group>\n"
"    </server-groups>"
msgstr ""

msgid "Host controller configuration"
msgstr ""

msgid "{project_name} comes with two host controller configuration files that reside in the _.../domain/configuration/_ directory: _host-master.xml_ and _host-slave.xml_.  _host-master.xml_ is configured to boot up a domain controller, a load balancer, and one {project_name} server instance.  _host-slave.xml_ is configured to talk to the domain controller and boot up one {project_name} server instance."
msgstr ""

msgid "The load balancer is not a required service.  It exists so that you can easily test drive clustering on your development        machine.  While usable in production, you have the option of replacing it if you have a different hardware or software        based load balancer you want to use."
msgstr ""

msgid "Host Controller Config"
msgstr ""

msgid "image:{project_images}/host-files.png[]"
msgstr ""

msgid "To disable the load balancer server instance, edit _host-master.xml_ and comment out or remove the `\"load-balancer\"` entry."
msgstr ""

msgid ""
"    <servers>\n"
"        <!-- remove or comment out next line -->\n"
"        <server name=\"load-balancer\" group=\"loadbalancer-group\"/>\n"
"        ...\n"
"    </servers>"
msgstr ""

msgid "Another interesting thing to note about this file is the declaration of the authentication server instance.  It has a `port-offset` setting.  Any network port defined in the _domain.xml_ `socket-binding-group` or the server group will have the value of `port-offset` added to it.  For this sample domain setup, we do this so that ports opened by the load balancer server don't conflict with the authentication server instance that is started."
msgstr ""

msgid ""
"    <servers>\n"
"        ...\n"
"        <server name=\"server-one\" group=\"auth-server-group\" auto-start=\"true\">\n"
"             <socket-bindings port-offset=\"150\"/>\n"
"        </server>\n"
"    </servers>"
msgstr ""

msgid "Server instance working directories"
msgstr ""

msgid "Each {project_name} server instance defined in your host files creates a working directory under _.../domain/servers/{SERVER NAME}_. Additional configuration can be put there, and any temporary, log, or data files the server instance needs or creates go there too. The structure of these per server directories ends up looking like any other {appserver_name} booted server."
msgstr ""

msgid "Working Directories"
msgstr ""

msgid "image:{project_images}/domain-server-dir.png[]"
msgstr ""

msgid "Booting in domain clustered mode"
msgstr ""

msgid "When running the server in domain mode, there is a specific script you need to run to boot the server depending on your operating system.  These scripts live in the _bin/_ directory of the server distribution."
msgstr ""

msgid "Domain Boot Script"
msgstr ""

msgid "image:{project_images}/domain-boot-files.png[]"
msgstr ""

msgid "$ .../bin/domain.sh --host-config=host-master.xml"
msgstr ""

msgid "> ...\\bin\\domain.bat --host-config=host-master.xml"
msgstr ""

msgid "When running the boot script you will need to pass in the host controlling configuration file you are going to use via the `--host-config` switch."
msgstr ""

msgid "Testing with a sample clustered domain"
msgstr ""

msgid "You can test drive clustering using the sample _domain.xml_ configuration.  This sample domain is meant to run on one machine and boots up:"
msgstr ""

msgid "a domain controller"
msgstr ""

msgid "an HTTP load balancer"
msgstr ""

msgid "two {project_name} server instances"
msgstr ""

msgid "Run the `domain.sh` script twice to start two separate host controllers."
msgstr ""

msgid "The first one is the master host controller that starts a domain controller, an HTTP load balancer, and one {project_name} authentication server instance.  The second one is a slave host controller that starts up only an authentication server instance."
msgstr ""

msgid "Configure the slave host controller so that it can talk securely to the domain controller. Perform these steps:"
msgstr ""

msgid "If you omit these steps, the slave host cannot obtain the centralized configuration from the domain controller."
msgstr ""

msgid "Set up a secure connection by creating a server admin user and a secret that are shared between the master and the slave."
msgstr ""

msgid "Run the `.../bin/add-user.sh` script."
msgstr ""

msgid "Select `Management User` when the script asks about the type of user to  add."
msgstr ""

msgid "This choice generates a secret that you cut and paste into the _.../domain/configuration/host-slave.xml_ file."
msgstr ""

msgid "Add App Server Admin"
msgstr ""

msgid ""
"$ add-user.sh\n"
" What type of user do you wish to add?\n"
"  a) Management User (mgmt-users.properties)\n"
"  b) Application User (application-users.properties)\n"
" (a): a\n"
" Enter the details of the new user to add.\n"
" Using realm 'ManagementRealm' as discovered from the existing property files.\n"
" Username : admin\n"
" Password recommendations are listed below. To modify these restrictions edit the add-user.properties configuration file.\n"
"  - The password should not be one of the following restricted values {root, admin, administrator}\n"
"  - The password should contain at least 8 characters, 1 alphabetic character(s), 1 digit(s), 1 non-alphanumeric symbol(s)\n"
"  - The password should be different from the username\n"
" Password :\n"
" Re-enter Password :\n"
" What groups do you want this user to belong to? (Please enter a comma separated list, or leave blank for none)[ ]:\n"
" About to add user 'admin' for realm 'ManagementRealm'\n"
" Is this correct yes/no? yes\n"
" Added user 'admin' to file '/.../standalone/configuration/mgmt-users.properties'\n"
" Added user 'admin' to file '/.../domain/configuration/mgmt-users.properties'\n"
" Added user 'admin' with groups to file '/.../standalone/configuration/mgmt-groups.properties'\n"
" Added user 'admin' with groups to file '/.../domain/configuration/mgmt-groups.properties'\n"
" Is this new user going to be used for one AS process to connect to another AS process?\n"
" e.g. for a slave host controller connecting to the master or for a Remoting connection for server to server EJB calls.\n"
" yes/no? yes\n"
" To represent the user add the following to the server-identities definition <secret value=\"bWdtdDEyMyE=\" />"
msgstr ""

msgid "The add-user.sh script does not add the user to the {project_name} server but to the underlying JBoss Enterprise Application Platform. The credentials used and generated in this script are only for demonstration purposes. Please use the ones generated on your system."
msgstr ""

msgid "Cut and paste the secret value into the _.../domain/configuration/host-slave.xml_ file as follows:"
msgstr ""

msgid ""
"     <management>\n"
"         <security-realms>\n"
"             <security-realm name=\"ManagementRealm\">\n"
"                 <server-identities>\n"
"                     <secret value=\"bWdtdDEyMyE=\"/>\n"
"                 </server-identities>"
msgstr ""

msgid "Add the _username_ of the created user in the _.../domain/configuration/host-slave.xml_ file:"
msgstr ""

msgid "     <remote security-realm=\"ManagementRealm\" username=\"admin\">"
msgstr ""

msgid "Run the boot script twice to simulate a two node cluster on one development machine."
msgstr ""

msgid "Boot up master"
msgstr ""

msgid "$ domain.sh --host-config=host-master.xml"
msgstr ""

msgid "Boot up slave"
msgstr ""

msgid "$ domain.sh --host-config=host-slave.xml"
msgstr ""

msgid "Open your browser and go to http://localhost:8080/auth to try it out."
msgstr ""

msgid "Using cross-site replication mode"
msgstr ""

msgid "{tech_feature_name} is *Technology Preview* and is not fully supported."
msgstr ""

msgid "Use cross-site replication mode to run {project_name} in a cluster across multiple data centers. Typically you use data center sites that are in different geographic regions. When using this mode, each data center will have its own cluster of {project_name} servers."
msgstr ""

msgid "This documentation will refer to the following example architecture diagram to illustrate and describe a simple cross-site replication use case."
msgstr ""

msgid "Example Architecture Diagram"
msgstr ""

msgid "image:{project_images}/cross-dc-architecture.png[]"
msgstr ""

msgid "Prerequisites"
msgstr ""

msgid "As this is an advanced topic, we recommend you first read the following, which provide valuable background knowledge:"
msgstr ""

msgid "link:{installguide_clustering_link}[Clustering with {project_name}] When setting up for cross-site replication, you will use more independent {project_name} clusters, so you must understand how a cluster works and the basic concepts and requirements such as load balancing, shared databases, and multicasting."
msgstr ""

msgid "link:https://infinispan.org/docs/11.0.x/titles/xsite/xsite.html#xsite_replication[Infinispan Cross-Site Replication] replicates data across clusters in separate geographic locations."
msgstr ""

msgid "Technical details"
msgstr ""

msgid "This section provides an introduction to the concepts and details of how {project_name} cross-site replication is accomplished."
msgstr ""

msgid "Data"
msgstr ""

msgid "{project_name} is stateful application. It uses the following as data sources:"
msgstr ""

msgid "A database is used to persist permanent data, such as user information."
msgstr ""

msgid "An Infinispan cache is used to cache persistent data from the database and also to save some short-lived and frequently-changing metadata, such as for user sessions. Infinispan is usually much faster than a database, however the data saved using Infinispan are not permanent and is not expected to persist across cluster restarts."
msgstr ""

msgid "In our example architecture, there are two data centers called `site1` and `site2`. For cross-site replication, we must make sure that both sources of data work reliably and that {project_name} servers from `site1` are eventually able to read the data saved by {project_name} servers on `site2` ."
msgstr ""

msgid "Based on the environment, you have the option to decide if you prefer:"
msgstr ""

msgid "Reliability - which is typically used in Active/Active mode. Data written on `site1` must be visible immediately on `site2`."
msgstr ""

msgid "Performance - which is typically used in Active/Passive mode. Data written on `site1` does not need to be visible immediately on `site2`. In some cases, the data may not be visible on `site2` at all."
msgstr ""

msgid "For more details, see <<Modes>>."
msgstr ""

msgid "Request processing"
msgstr ""

msgid "An end user's browser sends an HTTP request to the link:{installguide_loadbalancer_link}[front end load balancer]. This load balancer is usually HTTPD or WildFly with mod_cluster, NGINX, HA Proxy, or perhaps some other kind of software or hardware load balancer."
msgstr ""

msgid "The load balancer then forwards the HTTP requests it receives to the underlying {project_name} instances, which can be spread among multiple data centers. Load balancers typically offer support for link:{installguide_stickysessions_link}[sticky sessions], which means that the load balancer is able to always forward all HTTP requests from the same user to the same {project_name} instance in same data center."
msgstr ""

msgid "HTTP requests that are sent from client applications to the load balancer are called `backchannel requests`. These are not seen by an end user's browser and therefore can not be part of a sticky session between the user and the load balancer. For backchannel requests, the loadbalancer can forward the HTTP request to any {project_name} instance in any data center. This is challenging as some OpenID Connect and some SAML flows require multiple HTTP requests from both the user and the application. Because we can not reliably depend on sticky sessions to force all the related requests to be sent to the same {project_name} instance in the same data center, we must instead replicate some data across data centers, so the data are seen by subsequent HTTP requests during a particular flow."
msgstr ""

msgid "Modes"
msgstr ""

msgid "According your requirements, there are two basic operating modes for cross-site replication:"
msgstr ""

msgid "Active/Passive - Here the users and client applications send the requests just to the {project_name} nodes in just a single data center. The second data center is used just as a `backup` for saving the data. In case of the failure in the main data center, the data can be usually restored from the second data center."
msgstr ""

msgid "Active/Active - Here the users and client applications send the requests to the {project_name} nodes in both data centers. It means that data need to be visible immediately on both sites and available to be consumed immediately from {project_name} servers on both sites. This is especially true if {project_name} server writes some data on `site1`, and it is required that the data are available immediately for reading by {project_name} servers on `site2` immediately after the write on `site1` is finished."
msgstr ""

msgid "The active/passive mode is better for performance. For more information about how to configure caches for either mode, see: <<backups>>."
msgstr ""

msgid "Database"
msgstr ""

msgid "{project_name} uses a relational database management system (RDBMS) to persist some metadata about realms, clients, users, and so on. See link:{installguide_database_link}[this chapter] of the server installation guide for more details. In a cross-site replication setup, we assume that either both data centers talk to the same database or that every data center has its own database node and both database nodes are synchronously replicated across the data centers. In both cases, it is required that when a {project_name} server on `site1` persists some data and commits the transaction, those data are immediately visible by subsequent DB transactions on `site2`."
msgstr ""

msgid "Details of DB setup are out-of-scope for {project_name}, however many RDBMS vendors like MariaDB and Oracle offer replicated databases and synchronous replication. We test {project_name} with these vendors:"
msgstr ""

msgid "Oracle Database 19c RAC"
msgstr ""

msgid "Galera 3.12 cluster for MariaDB server version 10.1.19-MariaDB"
msgstr ""

msgid "Infinispan caches"
msgstr ""

msgid "This section begins with a high level description of the Infinispan caches. More details of the cache setup follow."
msgstr ""

msgid "Authentication sessions"
msgstr ""

msgid "In {project_name} we have the concept of authentication sessions. There is a separate Infinispan cache called `authenticationSessions` used to save data during authentication of particular user. Requests from this cache usually involve only a browser and the {project_name} server, not the application. Here we can rely on sticky sessions and the `authenticationSessions` cache content does not need to be replicated across data centers, even if you are in Active/Active mode."
msgstr ""

msgid "Action tokens"
msgstr ""

msgid "We also have the concept of link:{developerguide_actiontoken_link}[action tokens], which are used typically for scenarios when the user needs to confirm an action asynchronously by email. For example, during the `forget password` flow the `actionTokens` Infinispan cache is used to track metadata about related action tokens, such as which action token was already used, so it can't be reused second time. This usually needs to be replicated across data centers."
msgstr ""

msgid "Caching and invalidation of persistent data"
msgstr ""

msgid "{project_name} uses Infinispan to cache persistent data to avoid many unnecessary requests to the database. Caching improves performance, however it adds an additional challenge. When some {project_name} server updates any data, all other {project_name} servers in all data centers need to be aware of it, so they invalidate particular data from their caches. {project_name} uses local Infinispan caches called `realms`, `users`, and `authorization` to cache persistent data."
msgstr ""

msgid "We use a separate cache, `work`, which is replicated across all data centers. The work cache itself does not cache any real data. It is used only for sending invalidation messages between cluster nodes and data centers. In other words, when data is updated, such as the user `john`, the {project_name} node sends the invalidation message to all other cluster nodes in the same data center and also to all other data centers. After receiving the invalidation notice, every node then invalidates the appropriate data from their local cache."
msgstr ""

msgid "User sessions"
msgstr ""

msgid "There are Infinispan caches called `sessions`, `clientSessions`, `offlineSessions`, and `offlineClientSessions`, all of which usually need to be replicated across data centers. These caches are used to save data about user sessions, which are valid for the length of a user's browser session. The caches must handle the HTTP requests from the end user and from the application. As described above, sticky sessions can not be reliably used in this instance, but we still want to ensure that subsequent HTTP requests can see the latest data. For this reason, the data are usually replicated across data centers."
msgstr ""

msgid "Brute force protection"
msgstr ""

msgid "Finally the `loginFailures` cache is used to track data about failed logins, such as how many times the user `john` entered a bad password. The details are described link:{adminguide_bruteforce_link}[here]. It is up to the admin whether this cache should be replicated across data centers. To have an accurate count of login failures, the replication is needed. On the other hand, not replicating this data can save some performance. So if performance is more important than accurate counts of login failures, the replication can be avoided."
msgstr ""

msgid "For more detail about how caches can be configured see <<tuningcache>>."
msgstr ""

msgid "Communication details"
msgstr ""

msgid "{project_name} uses multiple, separate clusters of Infinispan caches. Every {project_name} node is in the cluster with the other {project_name} nodes in same data center, but not with the {project_name} nodes in different data centers. A {project_name} node does not communicate directly with the {project_name} nodes from different data centers. {project_name} nodes use external JDG (actually {jdgserver_name} servers) for communication across data centers. This is done using the link:https://infinispan.org/docs/10.1.x/titles/server/server.html#hot_rod[Infinispan HotRod protocol]."
msgstr ""

msgid "The Infinispan caches on the {project_name} side must be configured with the link:https://infinispan.org/docs/10.1.x/titles/configuring/configuring.html#remote_cache_store[remoteStore] to ensure that data are saved to the remote cache. There is separate Infinispan cluster between JDG servers, so the data saved on JDG1 on `site1` are replicated to JDG2 on `site2` ."
msgstr ""

msgid "The receiving {jdgserver_name} server notifies the {project_name} servers in its cluster through Client Listeners, which are a feature of the Hot Rod protocol. {project_name} nodes on `site2` then update their Infinispan caches and the particular user session is also visible on {project_name} nodes on `site2`."
msgstr ""

msgid "See the <<archdiagram>> for more details."
msgstr ""

msgid "Setting up cross-site with {jdgserver_name} {jdgserver_version_latest}"
msgstr ""

msgid "Use the following procedures for {jdgserver_name} {jdgserver_version_latest} to perform a basic setup of cross-site replication."
msgstr ""

msgid "This example for {jdgserver_name} {jdgserver_version_latest} involves two data centers, `site1` and `site2`. Each data center consists of 1 {jdgserver_name} server and 2 {project_name} servers. We will end up with 2 {jdgserver_name} servers and 4 {project_name} servers in total."
msgstr ""

msgid "`Site1` consists of {jdgserver_name} server, `server1`, and 2 {project_name} servers, `node11` and `node12` ."
msgstr ""

msgid "`Site2` consists of {jdgserver_name} server, `server2`, and 2 {project_name} servers, `node21` and `node22` ."
msgstr ""

msgid "{jdgserver_name} servers `server1` and `server2` are connected to each other through the RELAY2 protocol and `backup` based {jdgserver_name} caches in a similar way as described in the link:{jdgserver_crossdcdocs_link}[{jdgserver_name} documentation]."
msgstr ""

msgid "{project_name} servers `node11` and `node12` form a cluster with each other, but they do not communicate directly with any server in `site2`. They communicate with the Infinispan server `server1` using the Hot Rod protocol (Remote cache). See <<communication>> for more information."
msgstr ""

msgid "The same details apply for `node21` and `node22`. They cluster with each other and communicate only with `server2` server using the Hot Rod protocol."
msgstr ""

msgid "Our example setup assumes that the four {project_name} servers talk to the same database. In production, we recommend that you use separate synchronously replicated databases across data centers as described in <<database>>."
msgstr ""

msgid "Setting Up {jdgserver_name} Servers"
msgstr ""

msgid "For cross-site replication, you start by creating remote {jdgserver_name} clusters that can back up {project_name} data."
msgstr ""

msgid "Download and install {jdgserver_name} Server {jdgserver_version_latest}."
msgstr ""

msgid "{jdgserver_name} Server {jdgserver_version_latest} requires Java 11."
msgstr ""

msgid "Create a user to authenticate client connections from {jdgserver_name}, for example:"
msgstr ""

msgid "$ bin/cli.sh user create myuser -p \"qwer1234!\""
msgstr ""

msgid "You specify these credentials in the Hot Rod client configuration when you create remote caches on {project_name}."
msgstr ""

msgid "Create an SSL keystore and truststore to secure connections between {jdgserver_name} and {project_name}, for example:"
msgstr ""

msgid "Create a keystore to provide an SSL identity to your {jdgserver_name} cluster"
msgstr ""

msgid "keytool -genkey -alias server -keyalg RSA -keystore server.jks -keysize 2048"
msgstr ""

msgid "Export an SSL certificate from the keystore."
msgstr ""

msgid "keytool -exportcert -keystore server.jks -alias server -file server.crt"
msgstr ""

msgid "Import the SSL certificate into a truststore that {project_name} can use to verify the SSL identity for {jdgserver_name}."
msgstr ""

msgid "keytool -importcert -keystore truststore.jks -alias server -file server.crt"
msgstr ""

msgid "Remove `server.crt`."
msgstr ""

msgid "rm server.crt"
msgstr ""

msgid "Configuring {jdgserver_name} Clusters"
msgstr ""

msgid "Configure {jdgserver_name} clusters to replicate {project_name} data across data centers."
msgstr ""

msgid "Install and set up {jdgserver_name} Server."
msgstr ""

msgid "Open `infinispan.xml` for editing."
msgstr ""

msgid "By default, {jdgserver_name} Server uses `server/conf/infinispan.xml` for static configuration such as cluster transport and security mechanisms."
msgstr ""

msgid "Create a stack that uses TCPPING as the cluster discovery protocol."
msgstr ""

msgid ""
"<stack name=\"global-cluster\" extends=\"tcp\">\n"
"    <!-- Remove MPING protocol from the stack and add TCPPING -->\n"
"    <TCPPING initial_hosts=\"server1[7800],server2[7800]\" <1>\n"
"             stack.combine=\"REPLACE\" stack.position=\"MPING\"/>\n"
"</stack>"
msgstr ""

msgid "Lists the host names for `server1` and `server2`."
msgstr ""

msgid "Configure the {jdgserver_name} cluster transport to perform cross-site replication."
msgstr ""

msgid "Add the RELAY2 protocol to a JGroups stack."
msgstr ""

msgid ""
"<jgroups>\n"
"   <stack name=\"xsite\" extends=\"udp\"> <1>\n"
"      <relay.RELAY2 site=\"site1\" <2>\n"
"                    max_site_masters=\"1000\"/> <3>\n"
"      <remote-sites default-stack=\"global-cluster\"> <4>\n"
"         <remote-site name=\"site1\"/>\n"
"         <remote-site name=\"site2\"/>\n"
"      </remote-sites>\n"
"   </stack>\n"
"</jgroups>"
msgstr ""

msgid "Creates a stack named `xsite` that extends the default UDP cluster transport."
msgstr ""

msgid "Adds the RELAY2 protocol and names the cluster you are configuring as `site1`. The site name must be unique to each {jdgserver_name} cluster."
msgstr ""

msgid "Sets 1000 as the number of relay nodes for the cluster. You should set a value that is equal to or greater than the maximum number of nodes in your {jdgserver_name} cluster."
msgstr ""

msgid "Names all {jdgserver_name} clusters that backup caches with {jdgserver_name} data and uses the default TCP stack for inter-cluster transport."
msgstr ""

msgid "Configure the {jdgserver_name} cluster transport to use the stack."
msgstr ""

msgid ""
"<cache-container name=\"default\" statistics=\"true\">\n"
"      <transport cluster=\"${infinispan.cluster.name:cluster}\"\n"
"                 stack=\"xsite\"/> <1>\n"
"</cache-container>"
msgstr ""

msgid "Uses the `xsite` stack for the cluster."
msgstr ""

msgid "Configure the keystore as an SSL identity in the server security realm."
msgstr ""

msgid ""
"<server-identities>\n"
"  <ssl>\n"
"    <keystore path=\"server.jks\" <1>\n"
"              relative-to=\"infinispan.server.config.path\"\n"
"              keystore-password=\"password\" <2>\n"
"              alias=\"server\" /> <3>\n"
"  </ssl>\n"
"</server-identities>"
msgstr ""

msgid "Specifies the path of the keystore that contains the SSL identity."
msgstr ""

msgid "Specifies the password to access the keystore."
msgstr ""

msgid "Names the alias of the certificate in the keystore."
msgstr ""

msgid "Configure the authentication mechanism for the Hot Rod endpoint."
msgstr ""

msgid ""
"<endpoints socket-binding=\"default\">\n"
"   <hotrod-connector name=\"hotrod\">\n"
"      <authentication>\n"
"         <sasl mechanisms=\"SCRAM-SHA-512\" <1>\n"
"               server-name=\"infinispan\" /> <2>\n"
"      </authentication>\n"
"   </hotrod-connector>\n"
"   <rest-connector name=\"rest\"/>\n"
"</endpoints>"
msgstr ""

msgid "Configures the SASL authentication mechanism for the Hot Rod endpoint.  SCRAM-SHA-512 is the default SASL mechanism for Hot Rod. However you can use whatever is appropriate for your environment, such as GSSAPI."
msgstr ""

msgid "Defines the name that {jdgserver_name} servers present to clients. You specify this name in the Hot Rod client configuration when you set up {project_name}."
msgstr ""

msgid "Create a cache template."
msgstr ""

msgid "Add the cache template to `infinispan.xml` on each node in the {jdgserver_name} cluster."
msgstr ""

msgid ""
"<cache-container ... >\n"
"  <replicated-cache-configuration name=\"sessions-cfg\" <1>\n"
"                                  mode=\"SYNC\"> <2>\n"
"    <locking acquire-timeout=\"0\" /> <3>\n"
"    <backups>\n"
"      <backup site=\"site2\" strategy=\"SYNC\" /> <4>\n"
"    </backups>\n"
"  </replicated-cache-configuration>\n"
"</cache-container>"
msgstr ""

msgid "Creates a cache template named `sessions-cfg`."
msgstr ""

msgid "Defines a cache that synchronously replicates data across the cluster."
msgstr ""

msgid "Disables timeout for lock acquisition."
msgstr ""

msgid "Names the backup site for the {jdgserver_name} cluster you are configuring."
msgstr ""

msgid "Start {jdgserver_name} server1."
msgstr ""

msgid "./server.sh -c infinispan.xml -b PUBLIC_IP_ADDRESS -k PUBLIC_IP_ADDRESS -Djgroups.mcast_addr=228.6.7.10"
msgstr ""

msgid "Start {jdgserver_name} server2."
msgstr ""

msgid "./server.sh -c infinispan.xml -b PUBLIC_IP_ADDRESS -k PUBLIC_IP_ADDRESS -Djgroups.mcast_addr=228.6.7.11"
msgstr ""

msgid "Check {jdgserver_name} server logs to verify the clusters form cross-site views."
msgstr ""

msgid ""
"INFO  [org.infinispan.XSITE] (jgroups-5,${server.hostname}) ISPN000439: Received new x-site view: [site1]\n"
"INFO  [org.infinispan.XSITE] (jgroups-7,${server.hostname}) ISPN000439: Received new x-site view: [site1, site2]"
msgstr ""

msgid "Creating Infinispan Caches"
msgstr ""

msgid "Create the Infinispan caches that {project_name} requires."
msgstr ""

msgid "We recommend that you create caches on {jdgserver_name} clusters at runtime rather than adding caches to `infinispan.xml`. This strategy ensures that your caches are automatically synchronized across the cluster and permanently stored."
msgstr ""

msgid "The following procedure uses the {jdgserver_name} Command Line Interface (CLI) to create all the required caches in a single batch command."
msgstr ""

msgid "Configure your {jdgserver_name} clusters."
msgstr ""

msgid "Create a batch file that contains caches, for example:"
msgstr ""

msgid ""
"cat > /tmp/caches.batch<<EOF\n"
"echo \"creating caches...\"\n"
"create cache work --template=sessions-cfg\n"
"create cache sessions --template=sessions-cfg\n"
"create cache clientSessions --template=sessions-cfg\n"
"create cache offlineSessions --template=sessions-cfg\n"
"create cache offlineClientSessions --template=sessions-cfg\n"
"create cache actionTokens --template=sessions-cfg\n"
"create cache loginFailures --template=sessions-cfg\n"
"echo \"verifying caches\"\n"
"ls caches\n"
"EOF"
msgstr ""

msgid "Create the caches with the CLI."
msgstr ""

msgid "$ bin/cli.sh -c https://server1:11222 --trustall -f /tmp/caches.batch"
msgstr ""

msgid "Instead of the `--trustall` argument you can specify the truststore with the `-t` argument and the truststore password with the `-s` argument."
msgstr ""

msgid "Create the caches on the other site."
msgstr ""

msgid "Configuring Remote Cache Stores on {project_name}"
msgstr ""

msgid "After you set up remote {jdgserver_name} clusters, you configure the Infinispan subsystem on {project_name} to externalize data to those clusters through remote stores."
msgstr ""

msgid "Set up remote {jdgserver_name} clusters for cross-site configuration."
msgstr ""

msgid "Create a truststore that contains the SSL certificate with the {jdgserver_name} Server identity."
msgstr ""

msgid "Add the truststore to the {project_name} deployment."
msgstr ""

msgid "Create a socket binding that points to your {jdgserver_name} cluster."
msgstr ""

msgid ""
"<outbound-socket-binding name=\"remote-cache\"> <1>\n"
"  <remote-destination host=\"${remote.cache.host:server_hostname}\" <2>\n"
"                      port=\"${remote.cache.port:11222}\"/> <3>\n"
"</outbound-socket-binding>"
msgstr ""

msgid "Names the socket binding as `remote-cache`."
msgstr ""

msgid "Specifies one or more hostnames for the {jdgserver_name} cluster."
msgstr ""

msgid "Defines the port of `11222` where the Hot Rod endpoint listens."
msgstr ""

msgid "Add the `org.keycloak.keycloak-model-infinispan` module to the `keycloak` cache container in the Infinispan subsystem."
msgstr ""

msgid ""
"<subsystem xmlns=\"urn:jboss:domain:infinispan:12.0\">\n"
"    <cache-container name=\"keycloak\"\n"
"                     modules=\"org.keycloak.keycloak-model-infinispan\"/>"
msgstr ""

msgid "Update the `work` cache in the Infinispan subsystem so it has the following configuration:"
msgstr ""

msgid ""
"<replicated-cache name=\"work\"> <1>\n"
"    <remote-store cache=\"work\" <2>\n"
"                  remote-servers=\"remote-cache\" <3>\n"
"                  passivation=\"false\"\n"
"                  fetch-state=\"false\"\n"
"                  purge=\"false\"\n"
"                  preload=\"false\"\n"
"                  shared=\"true\">\n"
"        <property name=\"rawValues\">true</property>\n"
"        <property name=\"marshaller\">org.keycloak.cluster.infinispan.KeycloakHotRodMarshallerFactory</property>\n"
"        <property name=\"infinispan.client.hotrod.auth_username\">myuser</property>\n"
"        <property name=\"infinispan.client.hotrod.auth_password\">qwer1234!</property>\n"
"        <property name=\"infinispan.client.hotrod.auth_realm\">default</property>\n"
"        <property name=\"infinispan.client.hotrod.auth_server_name\">infinispan</property>\n"
"        <property name=\"infinispan.client.hotrod.sasl_mechanism\">SCRAM-SHA-512</property>\n"
"        <property name=\"infinispan.client.hotrod.trust_store_file_name\">/path/to/truststore.jks</property>\n"
"        <property name=\"infinispan.client.hotrod.trust_store_type\">JKS</property>\n"
"        <property name=\"infinispan.client.hotrod.trust_store_password\">password</property>\n"
"    </remote-store>\n"
"</replicated-cache>"
msgstr ""

msgid "Names the cache in the {jdgserver_name} configuration."
msgstr ""

msgid "Names the corresponding cache on the remote {jdgserver_name} cluster."
msgstr ""

msgid "Specifies the `remote-cache` socket binding."
msgstr ""

msgid "The preceding cache configuration includes recommended settings for {jdgserver_name} caches. Hot Rod client configuration properties specify the {jdgserver_name} user credentials and SSL keystore and truststore details."
msgstr ""

msgid "Refer to the https://infinispan.org/docs/11.0.x/titles/xsite/xsite.html#configure_clients-xsite[{jdgserver_name} documentation] for descriptions of each property."
msgstr ""

msgid "Add distributed caches to the Infinispan subsystem for each of the following caches:"
msgstr ""

msgid "sessions"
msgstr ""

msgid "clientSessions"
msgstr ""

msgid "offlineSessions"
msgstr ""

msgid "offlineClientSessions"
msgstr ""

msgid "actionTokens"
msgstr ""

msgid "loginFailures"
msgstr ""

msgid "For example, add a cache named `sessions` with the following configuration:"
msgstr ""

msgid ""
"<distributed-cache name=\"sessions\" <1>\n"
"                   owners=\"1\"> <2>\n"
"    <remote-store cache=\"sessions\" <3>\n"
"                  remote-servers=\"remote-cache\" <4>\n"
"                  passivation=\"false\"\n"
"                  fetch-state=\"false\"\n"
"                  purge=\"false\"\n"
"                  preload=\"false\"\n"
"                  shared=\"true\">\n"
"        <property name=\"rawValues\">true</property>\n"
"        <property name=\"marshaller\">org.keycloak.cluster.infinispan.KeycloakHotRodMarshallerFactory</property>\n"
"        <property name=\"infinispan.client.hotrod.auth_username\">myuser</property>\n"
"        <property name=\"infinispan.client.hotrod.auth_password\">qwer1234!</property>\n"
"        <property name=\"infinispan.client.hotrod.auth_realm\">default</property>\n"
"        <property name=\"infinispan.client.hotrod.auth_server_name\">infinispan</property>\n"
"        <property name=\"infinispan.client.hotrod.sasl_mechanism\">SCRAM-SHA-512</property>\n"
"        <property name=\"infinispan.client.hotrod.trust_store_file_name\">/path/to/truststore.jks</property>\n"
"        <property name=\"infinispan.client.hotrod.trust_store_type\">JKS</property>\n"
"        <property name=\"infinispan.client.hotrod.trust_store_password\">password</property>\n"
"    </remote-store>\n"
"</distributed-cache>"
msgstr ""

msgid "Configures one replica of each cache entry across the {jdgserver_name} cluster."
msgstr ""

msgid "Copy the `NODE11` to 3 other directories referred later as `NODE12`, `NODE21` and `NODE22`."
msgstr ""

msgid "Start `NODE11` :"
msgstr ""

msgid ""
"cd NODE11/bin\n"
"./standalone.sh -c standalone-ha.xml -Djboss.node.name=node11 -Djboss.site.name=site1 \\\n"
"  -Djboss.default.multicast.address=234.56.78.1 -Dremote.cache.host=server1 \\\n"
"  -Djava.net.preferIPv4Stack=true -b _PUBLIC_IP_ADDRESS_"
msgstr ""

msgid "If you notice the following warning messages in logs, you can safely ignore them:"
msgstr ""

msgid ""
"WARN  [org.infinispan.CONFIG] (MSC service thread 1-5) ISPN000292: Unrecognized attribute 'infinispan.client.hotrod.auth_password'. Please check your configuration. Ignoring!\n"
"WARN  [org.infinispan.CONFIG] (MSC service thread 1-5) ISPN000292: Unrecognized attribute 'infinispan.client.hotrod.auth_username'. Please check your configuration. Ignoring!"
msgstr ""

msgid "Start `NODE12` :"
msgstr ""

msgid ""
"cd NODE12/bin\n"
"./standalone.sh -c standalone-ha.xml -Djboss.node.name=node12 -Djboss.site.name=site1 \\\n"
"  -Djboss.default.multicast.address=234.56.78.1 -Dremote.cache.host=server1 \\\n"
"  -Djava.net.preferIPv4Stack=true -b _PUBLIC_IP_ADDRESS_"
msgstr ""

msgid "The cluster nodes should be connected. Something like this should be in the log of both NODE11 and NODE12:"
msgstr ""

msgid "Received new cluster view for channel keycloak: [node11|1] (2) [node11, node12]"
msgstr ""

msgid "The channel name in the log might be different."
msgstr ""

msgid "Start `NODE21` :"
msgstr ""

msgid ""
"cd NODE21/bin\n"
"./standalone.sh -c standalone-ha.xml -Djboss.node.name=node21 -Djboss.site.name=site2 \\\n"
"  -Djboss.default.multicast.address=234.56.78.2 -Dremote.cache.host=server2 \\\n"
"  -Djava.net.preferIPv4Stack=true -b _PUBLIC_IP_ADDRESS_"
msgstr ""

msgid "It shouldn't be connected to the cluster with `NODE11` and `NODE12`, but to a separate one:"
msgstr ""

msgid "Received new cluster view for channel keycloak: [node21|0] (1) [node21]"
msgstr ""

msgid "Start `NODE22` :"
msgstr ""

msgid ""
"cd NODE22/bin\n"
"./standalone.sh -c standalone-ha.xml -Djboss.node.name=node22 -Djboss.site.name=site2 \\\n"
"  -Djboss.default.multicast.address=234.56.78.2 -Dremote.cache.host=server2 \\\n"
"  -Djava.net.preferIPv4Stack=true -b _PUBLIC_IP_ADDRESS_"
msgstr ""

msgid "It should be in cluster with `NODE21` :"
msgstr ""

msgid "Received new cluster view for channel keycloak: [node21|1] (2) [node21, node22]"
msgstr ""

msgid "Test:"
msgstr ""

msgid "Go to `http://node11:8080/auth/` and create the initial admin user."
msgstr ""

msgid "Go to `http://node11:8080/auth/admin` and login as admin to admin console."
msgstr ""

msgid "Open a second browser and go to any of nodes `http://node12:8080/auth/admin` or `http://node21:8080/auth/admin` or `http://node22:8080/auth/admin`. After login, you should be able to see the same sessions in tab `Sessions` of particular user, client or realm on all 4 servers."
msgstr ""

msgid "After making a change in the {project_name} Admin Console, such as modifying a user or a realm, that change should be immediately visible on any of the four nodes. Caches should be properly invalidated everywhere."
msgstr ""

msgid "Check server.logs if needed. After login or logout, the message like this should be on all the nodes `NODEXY/standalone/log/server.log` :"
msgstr ""

msgid ""
"2017-08-25 17:35:17,737 DEBUG [org.keycloak.models.sessions.infinispan.remotestore.RemoteCacheSessionListener] (Client-Listener-sessions-30012a77422542f5) Received event from remote store.\n"
"Event 'CLIENT_CACHE_ENTRY_REMOVED', key '193489e7-e2bc-4069-afe8-f1dfa73084ea', skip 'false'"
msgstr ""

msgid "Setting up cross-site replication with {jdgserver_name} {jdgserver_version}"
msgstr ""

msgid "This example for {jdgserver_name} {jdgserver_version} involves two data centers, `site1` and `site2`. Each data center consists of 1 {jdgserver_name} server and 2 {project_name} servers. We will end up with 2 {jdgserver_name} servers and 4 {project_name} servers in total."
msgstr ""

msgid "{project_name} servers `node11` and `node12` form a cluster with each other, but they do not communicate directly with any server in `site2`. They communicate with the Infinispan server `server1` using the Hot Rod protocol (Remote cache). See <<communication>> for the details."
msgstr ""

msgid "Our example setup assumes all that all 4 {project_name} servers talk to the same database. In production, it is recommended to use separate synchronously replicated databases across data centers as described in <<database>>."
msgstr ""

msgid "Setting up the {jdgserver_name} server"
msgstr ""

msgid "Follow these steps to set up the {jdgserver_name} server:"
msgstr ""

msgid "Download {jdgserver_name} {jdgserver_version} server and unzip to a directory you choose. This location will be referred in later steps as `SERVER1_HOME` ."
msgstr ""

msgid "Change those things in the `SERVER1_HOME/server/conf/infinispan-xsite.xml` in the configuration of JGroups subsystem:"
msgstr ""

msgid "Add the `xsite` channel, which will use `tcp` stack, under `channels` element:"
msgstr ""

msgid ""
"<channels default=\"cluster\">\n"
"    <channel name=\"cluster\"/>\n"
"    <channel name=\"xsite\" stack=\"tcp\"/>\n"
"</channels>"
msgstr ""

msgid "Add a `relay` element to the end of the `udp` stack. We will configure it in a way that our site is `site1` and the other site, where we will backup, is `site2`:"
msgstr ""

msgid ""
"<stack name=\"udp\">\n"
"    ...\n"
"    <relay site=\"site1\">\n"
"        <remote-site name=\"site2\" channel=\"xsite\"/>\n"
"        <property name=\"relay_multicasts\">false</property>\n"
"    </relay>\n"
"</stack>"
msgstr ""

msgid "Configure the `tcp` stack to use `TCPPING` protocol instead of `MPING`. Remove the `MPING` element and replace it with the `TCPPING`. The `initial_hosts` element points to the hosts `server1` and `server2`:"
msgstr ""

msgid ""
"<stack name=\"tcp\">\n"
"    <transport type=\"TCP\" socket-binding=\"jgroups-tcp\"/>\n"
"    <protocol type=\"TCPPING\">\n"
"        <property name=\"initial_hosts\">server1[7600],server2[7600]</property>\n"
"        <property name=\"ergonomics\">false</property>\n"
"    </protocol>\n"
"    <protocol type=\"MERGE3\"/>\n"
"    ...\n"
"</stack>"
msgstr ""

msgid "This is just an example setup to have things quickly running. In production, you are not required to use `tcp` stack for the JGroups `RELAY2`, but you can configure any other stack. For example, you could use the default udp stack, if the network between your data centers is able to support multicast. Just make sure that the {jdgserver_name} and {project_name} clusters are mutually indiscoverable. Similarly, you are not required to use `TCPPING` as discovery protocol. And in production, you probably won't use `TCPPING` due it's static nature. Finally, site names are also configurable. Details of this more-detailed setup are out-of-scope of the {project_name} documentation. See the {jdgserver_name} documentation and JGroups documentation for more details."
msgstr ""

msgid "Add this into `SERVER1_HOME/standalone/configuration/clustered.xml` under cache-container named `clustered`:"
msgstr ""

msgid ""
"<cache-container name=\"clustered\" default-cache=\"default\" statistics=\"true\">\n"
"        ...\n"
"        <replicated-cache-configuration name=\"sessions-cfg\" mode=\"SYNC\" start=\"EAGER\" batching=\"false\">\n"
"            <locking acquire-timeout=\"0\" />\n"
"            <backups>\n"
"                <backup site=\"site2\" failure-policy=\"FAIL\" strategy=\"SYNC\" enabled=\"true\">\n"
"                    <take-offline min-wait=\"60000\" after-failures=\"3\" />\n"
"                </backup>\n"
"            </backups>\n"
"        </replicated-cache-configuration>\n"
"\n"
"        <replicated-cache name=\"work\" configuration=\"sessions-cfg\"/>\n"
"        <replicated-cache name=\"sessions\" configuration=\"sessions-cfg\"/>\n"
"        <replicated-cache name=\"clientSessions\" configuration=\"sessions-cfg\"/>\n"
"        <replicated-cache name=\"offlineSessions\" configuration=\"sessions-cfg\"/>\n"
"        <replicated-cache name=\"offlineClientSessions\" configuration=\"sessions-cfg\"/>\n"
"        <replicated-cache name=\"actionTokens\" configuration=\"sessions-cfg\"/>\n"
"        <replicated-cache name=\"loginFailures\" configuration=\"sessions-cfg\"/>\n"
"\n"
"</cache-container>"
msgstr ""

msgid "Details about the configuration options inside `replicated-cache-configuration` are explained in <<tuningcache>>, which includes information about tweaking some of those options."
msgstr ""

msgid "Unlike in previous version, the {jdgserver_name} server `replicated-cache-configuration` needs to be configured without `transaction` element. See <<troubleshooting>> for more details."
msgstr ""

msgid "Some {jdgserver_name} server releases require authorization before accessing protected caches over network."
msgstr ""

msgid "You should not see any issue if you use recommended {jdgserver_name} {jdgserver_version} server and this step can (and should) be ignored. Issues related to authorization may exist just for some other versions of {jdgserver_name} server."
msgstr ""

msgid "{project_name} requires updates to `___script_cache` cache containing scripts. If you get errors accessing this cache, you will need to set up authorization in `clustered.xml` configuration as described below:"
msgstr ""

msgid "In the `<management>` section, add a security realm:"
msgstr ""

msgid ""
"<management>\n"
"    <security-realms>\n"
"        ...\n"
"        <security-realm name=\"AllowScriptManager\">\n"
"            <authentication>\n"
"                <users>\n"
"                    <user username=\"___script_manager\">\n"
"                        <password>not-so-secret-password</password>\n"
"                    </user>\n"
"                </users>\n"
"            </authentication>\n"
"        </security-realm>\n"
"    </security-realms>\n"
msgstr ""

msgid "In the server core subsystem, add `<security>` as below:"
msgstr ""

msgid ""
"<subsystem xmlns=\"urn:infinispan:server:core:8.4\">\n"
"    <cache-container name=\"clustered\" default-cache=\"default\" statistics=\"true\">\n"
"        <security>\n"
"            <authorization>\n"
"                <identity-role-mapper/>\n"
"                <role name=\"___script_manager\" permissions=\"ALL\"/>\n"
"            </authorization>\n"
"        </security>\n"
"        ..."
msgstr ""

msgid "In the endpoint subsystem, add authentication configuration to Hot Rod connector:"
msgstr ""

msgid ""
"<subsystem xmlns=\"urn:infinispan:server:endpoint:8.1\">\n"
"    <hotrod-connector cache-container=\"clustered\" socket-binding=\"hotrod\">\n"
"        ...\n"
"        <authentication security-realm=\"AllowScriptManager\">\n"
"            <sasl mechanisms=\"DIGEST-MD5\" qop=\"auth\" server-name=\"keycloak-jdg-server\">\n"
"                <policy>\n"
"                    <no-anonymous value=\"false\" />\n"
"                </policy>\n"
"            </sasl>\n"
"        </authentication>"
msgstr ""

msgid "Copy the server to the second location, which will be referred to later as `SERVER2_HOME`."
msgstr ""

msgid "In the `SERVER2_HOME/standalone/configuration/clustered.xml` exchange `site1` with `site2` and vice versa, both in the configuration of `relay` in the JGroups subsystem and in configuration of `backups` in the cache-subsystem. For example:"
msgstr ""

msgid "The `relay` element should look like this:"
msgstr ""

msgid ""
"<relay site=\"site2\">\n"
"    <remote-site name=\"site1\" channel=\"xsite\"/>\n"
"    <property name=\"relay_multicasts\">false</property>\n"
"</relay>"
msgstr ""

msgid "The `backups` element like this:"
msgstr ""

msgid ""
"<backups>\n"
"  <backup site=\"site1\" ....\n"
"  ..."
msgstr ""

msgid "The _PUBLIC_IP_ADDRESS_ below refers to the IP address or hostname, which can be used for your server to bind to. Note that every {jdgserver_name} server and {project_name} server needs to use different address. During example setup with all the servers running on the same host, you may need to add the option `-Djboss.bind.address.management=_PUBLIC_IP_ADDRESS_` as every server needs to use also different management interface. But this option usually should be omitted in production environments to avoid the ability for remote access to your server. For more information, see the link:{appserver_socket_link}[_{appserver_socket_name}_]."
msgstr ""

msgid "Start server `server1`:"
msgstr ""

msgid ""
"cd SERVER1_HOME/bin\n"
"./standalone.sh -c clustered.xml -Djava.net.preferIPv4Stack=true \\\n"
"  -Djboss.default.multicast.address=234.56.78.99 \\\n"
"  -Djboss.node.name=server1 -b _PUBLIC_IP_ADDRESS_"
msgstr ""

msgid "Start server `server2`. There is a different multicast address, so the `server1` and `server2` servers are not directly clustered with each other; rather, they are just connected through the RELAY2 protocol, and the TCP JGroups stack is used for communication between them. The start up command looks like this:"
msgstr ""

msgid ""
"cd SERVER2_HOME/bin\n"
"./standalone.sh -c clustered.xml -Djava.net.preferIPv4Stack=true \\\n"
"  -Djboss.default.multicast.address=234.56.78.100 \\\n"
"  -Djboss.node.name=server2 -b _PUBLIC_IP_ADDRESS_"
msgstr ""

msgid "To verify that channel works at this point, you may need to use JConsole and connect either to the running `SERVER1` or the `SERVER2` server. When you use the MBean `jgroups:type=protocol,cluster=\"cluster\",protocol=RELAY2` and operation `printRoutes`, you should see output like this:"
msgstr ""

msgid ""
"site1 --> _server1:site1\n"
"site2 --> _server2:site2"
msgstr ""

msgid "When you use the MBean `jgroups:type=protocol,cluster=\"cluster\",protocol=GMS`, you should see that the attribute member contains just single member:"
msgstr ""

msgid "On `SERVER1` it should be like this:"
msgstr ""

msgid "(1) server1"
msgstr ""

msgid "And on SERVER2 like this:"
msgstr ""

msgid "(1) server2"
msgstr ""

msgid "In production, you can have more {jdgserver_name} servers in every data center. You just need to ensure that {jdgserver_name} servers in same data center are using the same multicast address (In other words, the same `jboss.default.multicast.address` during startup). Then in jconsole in `GMS` protocol view, you will see all the members of current cluster."
msgstr ""

msgid "Setting up {project_name} servers"
msgstr ""

msgid "Unzip {project_name} server distribution to a location you choose. It will be referred to later as `NODE11`."
msgstr ""

msgid "Configure a shared database for KeycloakDS datasource. It is recommended to use MySQL or MariaDB for testing purposes. See <<database>> for more details."
msgstr ""

msgid "In production you will likely need to have a separate database server in every data center and both database servers should be synchronously replicated to each other. In the example setup, we just use a single database and connect all 4 {project_name} servers to it."
msgstr ""

msgid "Edit `NODE11/standalone/configuration/standalone-ha.xml` :"
msgstr ""

msgid "Add the attribute `site` to the JGroups UDP protocol:"
msgstr ""

msgid ""
"<stack name=\"udp\">\n"
"  <transport type=\"UDP\" socket-binding=\"jgroups-udp\" site=\"${jboss.site.name}\"/>"
msgstr ""

msgid "Add the `remote-store` under `work` cache:"
msgstr ""

msgid ""
"<replicated-cache name=\"work\">\n"
"    <remote-store cache=\"work\" remote-servers=\"remote-cache\" passivation=\"false\" fetch-state=\"false\" purge=\"false\" preload=\"false\" shared=\"true\">\n"
"        <property name=\"rawValues\">true</property>\n"
"        <property name=\"marshaller\">org.keycloak.cluster.infinispan.KeycloakHotRodMarshallerFactory</property>\n"
"        <property name=\"protocolVersion\">2.9</property>\n"
"    </remote-store>\n"
"</replicated-cache>"
msgstr ""

msgid "Add the `remote-store` like this under `sessions` cache:"
msgstr ""

msgid ""
"<distributed-cache name=\"sessions\" owners=\"1\">\n"
"    <remote-store cache=\"sessions\" remote-servers=\"remote-cache\" passivation=\"false\" fetch-state=\"false\" purge=\"false\" preload=\"false\" shared=\"true\">\n"
"        <property name=\"rawValues\">true</property>\n"
"        <property name=\"marshaller\">org.keycloak.cluster.infinispan.KeycloakHotRodMarshallerFactory</property>\n"
"        <property name=\"protocolVersion\">2.9</property>\n"
"    </remote-store>\n"
"</distributed-cache>"
msgstr ""

msgid "Do the same for `offlineSessions`, `clientSessions`, `offlineClientSessions`, `loginFailures`, and `actionTokens` caches (the only difference from `sessions` cache is that `cache` property value are different):"
msgstr ""

msgid ""
"<distributed-cache name=\"offlineSessions\" owners=\"1\">\n"
"    <remote-store cache=\"offlineSessions\" remote-servers=\"remote-cache\" passivation=\"false\" fetch-state=\"false\" purge=\"false\" preload=\"false\" shared=\"true\">\n"
"        <property name=\"rawValues\">true</property>\n"
"        <property name=\"marshaller\">org.keycloak.cluster.infinispan.KeycloakHotRodMarshallerFactory</property>\n"
"        <property name=\"protocolVersion\">2.9</property>\n"
"    </remote-store>\n"
"</distributed-cache>\n"
"\n"
"<distributed-cache name=\"clientSessions\" owners=\"1\">\n"
"    <remote-store cache=\"clientSessions\" remote-servers=\"remote-cache\" passivation=\"false\" fetch-state=\"false\" purge=\"false\" preload=\"false\" shared=\"true\">\n"
"        <property name=\"rawValues\">true</property>\n"
"        <property name=\"marshaller\">org.keycloak.cluster.infinispan.KeycloakHotRodMarshallerFactory</property>\n"
"        <property name=\"protocolVersion\">2.9</property>\n"
"    </remote-store>\n"
"</distributed-cache>\n"
"\n"
"<distributed-cache name=\"offlineClientSessions\" owners=\"1\">\n"
"    <remote-store cache=\"offlineClientSessions\" remote-servers=\"remote-cache\" passivation=\"false\" fetch-state=\"false\" purge=\"false\" preload=\"false\" shared=\"true\">\n"
"        <property name=\"rawValues\">true</property>\n"
"        <property name=\"marshaller\">org.keycloak.cluster.infinispan.KeycloakHotRodMarshallerFactory</property>\n"
"        <property name=\"protocolVersion\">2.9</property>\n"
"    </remote-store>\n"
"</distributed-cache>\n"
"\n"
"<distributed-cache name=\"loginFailures\" owners=\"1\">\n"
"    <remote-store cache=\"loginFailures\" remote-servers=\"remote-cache\" passivation=\"false\" fetch-state=\"false\" purge=\"false\" preload=\"false\" shared=\"true\">\n"
"        <property name=\"rawValues\">true</property>\n"
"        <property name=\"marshaller\">org.keycloak.cluster.infinispan.KeycloakHotRodMarshallerFactory</property>\n"
"        <property name=\"protocolVersion\">2.9</property>\n"
"    </remote-store>\n"
"</distributed-cache>\n"
"\n"
"<distributed-cache name=\"actionTokens\" owners=\"2\">\n"
"    <object-memory size=\"-1\"/>\n"
"    <expiration max-idle=\"-1\" interval=\"300000\"/>\n"
"    <remote-store cache=\"actionTokens\" remote-servers=\"remote-cache\" passivation=\"false\" fetch-state=\"false\" purge=\"false\" preload=\"true\" shared=\"true\">\n"
"        <property name=\"rawValues\">true</property>\n"
"        <property name=\"marshaller\">org.keycloak.cluster.infinispan.KeycloakHotRodMarshallerFactory</property>\n"
"        <property name=\"protocolVersion\">2.9</property>\n"
"    </remote-store>\n"
"</distributed-cache>"
msgstr ""

msgid "Add outbound socket binding for the remote store into `socket-binding-group` element configuration:"
msgstr ""

msgid ""
"<outbound-socket-binding name=\"remote-cache\">\n"
"    <remote-destination host=\"${remote.cache.host:localhost}\" port=\"${remote.cache.port:11222}\"/>\n"
"</outbound-socket-binding>"
msgstr ""

msgid "The configuration of distributed cache `authenticationSessions` and other caches is left unchanged."
msgstr ""

msgid "It is recommended to add the `remoteStoreSecurityEnabled` property with the value of `false` (or eventually `true` if you enabled security for the {jdgserver_name} servers as described above) to the `connectionsInfinispan` SPI in the `keycloak-server` subsystem:"
msgstr ""

msgid ""
"<spi name=\"connectionsInfinispan\">\n"
"    ...\n"
"    <provider ...>\n"
"        <properties>\n"
"            ...\n"
"            <property name=\"remoteStoreSecurityEnabled\" value=\"false\"/>\n"
"        </properties>\n"
"    ..."
msgstr ""

msgid "Optionally enable DEBUG logging under the `logging` subsystem:"
msgstr ""

msgid ""
"<logger category=\"org.keycloak.cluster.infinispan\">\n"
"    <level name=\"DEBUG\"/>\n"
"</logger>\n"
"<logger category=\"org.keycloak.connections.infinispan\">\n"
"    <level name=\"DEBUG\"/>\n"
"</logger>\n"
"<logger category=\"org.keycloak.models.cache.infinispan\">\n"
"    <level name=\"DEBUG\"/>\n"
"</logger>\n"
"<logger category=\"org.keycloak.models.sessions.infinispan\">\n"
"    <level name=\"DEBUG\"/>\n"
"</logger>"
msgstr ""

msgid ""
"cd NODE11/bin\n"
"./standalone.sh -c standalone-ha.xml -Djboss.node.name=node11 -Djboss.site.name=site1 \\\n"
"  -Djboss.default.multicast.address=234.56.78.1 -Dremote.cache.host=server1 \\\n"
"  -Djava.net.preferIPv4Stack=true -b _PUBLIC_IP_ADDRESS_\n"
msgstr ""

msgid "It shouldn't be connected to the cluster with `NODE11` and `NODE12`, but to separate one:"
msgstr ""

msgid "After doing any change in Keycloak admin console (eg. update some user or some realm), the update should be immediately visible on any of 4 nodes as caches should be properly invalidated everywhere."
msgstr ""

msgid "Administration of cross-site deployment"
msgstr ""

msgid "This section contains some tips and options related to cross-site replication."
msgstr ""

msgid "When you run the {project_name} server inside a data center, it is required that the database referenced in `KeycloakDS` datasource is already running and available in that data center. It is also necessary that the {jdgserver_name} server referenced by the `outbound-socket-binding`, which is referenced from the Infinispan cache `remote-store` element, is already running. Otherwise the {project_name} server will fail to start."
msgstr ""

msgid "Every data center can have more database nodes if you want to support database failover and better reliability. Refer to the documentation of your database and JDBC driver for the details how to set this up on the database side and how the `KeycloakDS` datasource on Keycloak side needs to be configured."
msgstr ""

msgid "Every datacenter can have more {jdgserver_name} servers running in the cluster. This is useful if you want some failover and better fault tolerance. The Hot Rod protocol used for communication between {jdgserver_name} servers and {project_name} servers has a feature that {jdgserver_name} servers will automatically send new topology to the {project_name} servers about the change in the {jdgserver_name} cluster, so the remote store on {project_name} side will know to which {jdgserver_name} servers it can connect. Read the {jdgserver_name} and WildFly documentation for more details."
msgstr ""

msgid "It is highly recommended that a master {jdgserver_name} server is running in every site before the {project_name} servers in **any** site are started. As in our example, we started both `server1` and `server2` first, before all {project_name} servers. If you still need to run the {project_name} server and the backup site is offline, it is recommended to manually switch the backup site offline on the {jdgserver_name} servers on your site, as described in <<onoffline>>. If you do not manually switch the unavailable site offline, the first startup may fail or they may be some exceptions during startup until the backup site is taken offline automatically due the configured count of failed operations."
msgstr ""

msgid "Bringing sites offline and online"
msgstr ""

msgid "For example, assume this scenario:"
msgstr ""

msgid "Site `site2` is entirely offline from the `site1` perspective. This means that all {jdgserver_name} servers on `site2` are off *or* the network between `site1` and `site2` is broken."
msgstr ""

msgid "You run {project_name} servers and {jdgserver_name} server `server1` in site `site1`"
msgstr ""

msgid "Someone logs in on a {project_name} server on `site1`."
msgstr ""

msgid "The {project_name} server from `site1` will try to write the session to the remote cache on `server1` server, which is supposed to backup data to the `server2` server in the `site2`. See <<communication>> for more information."
msgstr ""

msgid "Server `server2` is offline or unreachable from `server1`. So the backup from `server1` to `server2` will fail."
msgstr ""

msgid "The exception is thrown in `server1` log and the failure will be propagated from `server1` server to {project_name} servers as well because the default `FAIL` backup failure policy is configured. See <<backupfailure>> for details around the backup policies."
msgstr ""

msgid "The error will happen on {project_name} side too and user may not be able to finish his login."
msgstr ""

msgid "According to your environment, it may be more or less probable that the network between sites is unavailable or temporarily broken (split-brain). In case this happens, it is good that {jdgserver_name} servers on `site1` are aware of the fact that {jdgserver_name} servers on `site2` are unavailable, so they will stop trying to reach the servers in the `server2` site and the backup failures won't happen. This is called `Take site offline` ."
msgstr ""

msgid "Take site offline"
msgstr ""

msgid "There are 2 ways to take the site offline."
msgstr ""

msgid "**Manually by admin** - Admin can use the `jconsole` or other tool and run some JMX operations to manually take the particular site offline. This is useful especially if the outage is planned. With `jconsole` or CLI, you can connect to the `server1` server and take the `site2` offline. More details about this are available in the link:{jdgserver_crossdcdocs_link}[{jdgserver_name} documentation]."
msgstr ""

msgid "These steps usually need to be done for all the {project_name} caches mentioned in <<backups>>."
msgstr ""

msgid "**Automatically** - After some amount of failed backups, the `site2` will usually be taken offline automatically. This is done due the configuration of `take-offline` element inside the cache configuration as configured in <<jdgsetup>>."
msgstr ""

msgid "<take-offline min-wait=\"60000\" after-failures=\"3\" />"
msgstr ""

msgid "This example shows that the site will be taken offline automatically for the particular single cache if there are at least 3 subsequent failed backups and there is no any successful backup within 60 seconds."
msgstr ""

msgid "Automatically taking a site offline is useful especially if the broken network between sites is unplanned. The disadvantage is that there will be some failed backups until the network outage is detected, which could also mean  failures on the application side. For example, there will be failed logins for some users or big login timeouts. Especially if `failure-policy` with value `FAIL` is used."
msgstr ""

msgid "The tracking of whether a site is offline is tracked separately for every cache."
msgstr ""

msgid "Take site online"
msgstr ""

msgid "Once your network is back and `site1` and `site2` can talk to each other, you may need to put the site online. This needs to be done manually through JMX or CLI in similar way as taking a site offline. Again, you may need to check all the caches and bring them online."
msgstr ""

msgid "Once the sites are put online, it's usually good to:"
msgstr ""

msgid "Do the <<statetransfer>>."
msgstr ""

msgid "Manually <<clearcache>>."
msgstr ""

msgid "State transfer"
msgstr ""

msgid "State transfer is a required, manual step. {jdgserver_name} server does not do this automatically, for example during split-brain, it is only the admin who may decide which site has preference and hence if state transfer needs to be done bidirectionally between both sites or just unidirectionally, as in only from `site1` to `site2`, but not from `site2` to `site1`."
msgstr ""

msgid "A bidirectional state transfer will ensure that entities which were created *after* split-brain on `site1` will be transferred to `site2`. This is not an issue as they do not yet exist on `site2`. Similarly, entities created *after* split-brain on `site2` will be transferred to `site1`. Possibly problematic parts are those entities which exist *before* split-brain on both sites and which were updated during split-brain on both sites. When this happens, one of the sites will *win* and will overwrite the updates done during split-brain by the second site."
msgstr ""

msgid "Unfortunately, there is no any universal solution to this. Split-brains and network outages are just state, which is usually impossible to be handled 100% correctly with 100% consistent data between sites. In the case of {project_name}, it typically is not a critical issue. In the worst case, users will need to re-login again to their clients, or have the improper count of loginFailures tracked for brute force protection. See the {jdgserver_name}/JGroups documentation for more tips how to deal with split-brain."
msgstr ""

msgid "The state transfer can be also done on the {jdgserver_name} server side through JMX. The operation name is `pushState`. There are few other operations to monitor status, cancel push state, and so on. More info about state transfer is available in the link:{jdgserver_crossdcdocs_link}[{jdgserver_name} docs]."
msgstr ""

msgid "Clear caches"
msgstr ""

msgid "After split-brain it is safe to manually clear caches in the {project_name} admin console. This is because there might be some data changed in the database on `site1` and because of the event, that the cache should be invalidated wasn't transferred during split-brain to `site2`. Hence {project_name} nodes on `site2` may still have some stale data in their caches."
msgstr ""

msgid "To clear the caches, see {adminguide_clearcache_link}[{adminguide_clearcache_name}]."
msgstr ""

msgid "When the network is back, it is sufficient to clear the cache just on one {project_name} node on any random site. The cache invalidation event will be sent to all the other {project_name} nodes in all sites. However, it needs to be done for all the caches (realms, users, keys). See link:{adminguide_clearcache_link}[{adminguide_clearcache_name}] for more information."
msgstr ""

msgid "Tuning the {jdgserver_name} cache configuration"
msgstr ""

msgid "This section contains tips and options for configuring your JDG cache."
msgstr ""

msgid "Backup failure policy"
msgstr ""

msgid "By default, the configuration of backup `failure-policy` in the Infinispan cache configuration in the {jdgserver_name} `clustered.xml` file is configured as `FAIL`. You may change it to `WARN` or `IGNORE`, as you prefer."
msgstr ""

msgid "The difference between `FAIL` and `WARN` is that when `FAIL` is used and the {jdgserver_name} server tries to back data up to the other site and the backup fails then the failure will be propagated back to the caller (the {project_name} server). The backup might fail because the second site is temporarily unreachable or there is a concurrent transaction which is trying to update same entity. In this case, the {project_name} server will then retry the operation a few times. However, if the retry fails, then the user might see the error after a longer timeout."
msgstr ""

msgid "When using `WARN`, the failed backups are not propagated from the {jdgserver_name} server to the {project_name} server. The user won't see the error and the failed backup will be just ignored. There will be a shorter timeout, typically 10 seconds as that's the default timeout for backup. It can be changed by the attribute `timeout` of `backup` element. There won't be retries. There will just be a WARNING message in the {jdgserver_name} server log."
msgstr ""

msgid "The potential issue is, that in some cases, there may be just some a short network outage between sites, where the retry (usage of the `FAIL` policy) may help, so with `WARN` (without retry), there will be some data inconsistencies across sites. This can also happen if there is an attempt to update the same entity concurrently on both sites."
msgstr ""

msgid "How bad are these inconsistencies? Usually only means that a user will need to re-authenticate."
msgstr ""

msgid "When using the `WARN` policy, it may happen that the single-use cache, which is provided by the `actionTokens` cache and which handles that particular key is really single use, but may \"successfully\" write the same key twice. But, for example, the OAuth2 specification link:https://datatracker.ietf.org/doc/html/rfc6749#section-10.5[mentions] that code must be single-use. With the `WARN` policy, this may not be strictly guaranteed and the same code could be written twice if there is an attempt to write it concurrently in both sites."
msgstr ""

msgid "If there is a longer network outage or split-brain, then with both `FAIL` and `WARN`, the other site will be taken offline after some time and failures as described in <<onoffline>>. With the default 1 minute timeout, it is usually 1-3 minutes until all the involved caches are taken offline. After that, all the operations will work fine from an end user perspective. You only need to manually restore the site when it is back online as mentioned in <<onoffline>>."
msgstr ""

msgid "In summary, if you expect frequent, longer outages between sites and it is acceptable for you to have some data inconsistencies and a not 100% accurate single-use cache, but you never want end-users to see the errors and long timeouts, then switch to `WARN`."
msgstr ""

msgid "The difference between `WARN` and `IGNORE` is, that with `IGNORE` warnings are not written in the {jdgserver_name} log. See more details in the Infinispan documentation."
msgstr ""

msgid "Lock acquisition timeout"
msgstr ""

msgid "The default configuration is using transaction in NON_DURABLE_XA mode with acquire timeout 0. This means that transaction will fail-fast if there is another transaction in progress for the same key."
msgstr ""

msgid "The reason to switch this to 0 instead of default 10 seconds was to avoid possible deadlock issues. With {project_name}, it can happen that the same entity (typically session entity or loginFailure) is updated concurrently from both sites. This can cause deadlock under some circumstances, which will cause the transaction to be blocked for 10 seconds. See link:https://issues.redhat.com/browse/JDG-1318[this JIRA report] for details."
msgstr ""

msgid "With timeout 0, the transaction will immediately fail and then will be retried from {project_name} if backup `failure-policy` with the value `FAIL` is configured. As long as the second concurrent transaction is finished, the retry will usually be successful and the entity will have applied updates from both concurrent transactions."
msgstr ""

msgid "We see very good consistency and results for concurrent transaction with this configuration, and it is recommended to keep it."
msgstr ""

msgid "The only (non-functional) problem is the exception in the {jdgserver_name} server log, which happens every time when the lock is not immediately available."
msgstr ""

msgid "SYNC or ASYNC backups"
msgstr ""

msgid "An important part of the `backup` element is the `strategy` attribute. You must decide whether it needs to be `SYNC` or `ASYNC`. We have 7 caches which might be cross-site replication aware, and these can be configured in 3 different modes regarding cross-site:"
msgstr ""

msgid "SYNC backup"
msgstr ""

msgid "ASYNC backup"
msgstr ""

msgid "No backup at all"
msgstr ""

msgid "If the `SYNC` backup is used, then the backup is synchronous and operation is considered finished on the caller ({project_name} server) side once the backup is processed on the second site. This has worse performance than `ASYNC`, but on the other hand, you are sure that subsequent reads of the particular entity, such as user session, on `site2` will see the updates from `site1`. Also, it is needed if you want data consistency. As with `ASYNC` the caller is not notified at all if backup to the other site failed."
msgstr ""

msgid "For some caches, it is even possible to not backup at all and completely skip writing data to the {jdgserver_name} server. To set this up, do not use the `remote-store` element for the particular cache on the {project_name} side (file `KEYCLOAK_HOME/standalone/configuration/standalone-ha.xml`) and then the particular `replicated-cache` element is also not needed on the {jdgserver_name} server side."
msgstr ""

msgid "By default, all 7 caches are configured with `SYNC` backup, which is the safest option. Here are a few things to consider:"
msgstr ""

msgid "If you are using active/passive mode (all {project_name} servers are in single site `site1` and the {jdgserver_name} server in `site2` is used purely as backup. See <<modes>> for more details), then it is usually fine to use `ASYNC` strategy for all the caches to save the performance."
msgstr ""

msgid "The `work` cache is used mainly to send some messages, such as cache invalidation events, to the other site. It is also used to ensure that some special events, such as userStorage synchronizations, happen only on single site. It is recommended to keep this set to `SYNC`."
msgstr ""

msgid "The `actionTokens` cache is used as single-use cache to track that some tokens/tickets were used just once. For example action tokens or OAuth2 codes. It is possible to set this to `ASYNC` to slightly improved performance, but then it is not guaranteed that particular ticket is really single-use. For example, if there is concurrent request for same ticket in both sites, then it is possible that both requests will be successful with the `ASYNC` strategy. So what you set here will depend on whether you prefer better security (`SYNC` strategy) or better performance (`ASYNC` strategy)."
msgstr ""

msgid "The `loginFailures` cache may be used in any of the 3 modes. If there is no backup at all, it means that count of login failures for a user will be counted separately for every site (See <<cache>> for details). This has some security implications, however it has some performance advantages. Also it mitigates the possible risk of denial of service (DoS) attacks. For example, if an attacker simulates 1000 concurrent requests using the username and password of the user on both sites, it will mean lots of messages being passed between the sites, which may result in network congestion. The `ASYNC` strategy might be even worse as the attacker requests won't be blocked by waiting for the backup to the other site, resulting in potentially even more congested network traffic. The count of login failures also will not be accurate with the `ASYNC` strategy."
msgstr ""

msgid "For the environments with slower network between data centers and probability of DoS, it is recommended to not backup the `loginFailures` cache at all."
msgstr ""

msgid "It is recommended to keep the `sessions` and `clientSessions` caches in `SYNC`. Switching them to `ASYNC` is possible only if you are sure that user requests and backchannel requests (requests from client applications to {project_name} as described in <<requestprocessing>>) will be always processed on same site. This is true, for example, if:"
msgstr ""

msgid "You use active/passive mode as described <<modes>>."
msgstr ""

msgid "All your client applications are using the {project_name} {adapterguide_link_js_adapter}[JavaScript Adapter]. The JavaScript adapter sends the backchannel requests within the browser and hence they participate on the browser sticky session and will end on same cluster node (hence on same site) as the other browser requests of this user."
msgstr ""

msgid "Your load balancer is able to serve the requests based on client IP address (location) and the client applications are deployed on both sites."
msgstr ""

msgid "For example you have 2 sites LON and NYC. As long as your applications are deployed in both LON and NYC sites too, you can ensure that all the user requests from London users will be redirected to the applications in LON site and also to the {project_name} servers in LON site. Backchannel requests from the LON site client deployments will end on {project_name} servers in LON site too. On the other hand, for the American users, all the {project_name} requests, application requests and backchannel requests will be processed on NYC site."
msgstr ""

msgid "For `offlineSessions` and `offlineClientSessions` it is similar, with the difference that you even don't need to backup them at all if you never plan to use offline tokens for any of your client applications."
msgstr ""

msgid "Generally, if you are in doubt and performance is not a blocker for you, it's safer to keep the caches in `SYNC` strategy."
msgstr ""

msgid "Regarding the switch to SYNC/ASYNC backup, make sure that you edit the `strategy` attribute of the `backup` element. For example like this:"
msgstr ""

msgid "<backup site=\"site2\" failure-policy=\"FAIL\" strategy=\"ASYNC\" enabled=\"true\">"
msgstr ""

msgid "Note the `mode` attribute of cache-configuration element."
msgstr ""

msgid "Troubleshooting"
msgstr ""

msgid "The following tips are intended to assist you should you need to troubleshoot:"
msgstr ""

msgid "It is recommended to go through the <<setup>> and have this one working first, so that you have some understanding of how things work. It is also wise to read this entire document to have some understanding of things."
msgstr ""

msgid "Check in jconsole cluster status (GMS) and the JGroups status (RELAY) of {jdgserver_name} as described in <<jdgsetup>>. If things do not look as expected, then the issue is likely in the setup of {jdgserver_name} servers."
msgstr ""

msgid "For the {project_name} servers, you should see a message like this during the server startup:"
msgstr ""

msgid ""
"18:09:30,156 INFO  [org.keycloak.connections.infinispan.DefaultInfinispanConnectionProviderFactory] (ServerService Thread Pool -- 54)\n"
"Node name: node11, Site name: site1"
msgstr ""

msgid "Check that the site name and the node name looks as expected during the startup of {project_name} server."
msgstr ""

msgid "Check that {project_name} servers are in cluster as expected, including that only the {project_name} servers from the same data center are in cluster with each other. This can be also checked in JConsole through the GMS view. See link:{installguide_troubleshooting_link}[cluster troubleshooting] for additional details."
msgstr ""

msgid "If there are exceptions during startup of {project_name} server like this:"
msgstr ""

msgid ""
"17:33:58,605 ERROR [org.infinispan.client.hotrod.impl.operations.RetryOnFailureOperation] (ServerService Thread Pool -- 59) ISPN004007: Exception encountered. Retry 10 out of 10: org.infinispan.client.hotrod.exceptions.TransportException:: Could not fetch transport\n"
"...\n"
"Caused by: org.infinispan.client.hotrod.exceptions.TransportException:: Could not connect to server: 127.0.0.1:12232\n"
"\tat org.infinispan.client.hotrod.impl.transport.tcp.TcpTransport.<init>(TcpTransport.java:82)\n"
msgstr ""

msgid "it usually means that {project_name} server is not able to reach the {jdgserver_name} server in his own datacenter. Make sure that firewall is set as expected and {jdgserver_name} server is possible to connect."
msgstr ""

msgid ""
"16:44:18,321 WARN  [org.infinispan.client.hotrod.impl.protocol.Codec21] (ServerService Thread Pool -- 57) ISPN004005: Error received from the server: javax.transaction.RollbackException: ARJUNA016053: Could not commit transaction.\n"
" ..."
msgstr ""

msgid "then check the log of corresponding {jdgserver_name} server of your site and check if has failed to backup to the other site. If the backup site is unavailable, then it is recommended to switch it offline, so that {jdgserver_name} server won't try to backup to the offline site causing the operations to pass successfully on {project_name} server side as well. See <<administration>> for more information."
msgstr ""

msgid "Check the Infinispan statistics, which are available through JMX. For example, try to login and then see if the new session was successfully written to both {jdgserver_name} servers and is available in the `sessions` cache there. This can be done indirectly by checking the count of elements in the `sessions` cache for the MBean `jboss.datagrid-infinispan:type=Cache,name=\"sessions(repl_sync)\",manager=\"clustered\",component=Statistics` and attribute `numberOfEntries`. After login, there should be one more entry for `numberOfEntries` on both {jdgserver_name} servers on both sites."
msgstr ""

msgid "Enable DEBUG logging as described <<serversetup>>. For example, if you log in and you think that the new session is not available on the second site, it's good to check the {project_name} server logs and check that listeners were triggered as described in the <<serversetup>>. If you do not know and want to ask on keycloak-user mailing list, it is helpful to send the log files from {project_name} servers on both datacenters in the email. Either add the log snippets to the mails or put the logs somewhere and reference them in the email."
msgstr ""

msgid "If you updated the entity, such as `user`, on {project_name} server on `site1` and you do not see that entity updated on the {project_name} server on `site2`, then the issue can be either in the replication of the synchronous database itself or that {project_name} caches are not properly invalidated. You may try to temporarily disable the {project_name} caches as described link:{installguide_disablingcaching_link}[here] to nail down if the issue is at the database replication level. Also it may help to manually connect to the database and check if data are updated as expected. This is specific to every database, so you will need to consult the documentation for your database."
msgstr ""

msgid "Sometimes you may see the exceptions related to locks like this in {jdgserver_name} server log:"
msgstr ""

msgid ""
"(HotRodServerHandler-6-35) ISPN000136: Error executing command ReplaceCommand,\n"
"writing keys [[B0x033E243034396234..[39]]: org.infinispan.util.concurrent.TimeoutException: ISPN000299: Unable to acquire lock after\n"
"0 milliseconds for key [B0x033E243034396234..[39] and requestor GlobalTx:server1:4353. Lock is held by GlobalTx:server1:4352"
msgstr ""

msgid "Those exceptions are not necessarily an issue. They may happen anytime when a concurrent edit of the same entity is triggered on both DCs. This is common in a deployment. Usually the {project_name} server is notified about the failed operation and will retry it, so from the user's point of view, there is usually not any issue."
msgstr ""

msgid "If there are exceptions during startup of {project_name} server, like this:"
msgstr ""

msgid ""
"16:44:18,321 WARN  [org.infinispan.client.hotrod.impl.protocol.Codec21] (ServerService Thread Pool -- 55) ISPN004005: Error received from the server: java.lang.SecurityException: ISPN000287: Unauthorized access: subject 'Subject with principal(s): []' lacks 'READ' permission\n"
" ..."
msgstr ""

msgid "These log entries are the result of {project_name} automatically detecting whether authentication is required on {jdgserver_name} and mean that authentication is necessary. At this point you will notice that either the server starts successfully and you can safely ignore these or that the server fails to start. If the server fails to start, ensure that {jdgserver_name} has been configured properly for authentication as described in <<jdgsetup>>. To prevent this log entry from being included, you can force authentication by setting `remoteStoreSecurityEnabled` property to `true` in `spi=connectionsInfinispan/provider=default` configuration:"
msgstr ""

msgid ""
"<subsystem xmlns=\"urn:jboss:domain:keycloak-server:1.1\">\n"
"    ...\n"
"    <spi name=\"connectionsInfinispan\">\n"
"        ...\n"
"        <provider name=\"default\" enabled=\"true\">\n"
"            <properties>\n"
"                ...\n"
"                <property name=\"remoteStoreSecurityEnabled\" value=\"true\"/>\n"
"            </properties>\n"
"        </provider>\n"
"    </spi>"
msgstr ""

msgid "If you try to authenticate with {project_name} to your application, but authentication fails with an infinite number of redirects in your browser and you see the errors like this in the {project_name} server log:"
msgstr ""

msgid "2017-11-27 14:50:31,587 WARN  [org.keycloak.events] (default task-17) type=LOGIN_ERROR, realmId=master, clientId=null, userId=null, ipAddress=aa.bb.cc.dd, error=expired_code, restart_after_timeout=true"
msgstr ""

msgid "it probably means that your load balancer needs to be set to support sticky sessions. Make sure that the provided route name used during startup of {project_name} server (Property `jboss.node.name`) contains the correct name used by the load balancer server to identify the current server."
msgstr ""

msgid "If the {jdgserver_name} `work` cache grows indefinitely, you may be experiencing https://issues.redhat.com/browse/JDG-987[this {jdgserver_name} issue], which is caused by cache items not being properly expired. In that case, update the cache declaration with an empty `<expiration />` tag like this:"
msgstr ""

msgid ""
"    <replicated-cache name=\"work\" configuration=\"sessions-cfg\">\n"
"        <expiration />\n"
"    </replicated-cache>"
msgstr ""

msgid "If you see Warnings in the {jdgserver_name} server log like:"
msgstr ""

msgid ""
"18:06:19,687 WARN  [org.infinispan.server.hotrod.Decoder2x] (HotRod-ServerWorker-7-12) ISPN006011: Operation 'PUT_IF_ABSENT' forced to\n"
"  return previous value should be used on transactional caches, otherwise data inconsistency issues could arise under failure situations\n"
"18:06:19,700 WARN  [org.infinispan.server.hotrod.Decoder2x] (HotRod-ServerWorker-7-10) ISPN006010: Conditional operation 'REPLACE_IF_UNMODIFIED' should\n"
"  be used with transactional caches, otherwise data inconsistency issues could arise under failure situations"
msgstr ""

msgid "you can just ignore them. To avoid the warning, the caches on {jdgserver_name} server side could be changed to transactional caches, but this is not recommended as it can cause some other issues caused by the bug https://issues.redhat.com/browse/ISPN-9323. So for now, the warnings just need to be ignored."
msgstr ""

msgid "If you see errors in the {jdgserver_name} server log like:"
msgstr ""

msgid ""
"12:08:32,921 ERROR [org.infinispan.server.hotrod.CacheDecodeContext] (HotRod-ServerWorker-7-11) ISPN005003: Exception reported: org.infinispan.server.hotrod.InvalidMagicIdException: Error reading magic byte or message id: 7\n"
"\tat org.infinispan.server.hotrod.HotRodDecoder.readHeader(HotRodDecoder.java:184)\n"
"\tat org.infinispan.server.hotrod.HotRodDecoder.decodeHeader(HotRodDecoder.java:133)\n"
"\tat org.infinispan.server.hotrod.HotRodDecoder.decode(HotRodDecoder.java:92)\n"
"\tat io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:411)\n"
"\tat io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:248)"
msgstr ""

msgid "and you see some similar errors in the {project_name} log, it can indicate that there are incompatible versions of the Hot Rod protocol being used. This is likely happen when you try to use {project_name} with an old version of the Infinispan server. It will help if you add the `protocolVersion` property as an additional property to the `remote-store` element in the {project_name} configuration file. For example:"
msgstr ""

msgid "<property name=\"protocolVersion\">2.6</property>"
msgstr ""

msgid "Managing the subsystem configuration"
msgstr ""

msgid "Low-level configuration of {project_name} is done by editing the  `standalone.xml`, `standalone-ha.xml`, or `domain.xml` file in your distribution.  The location of this file depends on your <<_operating-mode, operating mode>>."
msgstr ""

msgid "While there are endless settings you can configure here, this section will focus on configuration of the _keycloak-server_ subsystem.  No matter which configuration file you are using, configuration of the _keycloak-server_ subsystem is the same."
msgstr ""

msgid "The keycloak-server subsystem is typically declared toward the end of the file like this:"
msgstr ""

msgid ""
"<subsystem xmlns=\"urn:jboss:domain:keycloak-server:1.1\">\n"
"   <web-context>auth</web-context>\n"
"   ...\n"
"</subsystem>"
msgstr ""

msgid "Note that anything changed in this subsystem will not take effect until the server is rebooted."
msgstr ""

msgid "Configure SPI providers"
msgstr ""

msgid "The specifics of each configuration setting is discussed elsewhere in context with that setting.  However, it is useful to understand the format used to declare settings on SPI providers."
msgstr ""

msgid "{project_name} is a highly modular system that allows great flexibility.  There are more than 50 service provider interfaces (SPIs), and you are allowed to swap out implementations of each SPI.  An implementation of an SPI is known as a _provider_."
msgstr ""

msgid "All elements in an SPI declaration are optional, but a full SPI declaration  looks like this:"
msgstr ""

msgid ""
"<spi name=\"myspi\">\n"
"    <default-provider>myprovider</default-provider>\n"
"    <provider name=\"myprovider\" enabled=\"true\">\n"
"        <properties>\n"
"            <property name=\"foo\" value=\"bar\"/>\n"
"        </properties>\n"
"    </provider>\n"
"    <provider name=\"mysecondprovider\" enabled=\"true\">\n"
"        <properties>\n"
"            <property name=\"foo\" value=\"foo\"/>\n"
"        </properties>\n"
"    </provider>\n"
"</spi>"
msgstr ""

msgid "Here we have two providers defined for the SPI `myspi`.  The `default-provider` is listed as `myprovider`.  However it is up to the SPI to decide how it will treat this setting.  Some SPIs allow more than one provider and some do not.  So `default-provider` can help the SPI to choose."
msgstr ""

msgid "Also notice that each provider defines its own set of configuration properties. The fact that both providers above have a property called `foo` is just a coincidence."
msgstr ""

msgid "The type of each property value is interpreted by the provider.  However, there is one exception.  Consider the `jpa` provider for the `eventsStore` SPI:"
msgstr ""

msgid ""
"<spi name=\"eventsStore\">\n"
"    <provider name=\"jpa\" enabled=\"true\">\n"
"        <properties>\n"
"            <property name=\"exclude-events\" value=\"[&quot;EVENT1&quot;,\n"
"                                                    &quot;EVENT2&quot;]\"/>\n"
"        </properties>\n"
"    </provider>\n"
"</spi>"
msgstr ""

msgid "We see that the value begins and ends with square brackets.  That means that the value will be passed to the provider as a list.  In this example, the system will pass the provider a list with two element values _EVENT1_ and _EVENT2_. To add more values to the list, just separate each list element with a comma. Unfortunately, you do need to escape the quotes surrounding each list element with `\\&quot;`."
msgstr ""

msgid "Follow the steps in link:{developerguide_link}#_providers[{developerguide_name}] for more details on custom providers and the configuration of providers."
msgstr ""

msgid "Starting the {appserver_name} CLI"
msgstr ""

msgid "Besides editing the configuration by hand, you also have the option of changing the configuration by issuing commands via the _jboss-cli_ tool.  CLI allows you to configure servers locally or remotely.  And it is especially useful when combined with scripting."
msgstr ""

msgid "To start the {appserver_name} CLI, you need to run `jboss-cli`."
msgstr ""

msgid "$ .../bin/jboss-cli.sh"
msgstr ""

msgid "> ...\\bin\\jboss-cli.bat"
msgstr ""

msgid "This will bring you to a prompt like this:"
msgstr ""

msgid "Prompt"
msgstr ""

msgid "[disconnected /]"
msgstr ""

msgid "If you wish to execute commands on a running server, you will first execute the `connect` command."
msgstr ""

msgid "connect"
msgstr ""

msgid ""
"[disconnected /] connect\n"
"connect\n"
"[standalone@localhost:9990 /]"
msgstr ""

msgid "You may be thinking to yourself, \"I didn't enter in any username or password!\".  If you run `jboss-cli` on the same machine as your running standalone server or domain controller and your account has appropriate file permissions, you do not have to setup or enter in an admin username and password.  See the link:{appserver_admindoc_link}[_{appserver_admindoc_name}_] for more details on how to make things more secure if you are uncomfortable with that setup."
msgstr ""

msgid "CLI embedded mode"
msgstr ""

msgid "If you do happen to be on the same machine as your standalone server and you want to issue commands while the server is not active, you can embed the server into CLI and make changes in a special mode that disallows incoming requests.  To do this, first execute the `embed-server` command with the config file you wish to change."
msgstr ""

msgid "embed-server"
msgstr ""

msgid ""
"[disconnected /] embed-server --server-config=standalone.xml\n"
"[standalone@embedded /]"
msgstr ""

msgid "Using CLI GUI mode"
msgstr ""

msgid "The CLI can also run in GUI mode.  GUI mode launches a Swing application that allows you to graphically view and edit the entire management model of a _running_ server. GUI mode is especially useful when you need help formatting your CLI commands and learning about the options available.  The GUI can also retrieve server logs from a local or remote server."
msgstr ""

msgid "Start the CLI in GUI mode"
msgstr ""

msgid "$ .../bin/jboss-cli.sh --gui"
msgstr ""

msgid "Note: to connect to a remote server, you pass the `--connect` option as well. Use the --help option for more details."
msgstr ""

msgid "Scroll down to find the node `subsystem=keycloak-server`."
msgstr ""

msgid "Right-click the node and select `Explore subsystem=keycloak-server`."
msgstr ""

msgid "A new tab displays only the keycloak-server subsystem."
msgstr ""

msgid "keycloak-server subsystem"
msgstr ""

msgid "image:images/cli-gui.png[keycloak-server subsystem]"
msgstr ""

msgid "CLI scripting"
msgstr ""

msgid "The CLI has extensive scripting capabilities.  A script is just a text file with CLI commands in it.  Consider a simple script that turns off theme and template caching."
msgstr ""

msgid "turn-off-caching.cli"
msgstr ""

msgid ""
"/subsystem=keycloak-server/theme=defaults/:write-attribute(name=cacheThemes,value=false)\n"
"/subsystem=keycloak-server/theme=defaults/:write-attribute(name=cacheTemplates,value=false)"
msgstr ""

msgid "To execute the script, you can follow the `Scripts` menu in CLI GUI, or execute the script from the command line as follows:"
msgstr ""

msgid "$ .../bin/jboss-cli.sh --file=turn-off-caching.cli"
msgstr ""

msgid "CLI recipes"
msgstr ""

msgid "Here are some configuration tasks and how to perform them with CLI commands. Note that in all but the first example, we use the wildcard path `**` to mean you should substitute or the path to the keycloak-server subsystem."
msgstr ""

msgid "For standalone, this just means:"
msgstr ""

msgid "`**` = `/subsystem=keycloak-server`"
msgstr ""

msgid "For domain mode, this would mean something like:"
msgstr ""

msgid "`**` = `/profile=auth-server-clustered/subsystem=keycloak-server`"
msgstr ""

msgid "Changing the web context of the server"
msgstr ""

msgid "/subsystem=keycloak-server/:write-attribute(name=web-context,value=myContext)"
msgstr ""

msgid "Setting the global default theme"
msgstr ""

msgid "**/theme=defaults/:write-attribute(name=default,value=myTheme)"
msgstr ""

msgid "Adding a new SPI and a provider"
msgstr ""

msgid ""
"**/spi=mySPI/:add\n"
"**/spi=mySPI/provider=myProvider/:add(enabled=true)"
msgstr ""

msgid "Disabling a provider"
msgstr ""

msgid "**/spi=mySPI/provider=myProvider/:write-attribute(name=enabled,value=false)"
msgstr ""

msgid "Changing the default provider for an SPI"
msgstr ""

msgid "**/spi=mySPI/:write-attribute(name=default-provider,value=myProvider)"
msgstr ""

msgid "Configuring the dblock SPI"
msgstr ""

msgid ""
"**/spi=dblock/:add(default-provider=jpa)\n"
"**/spi=dblock/provider=jpa/:add(properties={lockWaitTimeout => \"900\"},enabled=true)"
msgstr ""

msgid "Adding or changing a single property value for a provider"
msgstr ""

msgid "**/spi=dblock/provider=jpa/:map-put(name=properties,key=lockWaitTimeout,value=3)"
msgstr ""

msgid "Remove a single property from a provider"
msgstr ""

msgid "**/spi=dblock/provider=jpa/:map-remove(name=properties,key=lockRecheckTime)"
msgstr ""

msgid "Setting values on a provider property of type `List`"
msgstr ""

msgid "**/spi=eventsStore/provider=jpa/:map-put(name=properties,key=exclude-events,value=[EVENT1,EVENT2])"
msgstr ""

msgid "Profiles"
msgstr ""

msgid "There are features in {project_name} that are not enabled by default, these include features that are not fully supported. In addition there are some features that are enabled by default, but that can be disabled."
msgstr ""

msgid "The features that can be enabled and disabled are:"
msgstr ""

msgid "Name"
msgstr ""

msgid "Description"
msgstr ""

msgid "Enabled by default"
msgstr ""

msgid "Support level"
msgstr ""

msgid "account2"
msgstr ""

msgid "New Account Management Console"
msgstr ""

msgid "Yes"
msgstr ""

msgid "Supported"
msgstr ""

msgid "account_api"
msgstr ""

msgid "Account Management REST API"
msgstr ""

msgid "admin_fine_grained_authz"
msgstr ""

msgid "Fine-Grained Admin Permissions"
msgstr ""

msgid "No"
msgstr ""

msgid "Preview"
msgstr ""

msgid "ciba"
msgstr ""

msgid "OpenID Connect Client Initiated Backchannel Authentication (CIBA)"
msgstr ""

msgid "client_policies"
msgstr ""

msgid "Add client configuration policies"
msgstr ""

msgid "par"
msgstr ""

msgid "OAuth 2.0 Pushed Authorization Requests (PAR)"
msgstr ""

msgid "declarative_user_profile"
msgstr ""

msgid "Configure user profiles using a declarative style"
msgstr ""

msgid "docker"
msgstr ""

msgid "Docker Registry protocol"
msgstr ""

msgid "impersonation"
msgstr ""

msgid "Ability for admins to impersonate users"
msgstr ""

msgid "openshift_integration"
msgstr ""

msgid "Extension to enable securing OpenShift"
msgstr ""

msgid "scripts"
msgstr ""

msgid "Write custom authenticators using JavaScript"
msgstr ""

msgid "token_exchange"
msgstr ""

msgid "Token Exchange Service"
msgstr ""

msgid "upload_scripts"
msgstr ""

msgid "Upload scripts"
msgstr ""

msgid "Deprecated"
msgstr ""

msgid "web_authn"
msgstr ""

msgid "W3C Web Authentication (WebAuthn)"
msgstr ""

msgid "To enable all preview features start the server with:"
msgstr ""

msgid "bin/standalone.sh|bat -Dkeycloak.profile=preview"
msgstr ""

msgid "You can set this permanently by creating the file `standalone/configuration/profile.properties` (or `domain/servers/server-one/configuration/profile.properties` for `server-one` in domain mode). Add the following to the file:"
msgstr ""

msgid "profile=preview"
msgstr ""

msgid "To enable a specific feature start the server with:"
msgstr ""

msgid "bin/standalone.sh|bat -Dkeycloak.profile.feature.<feature name>=enabled"
msgstr ""

msgid "For example to enable Docker use `-Dkeycloak.profile.feature.docker=enabled`."
msgstr ""

msgid "You can set this permanently in the `profile.properties` file by adding:"
msgstr ""

msgid "feature.docker=enabled"
msgstr ""

msgid "To disable a specific feature start the server with:"
msgstr ""

msgid "bin/standalone.sh|bat -Dkeycloak.profile.feature.<feature name>=disabled"
msgstr ""

msgid "For example to disable Impersonation use `-Dkeycloak.profile.feature.impersonation=disabled`."
msgstr ""

msgid "feature.impersonation=disabled"
msgstr ""

msgid "Setting up the relational database"
msgstr ""

msgid "{project_name} comes with its own embedded Java-based relational database called H2. This is the default database that {project_name} will use to persist data and really only exists so that you can run the authentication server out of the box.  We highly recommend that you replace it with a more production ready external database.  The H2 database is not very viable in high concurrency situations and should not be used in a cluster either.  The purpose of this chapter is to show you how to connect {project_name} to a more mature database."
msgstr ""

msgid "{project_name} uses two layered technologies to persist its relational data.  The bottom layered technology is JDBC.  JDBC is a Java API that is used to connect to a RDBMS.  There are different JDBC drivers per database type that are provided by your database vendor.  This chapter discusses how to configure {project_name} to use one of these vendor-specific drivers."
msgstr ""

msgid "The top layered technology for persistence is Hibernate JPA.  This is an object to relational mapping API that maps Java Objects to relational data.  Most deployments of {project_name} will never have to touch the configuration aspects of Hibernate, but we will discuss how that is done if you run into that rare circumstance."
msgstr ""

msgid "Datasource configuration is covered much more thoroughly in link:{appserver_datasource_link}[the datasource configuration chapter]        in the _{appserver_admindoc_name}_."
msgstr ""

msgid "Database setup checklist"
msgstr ""

msgid "Following are the steps you perform to get an RDBMS configured for {project_name}."
msgstr ""

msgid "Locate and download a JDBC driver for your database"
msgstr ""

msgid "Package the driver JAR into a module and install this module into the server"
msgstr ""

msgid "Declare the JDBC driver in the configuration profile of the server"
msgstr ""

msgid "Modify the datasource configuration to use your database's JDBC driver"
msgstr ""

msgid "Modify the datasource configuration to define the connection parameters to your database"
msgstr ""

msgid "This chapter will use PostgresSQL for all its examples.  Other databases follow the same steps for installation."
msgstr ""

msgid "Packaging the JDBC driver"
msgstr ""

msgid "Find and download the JDBC driver JAR for your RDBMS. Before you can use this driver, you must package it up into a module and install it into the server. Modules define JARs that are loaded into the {project_name} classpath and the dependencies those JARs have on other modules."
msgstr ""

msgid "Create a directory structure to hold your module definition within the _.../modules/_ directory of your {project_name} distribution."
msgstr ""

msgid "The convention is use the Java package name of the JDBC driver for the name of the directory structure. For PostgreSQL, create the directory _org/postgresql/main_."
msgstr ""

msgid "Copy your database driver JAR into this directory and create an empty _module.xml_ file within it too."
msgstr ""

msgid "Module Directory"
msgstr ""

msgid "image:{project_images}/db-module.png[Module Directory]"
msgstr ""

msgid "Open up the _module.xml_ file and create the following XML:"
msgstr ""

msgid "Module XML"
msgstr ""

msgid ""
"<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n"
"<module xmlns=\"urn:jboss:module:1.3\" name=\"org.postgresql\">\n"
"\n"
"    <resources>\n"
"        <resource-root path=\"postgresql-VERSION.jar\"/>\n"
"    </resources>\n"
"\n"
"    <dependencies>\n"
"        <module name=\"javax.api\"/>\n"
"        <module name=\"javax.transaction.api\"/>\n"
"    </dependencies>\n"
"</module>"
msgstr ""

msgid "The module name should match the directory structure of your module. So, _org/postgresql_ maps to `org.postgresql`."
msgstr ""

msgid "The `resource-root path` attribute should specify the JAR filename of the driver."
msgstr ""

msgid "The rest are just the normal dependencies that any JDBC driver JAR would have."
msgstr ""

msgid "Declaring and loading the JDBC driver"
msgstr ""

msgid "You declare your JDBC into your deployment profile so that it loads and becomes available when the server boots up."
msgstr ""

msgid "You have packaged the JDBC driver."
msgstr ""

msgid "Declare your JDBC driver by editing one of these files based on your deployment mode:"
msgstr ""

msgid "For standard mode, edit _.../standalone/configuration/standalone.xml_."
msgstr ""

msgid "For standard clustering mode, edit _.../standalone/configuration/standalone-ha.xml_."
msgstr ""

msgid "For domain mode, edit _.../domain/configuration/domain.xml_."
msgstr ""

msgid "In domain mode, make sure you edit the profile you are using: either `auth-server-standalone` or `auth-server-clustered`"
msgstr ""

msgid "Within the profile, search for the `drivers` XML block within the `datasources` subsystem."
msgstr ""

msgid "You should see a pre-defined driver declared for the H2 JDBC driver. This is where you'll declare the JDBC driver for your external database."
msgstr ""

msgid "JDBC Drivers"
msgstr ""

msgid ""
"  <subsystem xmlns=\"{subsystem_datasources_xml_urn}\">\n"
"     <datasources>\n"
"       ...\n"
"       <drivers>\n"
"          <driver name=\"h2\" module=\"com.h2database.h2\">\n"
"              <xa-datasource-class>org.h2.jdbcx.JdbcDataSource</xa-datasource-class>\n"
"          </driver>\n"
"       </drivers>\n"
"     </datasources>\n"
"  </subsystem>"
msgstr ""

msgid "Within the `drivers` XML block, declare an additional JDBC driver."
msgstr ""

msgid "Assign any `name` to this driver."
msgstr ""

msgid "Specify the `module` attribute which points to the `module` package that you created earlier for the driver JAR."
msgstr ""

msgid "Specify the driver's Java class."
msgstr ""

msgid "Here's an example of installing a PostgreSQL driver that lives in the module example defined earlier in this chapter."
msgstr ""

msgid "Declare Your JDBC Drivers"
msgstr ""

msgid ""
"  <subsystem xmlns=\"{subsystem_datasources_xml_urn}\">\n"
"     <datasources>\n"
"       ...\n"
"       <drivers>\n"
"          <driver name=\"postgresql\" module=\"org.postgresql\">\n"
"              <xa-datasource-class>org.postgresql.xa.PGXADataSource</xa-datasource-class>\n"
"          </driver>\n"
"          <driver name=\"h2\" module=\"com.h2database.h2\">\n"
"              <xa-datasource-class>org.h2.jdbcx.JdbcDataSource</xa-datasource-class>\n"
"          </driver>\n"
"       </drivers>\n"
"     </datasources>\n"
"  </subsystem>"
msgstr ""

msgid "Modifying the {project_name} datasource"
msgstr ""

msgid "You modify the existing datasource configuration that {project_name} uses to connect it to your new external database.  You'll do this within the same configuration file and XML block that you registered your JDBC driver in.  Here's an example that sets up the connection to your new database:"
msgstr ""

msgid ""
"  <subsystem xmlns=\"{subsystem_datasources_xml_urn}\">\n"
"     <datasources>\n"
"       ...\n"
"       <datasource jndi-name=\"java:jboss/datasources/KeycloakDS\" pool-name=\"KeycloakDS\" enabled=\"true\" use-java-context=\"true\">\n"
"           <connection-url>jdbc:postgresql://localhost/keycloak</connection-url>\n"
"           <driver>postgresql</driver>\n"
"           <pool>\n"
"               <max-pool-size>20</max-pool-size>\n"
"           </pool>\n"
"           <security>\n"
"               <user-name>William</user-name>\n"
"               <password>password</password>\n"
"           </security>\n"
"       </datasource>\n"
"        ...\n"
"     </datasources>\n"
"  </subsystem>"
msgstr ""

msgid "You have already declared your JDBC driver."
msgstr ""

msgid "Search for the `datasource` definition for `KeycloakDS`."
msgstr ""

msgid "You'll first need to modify the `connection-url`.  The documentation for your vendor's JDBC implementation should specify the format for this connection URL value."
msgstr ""

msgid "Define the `driver` you will use."
msgstr ""

msgid "This is the logical name of the JDBC driver you declared in the previous section of this chapter."
msgstr ""

msgid "It is expensive to open a new connection to a database every time you want to perform a transaction.  To compensate, the datasource implementation maintains a pool of open connections.  The `max-pool-size` specifies the maximum number of connections it will pool. You may want to change the value of this depending on the load of your system."
msgstr ""

msgid "Define the database username and password that is needed to connect to the database.  This step is necessary for at least PostgreSQL. You may be concerned that these credentials are in clear text in the example. Methods exist to obfuscate these credentials, but these methods are beyond the scope of this guide."
msgstr ""

msgid "For more information about datasource features, see link:{appserver_datasource_link}[the datasource configuration chapter] in the _{appserver_admindoc_name}_."
msgstr ""

msgid "Database Configuration"
msgstr ""

msgid "The configuration for this component is found in the `standalone.xml`, `standalone-ha.xml`, or `domain.xml` file in your distribution. The location of this file depends on your <<_operating-mode, operating mode>>."
msgstr ""

msgid "Database Config"
msgstr ""

msgid ""
"<subsystem xmlns=\"urn:jboss:domain:keycloak-server:1.1\">\n"
"    ...\n"
"    <spi name=\"connectionsJpa\">\n"
"     <provider name=\"default\" enabled=\"true\">\n"
"         <properties>\n"
"             <property name=\"dataSource\" value=\"java:jboss/datasources/KeycloakDS\"/>\n"
"             <property name=\"initializeEmpty\" value=\"false\"/>\n"
"             <property name=\"migrationStrategy\" value=\"manual\"/>\n"
"             <property name=\"migrationExport\" value=\"${jboss.home.dir}/keycloak-database-update.sql\"/>\n"
"         </properties>\n"
"     </provider>\n"
"    </spi>\n"
"    ...\n"
"</subsystem>"
msgstr ""

msgid "Possible configuration options are:"
msgstr ""

msgid "dataSource"
msgstr ""

msgid "JNDI name of the dataSource"
msgstr ""

msgid "jta"
msgstr ""

msgid "boolean property to specify if datasource is JTA capable"
msgstr ""

msgid "driverDialect"
msgstr ""

msgid "Value of database dialect. In most cases you don't need to specify this property as dialect will be autodetected by Hibernate."
msgstr ""

msgid "initializeEmpty"
msgstr ""

msgid "Initialize database if empty. If set to false the database has to be manually initialized. If you want to manually initialize the database set migrationStrategy to `manual` which will create a file with SQL commands to initialize the database. Defaults to true."
msgstr ""

msgid "migrationStrategy"
msgstr ""

msgid "Strategy to use to migrate database. Valid values are `update`, `manual` and `validate`. Update will automatically migrate the database schema. Manual will export the required changes to a file with SQL commands that you can manually execute on the database. Validate will simply check if the database is up-to-date."
msgstr ""

msgid "migrationExport"
msgstr ""

msgid "Path for where to write manual database initialization/migration file."
msgstr ""

msgid "showSql"
msgstr ""

msgid "Specify whether Hibernate should show all SQL commands in the console (false by default).  This is very verbose!"
msgstr ""

msgid "formatSql"
msgstr ""

msgid "Specify whether Hibernate should format SQL commands (true by default)"
msgstr ""

msgid "globalStatsInterval"
msgstr ""

msgid "Will log global statistics from Hibernate about executed DB queries and other things. Statistics are always reported to server log at specified interval (in seconds) and are cleared after each report."
msgstr ""

msgid "schema"
msgstr ""

msgid "Specify the database schema to use"
msgstr ""

msgid "These configuration switches and more are described in the link:{appserver_jpa_link}[_{appserver_jpa_name}_]."
msgstr ""

msgid "Unicode considerations for databases"
msgstr ""

msgid "Database schema in {project_name} only accounts for Unicode strings in the following special fields:"
msgstr ""

msgid "Realms: display name, HTML display name, localization texts (keys and values)"
msgstr ""

msgid "Federation Providers: display name"
msgstr ""

msgid "Users: username, given name, last name, attribute names and values"
msgstr ""

msgid "Groups: name, attribute names and values"
msgstr ""

msgid "Roles: name"
msgstr ""

msgid "Descriptions of objects"
msgstr ""

msgid "Otherwise, characters are limited to those contained in database encoding which is often 8-bit. However, for some database systems, it is possible to enable UTF-8 encoding of Unicode characters and use full Unicode character set in all text fields. Often, this is counterbalanced by shorter maximum length of the strings than in case of 8-bit encodings."
msgstr ""

msgid "Some of the databases require special settings to database and/or JDBC driver to be able to handle Unicode characters. Please find the settings for your database below. Note that if a database is listed here, it can still work properly provided it handles UTF-8 encoding properly both on the level of database and JDBC driver."
msgstr ""

msgid "Technically, the key criterion for Unicode support for all fields is whether the database allows setting of Unicode character set for `VARCHAR` and `CHAR` fields. If yes, there is a high chance that Unicode will be plausible, usually at the expense of field length. If it only supports Unicode in `NVARCHAR` and `NCHAR` fields, Unicode support for all text fields is unlikely as Keycloak schema uses `VARCHAR` and `CHAR` fields extensively."
msgstr ""

msgid "Oracle database"
msgstr ""

msgid "Unicode characters are properly handled provided the database was created with Unicode support in `VARCHAR` and `CHAR` fields (e.g. by using `AL32UTF8` character set as the database character set). No special settings is needed for JDBC driver."
msgstr ""

msgid "If the database character set is not Unicode, then to use Unicode characters in the special fields, the JDBC driver needs to be configured with the connection property `oracle.jdbc.defaultNChar` set to `true`. It might be wise, though not strictly necessary, to also set the `oracle.jdbc.convertNcharLiterals` connection property to `true`. These properties can be set either as system properties or as connection properties. Please note that setting `oracle.jdbc.defaultNChar` may have negative impact on performance. For details, please refer to Oracle JDBC driver configuration documentation."
msgstr ""

msgid "Microsoft SQL Server database"
msgstr ""

msgid "Unicode characters are properly handled only for the special fields. No special settings of JDBC driver or database is necessary."
msgstr ""

msgid "MySQL database"
msgstr ""

msgid "Unicode characters are properly handled provided the database was created with Unicode support in `VARCHAR` and `CHAR` fields in the `CREATE DATABASE` command (e.g. by using `utf8` character set as the default database character set in MySQL 5.5. Please note that `utf8mb4` character set does not work due to different storage requirements to `utf8` character set footnote:[Tracked as https://issues.redhat.com/browse/KEYCLOAK-3873]). Note that in this case, length restriction to non-special fields does not apply because columns are created to accommodate given amount of characters, not bytes. If the database default character set does not allow storing Unicode, only the special fields allow storing Unicode values."
msgstr ""

msgid "At the side of JDBC driver settings, it is necessary to add a connection property `characterEncoding=UTF-8` to the JDBC connection settings."
msgstr ""

msgid "PostgreSQL database"
msgstr ""

msgid "Unicode is supported when the database character set is `UTF8`. In that case, Unicode characters can be used in any field, there is no reduction of field length for non-special fields. No special settings of JDBC driver is necessary."
msgstr ""

msgid "The character set of a PostgreSQL database is determined at the time it is created. You can determine the default character set for a PostgreSQL cluster with the SQL command"
msgstr ""

msgid "show server_encoding;"
msgstr ""

msgid "If the default character set is not UTF 8, then you can create the database with UTF8 as its character set like this:"
msgstr ""

msgid "create database keycloak with encoding 'UTF8';"
msgstr ""

msgid "Use of the public hostname"
msgstr ""

msgid "{project_name} uses the public hostname for a number of things. For example, in the token issuer fields and URLs sent in password reset emails."
msgstr ""

msgid "The Hostname SPI provides a way to configure the hostname for a request. The default provider allows setting a fixed URL for frontend requests, while allowing backend requests to be based on the request URI. It is also possible to develop your own provider in the case the built-in provider does not provide the functionality needed."
msgstr ""

msgid "Default provider"
msgstr ""

msgid "The default hostname provider uses the configured `frontendUrl` as the base URL for frontend requests (requests from user-agents) and uses the request URL as the basis for backend requests (direct requests from clients)."
msgstr ""

msgid "Frontend request do not have to have the same context-path as the Keycloak server. This means you can expose Keycloak on for example `https://auth.example.org` or `https://example.org/keycloak` while internally its URL could be `https://10.0.0.10:8080/auth`."
msgstr ""

msgid "This makes it possible to have user-agents (browsers) send requests to {project_name} through the public domain name, while internal clients can use an internal domain name or IP address."
msgstr ""

msgid "This is reflected in the OpenID Connect Discovery endpoint for example where the `authorization_endpoint` uses the frontend URL, while `token_endpoint` uses the backend URL. As a note here a public client for instance would contact Keycloak through the public endpoint, which would result in the base of `authorization_endpoint` and `token_endpoint` being the same."
msgstr ""

msgid "To set the frontendUrl for Keycloak you can either pass add `-Dkeycloak.frontendUrl=https://auth.example.org` to the startup or you can configure it in `standalone.xml`. See the example below:"
msgstr ""

msgid ""
"<spi name=\"hostname\">\n"
"    <default-provider>default</default-provider>\n"
"    <provider name=\"default\" enabled=\"true\">\n"
"        <properties>\n"
"            <property name=\"frontendUrl\" value=\"https://auth.example.com\"/>\n"
"            <property name=\"forceBackendUrlToFrontendUrl\" value=\"false\"/>\n"
"        </properties>\n"
"    </provider>\n"
"</spi>"
msgstr ""

msgid "To update the `frontendUrl` with jboss-cli use the following command:"
msgstr ""

msgid "/subsystem=keycloak-server/spi=hostname/provider=default:write-attribute(name=properties.frontendUrl,value=\"https://auth.example.com\")"
msgstr ""

msgid "If you want all requests to go through the public domain name you can force backend requests to use the frontend URL as well by setting `forceBackendUrlToFrontendUrl` to `true`."
msgstr ""

msgid "It is also possible to override the default frontend URL for individual realms. This can be done in the admin console."
msgstr ""

msgid "If you do not want to expose the admin endpoints and console on the public domain use the property `adminUrl` to set a fixed URL for the admin console, which is different to the `frontendUrl`. It is also required to block access to `/auth/admin` externally, for details on how to do that refer to the link:{adminguide_link}[{adminguide_name}]."
msgstr ""

msgid "Custom provider"
msgstr ""

msgid "To develop a custom hostname provider you need to implement `org.keycloak.urls.HostnameProviderFactory` and `org.keycloak.urls.HostnameProvider`."
msgstr ""

msgid "Follow the instructions in the Service Provider Interfaces section in link:{developerguide_link}[{developerguide_name}] for more information on how to develop a custom provider."
msgstr ""

msgid "Setting up the network"
msgstr ""

msgid "The default installation of {project_name} can run with some networking limitations.  For one, all network endpoints bind to `localhost` so the auth server is really only usable on one local machine.  For HTTP based connections, it does not use default ports like 80 and 443.  HTTPS/SSL is not configured out of the box and without it, {project_name} has many security vulnerabilities. Finally, {project_name} may often need to make secure SSL and HTTPS connections to external servers and thus need a trust store set up so that endpoints can be validated correctly.  This chapter discusses all of these things."
msgstr ""

msgid "Bind addresses"
msgstr ""

msgid "By default {project_name} binds to the localhost loopback address `127.0.0.1`.  That's not a very useful default if you want the authentication server available on your network.  Generally, what we recommend is that you deploy a reverse proxy or load balancer on a public network and route traffic to individual {project_name} server instances on a private network. In either case though, you still need to set up your network interfaces to bind to something other than `localhost`."
msgstr ""

msgid "Setting the bind address is quite easy and can be done on the command line with either the _standalone.sh_ or _domain.sh_ boot scripts discussed in the <<_operating-mode, Choosing an Operating Mode>> chapter."
msgstr ""

msgid "$ standalone.sh -b 192.168.0.5"
msgstr ""

msgid "The `-b` switch sets the IP bind address for any public interfaces."
msgstr ""

msgid "Alternatively, if you don't want to set the bind address at the command line, you can edit the profile configuration of your deployment. Open up the profile configuration file (_standalone.xml_ or _domain.xml_ depending on your <<_operating-mode, operating mode>>) and look for the `interfaces` XML block."
msgstr ""

msgid ""
"    <interfaces>\n"
"        <interface name=\"management\">\n"
"            <inet-address value=\"${jboss.bind.address.management:127.0.0.1}\"/>\n"
"        </interface>\n"
"        <interface name=\"public\">\n"
"            <inet-address value=\"${jboss.bind.address:127.0.0.1}\"/>\n"
"        </interface>\n"
"    </interfaces>"
msgstr ""

msgid "The `public` interface corresponds to subsystems creating sockets that are available publicly.  An example of one of these subsystems is the web layer which serves up the authentication endpoints of {project_name}.  The `management` interface corresponds to sockets opened up by the management layer of the {appserver_name}.  Specifically the sockets which allow you to use the `jboss-cli.sh` command line interface and the {appserver_name} web console."
msgstr ""

msgid "In looking at the `public` interface you see that it has a special string `${jboss.bind.address:127.0.0.1}`.  This string denotes a value `127.0.0.1` that can be overridden on the command line by setting a Java system property, i.e.:"
msgstr ""

msgid "$ domain.sh -Djboss.bind.address=192.168.0.5"
msgstr ""

msgid "The `-b` is just a shorthand notation for this command.  So, you can either change the bind address value directly in the profile config, or change it on the command line when you boot up."
msgstr ""

msgid "There are many more options available when setting up `interface` definitions. For more information, see link:{appserver_network_link}[the network interface] in the _{appserver_network_name}_."
msgstr ""

msgid "Socket port bindings"
msgstr ""

msgid "The ports opened for each socket have a pre-defined default that can be overridden at the command line or within configuration. To illustrate this configuration, let's pretend you are running in <<_standalone-mode,standalone mode>> and open up the _.../standalone/configuration/standalone.xml_.  Search for `socket-binding-group`."
msgstr ""

msgid ""
"    <socket-binding-group name=\"standard-sockets\" default-interface=\"public\" port-offset=\"${jboss.socket.binding.port-offset:0}\">\n"
"        <socket-binding name=\"management-http\" interface=\"management\" port=\"${jboss.management.http.port:9990}\"/>\n"
"        <socket-binding name=\"management-https\" interface=\"management\" port=\"${jboss.management.https.port:9993}\"/>\n"
"        <socket-binding name=\"ajp\" port=\"${jboss.ajp.port:8009}\"/>\n"
"        <socket-binding name=\"http\" port=\"${jboss.http.port:8080}\"/>\n"
"        <socket-binding name=\"https\" port=\"${jboss.https.port:8443}\"/>\n"
"        <socket-binding name=\"txn-recovery-environment\" port=\"4712\"/>\n"
"        <socket-binding name=\"txn-status-manager\" port=\"4713\"/>\n"
"        <outbound-socket-binding name=\"mail-smtp\">\n"
"            <remote-destination host=\"localhost\" port=\"25\"/>\n"
"        </outbound-socket-binding>\n"
"    </socket-binding-group>"
msgstr ""

msgid "`socket-bindings` define socket connections that will be opened by the server.  These bindings specify the `interface` (bind address) they use as well as what port number they will open.   The ones you will be most interested in are:"
msgstr ""

msgid "http"
msgstr ""

msgid "Defines the port used for {project_name} HTTP connections"
msgstr ""

msgid "https"
msgstr ""

msgid "Defines the port used for {project_name} HTTPS connections"
msgstr ""

msgid "ajp"
msgstr ""

msgid "This socket binding defines the port used for the AJP protocol.  This protocol is used by Apache HTTPD server in conjunction `mod-cluster` when you are using Apache HTTPD as a load balancer."
msgstr ""

msgid "management-http"
msgstr ""

msgid "Defines the HTTP connection used by {appserver_name} CLI and web console."
msgstr ""

msgid "When running in <<_domain-mode,domain mode>> setting the socket configurations is a bit trickier as the example _domain.xml_ file has multiple `socket-binding-groups` defined.  If you scroll down to the `server-group` definitions you can see what `socket-binding-group` is used for each `server-group`."
msgstr ""

msgid "domain socket bindings"
msgstr ""

msgid ""
"    <server-groups>\n"
"        <server-group name=\"load-balancer-group\" profile=\"load-balancer\">\n"
"            ...\n"
"            <socket-binding-group ref=\"load-balancer-sockets\"/>\n"
"        </server-group>\n"
"        <server-group name=\"auth-server-group\" profile=\"auth-server-clustered\">\n"
"            ...\n"
"            <socket-binding-group ref=\"ha-sockets\"/>\n"
"        </server-group>\n"
"    </server-groups>"
msgstr ""

msgid "There are many more options available when setting up `socket-binding-group` definitions.  For more information, see link:{appserver_socket_link}[the socket binding group] in the _{appserver_socket_name}_."
msgstr ""

msgid "Setting up HTTPS/SSL"
msgstr ""

msgid "{project_name} is not set up by default to handle SSL/HTTPS.           It is highly recommended that you either enable SSL on the {project_name} server itself or on a reverse proxy in front of the {project_name} server."
msgstr ""

msgid "This default behavior is defined by the SSL/HTTPS mode of each {project_name} realm.  This is discussed in more detail in the link:{adminguide_link}[{adminguide_name}], but let's give some context and a brief overview of these modes."
msgstr ""

msgid "external requests"
msgstr ""

msgid "{project_name} can run out of the box without SSL so long as you stick to private IP addresses like `localhost`, `127.0.0.1`, `10.x.x.x`, `192.168.x.x`, and `172.16.x.x`. If you don't have SSL/HTTPS configured on the server or you try to access {project_name} over HTTP from a non-private IP adress you will get an error."
msgstr ""

msgid "none"
msgstr ""

msgid "{project_name} does not require SSL.  This should really only be used in development when you are playing around with things."
msgstr ""

msgid "all requests"
msgstr ""

msgid "{project_name} requires SSL for all IP addresses."
msgstr ""

msgid "The SSL mode for each realm can be configured in the {project_name} admin console."
msgstr ""

msgid "Enabling SSL/HTTPS for the {project_name} server"
msgstr ""

msgid "If you are not using a reverse proxy or load balancer to handle HTTPS traffic for you, you'll need to enable HTTPS for the {project_name} server.  This involves"
msgstr ""

msgid "Obtaining or generating a keystore that contains the private key and certificate for SSL/HTTP traffic"
msgstr ""

msgid "Configuring the {project_name} server to use this keypair and certificate."
msgstr ""

msgid "Creating the Certificate and Java Keystore"
msgstr ""

msgid "In order to allow HTTPS connections, you need to obtain a self signed or third-party signed certificate and import it into a Java keystore before you can enable HTTPS in the web container where you are deploying the {project_name} Server."
msgstr ""

msgid "Self Signed Certificate"
msgstr ""

msgid "In development, you will probably not have a third party signed certificate available to test a {project_name} deployment so you'll need to generate a self-signed one using the `keytool` utility that comes with the Java JDK."
msgstr ""

msgid ""
"\n"
"$ keytool -genkey -alias localhost -keyalg RSA -keystore keycloak.jks -validity 10950\n"
"    Enter keystore password: secret\n"
"    Re-enter new password: secret\n"
"    What is your first and last name?\n"
"    [Unknown]:  localhost\n"
"    What is the name of your organizational unit?\n"
"    [Unknown]:  Keycloak\n"
"    What is the name of your organization?\n"
"    [Unknown]:  Red Hat\n"
"    What is the name of your City or Locality?\n"
"    [Unknown]:  Westford\n"
"    What is the name of your State or Province?\n"
"    [Unknown]:  MA\n"
"    What is the two-letter country code for this unit?\n"
"    [Unknown]:  US\n"
"    Is CN=localhost, OU=Keycloak, O=Test, L=Westford, ST=MA, C=US correct?\n"
"    [no]:  yes"
msgstr ""

msgid "When you see the question `What is your first and last name ?`, supply the DNS name of the machine where you are installing the server. For testing purposes, `localhost` should be used. After executing this command, the `keycloak.jks` file will be generated in the same directory as you executed the `keytool` command in."
msgstr ""

msgid "If you want a third-party signed certificate, but don't have one, you can obtain one for free at http://www.cacert.org[cacert.org].  However, you first need to use the following procedure."
msgstr ""

msgid "Generate a Certificate Request:"
msgstr ""

msgid "$ keytool -certreq -alias yourdomain -keystore keycloak.jks > keycloak.careq"
msgstr ""

msgid "Where `yourdomain` is a DNS name for which this certificate is generated. Keytool generates the request:"
msgstr ""

msgid ""
"-----BEGIN NEW CERTIFICATE REQUEST-----\n"
"MIIC2jCCAcICAQAwZTELMAkGA1UEBhMCVVMxCzAJBgNVBAgTAk1BMREwDwYDVQQHEwhXZXN0Zm9y\n"
"ZDEQMA4GA1UEChMHUmVkIEhhdDEQMA4GA1UECxMHUmVkIEhhdDESMBAGA1UEAxMJbG9jYWxob3N0\n"
"MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAr7kck2TaavlEOGbcpi9c0rncY4HhdzmY\n"
"Ax2nZfq1eZEaIPqI5aTxwQZzzLDK9qbeAd8Ji79HzSqnRDxNYaZu7mAYhFKHgixsolE3o5Yfzbw1\n"
"29RvyeUVe+WZxv5oo9wolVVpdSINIMEL2LaFhtX/c1dqiqYVpfnvFshZQaIg2nL8juzZcBjj4as\n"
"H98gIS7khql/dkZKsw9NLvyxgJvp7PaXurX29fNf3ihG+oFrL22oFyV54BWWxXCKU/GPn61EGZGw\n"
"Ft2qSIGLdctpMD1aJR2bcnlhEjZKDksjQZoQ5YMXaAGkcYkG6QkgrocDE2YXDbi7GIdf9MegVJ35\n"
"2DQMpwIDAQABoDAwLgYJKoZIhvcNAQkOMSEwHzAdBgNVHQ4EFgQUQwlZJBA+fjiDdiVzaO9vrE/i\n"
"n2swDQYJKoZIhvcNAQELBQADggEBAC5FRvMkhal3q86tHPBYWBuTtmcSjs4qUm6V6f63frhveWHf\n"
"PzRrI1xH272XUIeBk0gtzWo0nNZnf0mMCtUBbHhhDcG82xolikfqibZijoQZCiGiedVjHJFtniDQ\n"
"9bMDUOXEMQ7gHZg5q6mJfNG9MbMpQaUVEEFvfGEQQxbiFK7hRWU8S23/d80e8nExgQxdJWJ6vd0X\n"
"MzzFK6j4Dj55bJVuM7GFmfdNC52pNOD5vYe47Aqh8oajHX9XTycVtPXl45rrWAH33ftbrS8SrZ2S\n"
"vqIFQeuLL3BaHwpl3t7j2lMWcK1p80laAxEASib/fAwrRHpLHBXRcq6uALUOZl4Alt8=\n"
"-----END NEW CERTIFICATE REQUEST-----"
msgstr ""

msgid "Send this CA request to your Certificate Authority (CA)."
msgstr ""

msgid "The CA will issue you a signed certificate and send it to you."
msgstr ""

msgid "Obtain and import the root certificate of the CA."
msgstr ""

msgid "You can download the cert from CA (in other words: root.crt) and import as follows:"
msgstr ""

msgid "$ keytool -import -keystore keycloak.jks -file root.crt -alias root"
msgstr ""

msgid "Import your new CA generated certificate to your keystore:"
msgstr ""

msgid "$ keytool -import -alias yourdomain -keystore keycloak.jks -file your-certificate.cer"
msgstr ""

msgid "Configure {project_name} to Use the Keystore"
msgstr ""

msgid "Now that you have a Java keystore with the appropriate certificates, you need to configure your {project_name} installation to use it."
msgstr ""

msgid "Edit the _standalone.xml_, _standalone-ha.xml_, or _host.xml_ file to use the keystore and enable HTTPS."
msgstr ""

msgid "Either move the keystore file to the _configuration/_ directory of your deployment or the file in a location you choose and provide an absolute path to it."
msgstr ""

msgid "If you are using absolute paths, remove the optional `relative-to` parameter from your configuration (See <<_operating-mode, operating mode>>)."
msgstr ""

msgid "Configure the keystore using the CLI:"
msgstr ""

msgid ""
"$ /subsystem=elytron/key-store=httpsKS:add(relative-to=jboss.server.config.dir,path=keycloak.jks,credential-reference={clear-text=secret},type=JKS)\n"
"$ /subsystem=elytron/key-manager=httpsKM:add(key-store=httpsKS,credential-reference={clear-text=secret})\n"
"$ /subsystem=elytron/server-ssl-context=httpsSSC:add(key-manager=httpsKM,protocols=[\\\"TLSv1.3\\\"])"
msgstr ""

msgid "If using domain mode, the commands should be executed in every host using the `/host=<host_name>/` prefix (in order to create the `security-realm` in all of them). Here is an example, which you would repeat for each host:"
msgstr ""

msgid "$ /host=<host_name>/subsystem=elytron/key-store=httpsKS:add(relative-to=jboss.server.config.dir,path=keycloak.jks,credential-reference={clear-text=secret},type=JKS)"
msgstr ""

msgid "Modify the `https-listener` to use the `server-ssl-context`previously created:"
msgstr ""

msgid "$ /subsystem=undertow/server=default-server/https-listener=https:write-attribute(name=ssl-context, value=httpsSSC)"
msgstr ""

msgid "If using domain mode, prefix the command with the profile that is being used with: `/profile=<profile_name>/`."
msgstr ""

msgid "The resulting element, `server name=\"default-server\"`, which is a child element of `subsystem xmlns=\"{subsystem_undertow_xml_urn}\"`, should contain the following stanza:"
msgstr ""

msgid ""
"<subsystem xmlns=\"{subsystem_undertow_xml_urn}\">\n"
"   <buffer-cache name=\"default\"/>\n"
"   <server name=\"default-server\">\n"
"      <https-listener name=\"https\" socket-binding=\"https\" ssl-context=\"httpsSSC\"/>\n"
"   ...\n"
"</subsystem>"
msgstr ""

msgid "For more information on configuring TLS refer to the https://docs.wildfly.org/25/WildFly_Elytron_Security.html#configure-ssltls[WildFly documentation]."
msgstr ""

msgid "Outgoing HTTP requests"
msgstr ""

msgid "The {project_name} server often needs to make non-browser HTTP requests to the applications and services it secures. The auth server manages these outgoing connections by maintaining an HTTP client connection pool.  There are some things you'll need to configure in `standalone.xml`, `standalone-ha.xml`, or `domain.xml`.  The location of this file depends on your <<_operating-mode, operating mode>>."
msgstr ""

msgid "HTTP client Config example"
msgstr ""

msgid ""
"<spi name=\"connectionsHttpClient\">\n"
"    <provider name=\"default\" enabled=\"true\">\n"
"        <properties>\n"
"            <property name=\"connection-pool-size\" value=\"256\"/>\n"
"        </properties>\n"
"    </provider>\n"
"</spi>"
msgstr ""

msgid "establish-connection-timeout-millis"
msgstr ""

msgid "Timeout for establishing a socket connection."
msgstr ""

msgid "socket-timeout-millis"
msgstr ""

msgid "If an outgoing request does not receive data for this amount of time, timeout the connection."
msgstr ""

msgid "connection-pool-size"
msgstr ""

msgid "How many connections can be in the pool (128 by default)."
msgstr ""

msgid "max-pooled-per-route"
msgstr ""

msgid "How many connections can be pooled per host (64 by default)."
msgstr ""

msgid "connection-ttl-millis"
msgstr ""

msgid "Maximum connection time to live in milliseconds. Not set by default."
msgstr ""

msgid "max-connection-idle-time-millis"
msgstr ""

msgid "Maximum time the connection might stay idle in the connection pool (900 seconds by default). Will start background cleaner thread of Apache HTTP client. Set to `-1` to disable this checking and the background thread."
msgstr ""

msgid "disable-cookies"
msgstr ""

msgid "`true` by default. When set to true, this will disable any cookie caching."
msgstr ""

msgid "client-keystore"
msgstr ""

msgid "This is the file path to a Java keystore file. This keystore contains client certificate for two-way SSL."
msgstr ""

msgid "client-keystore-password"
msgstr ""

msgid "Password for the client keystore. This is _REQUIRED_ if `client-keystore` is set."
msgstr ""

msgid "client-key-password"
msgstr ""

msgid "Password for the client's key. This is _REQUIRED_ if `client-keystore` is set."
msgstr ""

msgid "proxy-mappings"
msgstr ""

msgid "Denotes proxy configurations for outgoing HTTP requests. See the section on <<_proxymappings, Proxy Mappings for Outgoing HTTP Requests>> for more details."
msgstr ""

msgid "disable-trust-manager"
msgstr ""

msgid "If an outgoing request requires HTTPS and this config option is set to `true` you do not have to specify a truststore. This setting should only be used during development and *never* in production as it will disable verification of SSL certificates. This is _OPTIONAL_. The default value is `false`."
msgstr ""

msgid "Proxy mappings for outgoing HTTP requests"
msgstr ""

msgid "Outgoing HTTP requests sent by {project_name} can optionally use a proxy server based on a comma delimited list of proxy-mappings. A proxy-mapping denotes the combination of a regex based hostname pattern and a proxy-uri in the form of `hostnamePattern;proxyUri`, e.g.:"
msgstr ""

msgid ".*\\.(google|googleapis)\\.com;http://www-proxy.acme.com:8080"
msgstr ""

msgid "To determine the proxy for an outgoing HTTP request the target hostname is matched against the configured hostname patterns. The first matching pattern determines the proxy-uri to use. If none of the configured patterns match for the given hostname then no proxy is used."
msgstr ""

msgid "If the proxy server requires authentication, include the proxy user's credentials in this format `username:password@`. For example:"
msgstr ""

msgid ".*\\.(google|googleapis)\\.com;http://user01:pas2w0rd@www-proxy.acme.com:8080"
msgstr ""

msgid "The special value `NO_PROXY` for the proxy-uri can be used to indicate that no proxy should be used for hosts matching the associated hostname pattern. It is possible to specify a catch-all pattern at the end of the proxy-mappings to define a default proxy for all outgoing requests."
msgstr ""

msgid "The following example demonstrates the proxy-mapping configuration."
msgstr ""

msgid ""
"# All requests to Google APIs should use http://www-proxy.acme.com:8080 as proxy\n"
".*\\.(google|googleapis)\\.com;http://www-proxy.acme.com:8080\n"
"\n"
"# All requests to internal systems should use no proxy\n"
".*\\.acme\\.com;NO_PROXY\n"
"\n"
"# All other requests should use http://fallback:8080 as proxy\n"
".*;http://fallback:8080"
msgstr ""

msgid "This can be configured via the following `jboss-cli` command. Note that you need to properly escape the regex-pattern as shown below."
msgstr ""

msgid ""
"echo SETUP: Configure proxy routes for HttpClient SPI\n"
"\n"
"# In case there is no connectionsHttpClient definition yet\n"
"/subsystem=keycloak-server/spi=connectionsHttpClient/provider=default:add(enabled=true)\n"
"\n"
"# Configure the proxy-mappings\n"
"/subsystem=keycloak-server/spi=connectionsHttpClient/provider=default:write-attribute(name=properties.proxy-mappings,value=[\".*\\\\.(google|googleapis)\\\\.com;http://www-proxy.acme.com:8080\",\".*\\\\.acme\\\\.com;NO_PROXY\",\".*;http://fallback:8080\"])"
msgstr ""

msgid "The `jboss-cli` command results in the following subsystem configuration. Note that one needs to encode `\"` characters with `\\&quot;`."
msgstr ""

msgid ""
"<spi name=\"connectionsHttpClient\">\n"
"    <provider name=\"default\" enabled=\"true\">\n"
"        <properties>\n"
"            <property\n"
"            name=\"proxy-mappings\"\n"
"            value=\"[&quot;.*\\\\.(google|googleapis)\\\\.com;http://www-proxy.acme.com:8080&quot;,&quot;.*\\\\.acme\\\\.com;NO_PROXY&quot;,&quot;.*;http://fallback:8080&quot;]\"/>\n"
"        </properties>\n"
"    </provider>\n"
"</spi>"
msgstr ""

msgid "Using standard environment variables"
msgstr ""

msgid "Alternatively, it is possible to use standard environment variables to configure the proxy mappings, that is `HTTP_PROXY`, `HTTPS_PROXY` and `NO_PROXY` variables."
msgstr ""

msgid "The `HTTP_PROXY` and `HTTPS_PROXY` variables represent the proxy server that should be used for all outgoing HTTP requests. {project_name} does not differ between the two. If both are specified, `HTTPS_PROXY` takes the precedence regardless of the actual scheme the proxy server uses."
msgstr ""

msgid "The `NO_PROXY` variable is used to define a comma separated list of hostnames that should not use the proxy. If a hostname is specified, all its prefixes (subdomains) are also excluded from using proxy."
msgstr ""

msgid "Take the following example:"
msgstr ""

msgid ""
"HTTPS_PROXY=https://www-proxy.acme.com:8080\n"
"NO_PROXY=google.com,login.facebook.com"
msgstr ""

msgid "In this example, all outgoing HTTP requests will use `\\https://www-proxy.acme.com:8080` proxy server except for requests to for example `login.google.com`, `google.com`, `auth.login.facebook.com`. However, for example `groups.facebook.com` will be routed through the proxy."
msgstr ""

msgid "The environment variables can be lowercase or uppercase. Lowercase takes precedence. For example if both `HTTP_PROXY` and        `http_proxy` are defined, `http_proxy` will be used."
msgstr ""

msgid "If proxy mappings are defined using the subsystem configuration (as described above), the environment variables are not considered by {project_name}. This scenario applies in case no proxy server should be used despite having for example `HTTP_PROXY` environment variable defined. To do so, you can specify a generic no proxy route as follows:"
msgstr ""

msgid ""
"<spi name=\"connectionsHttpClient\">\n"
"    <provider name=\"default\" enabled=\"true\">\n"
"        <properties>\n"
"            <property name=\"proxy-mappings\" value=\".*;NO_PROXY\"/>\n"
"        </properties>\n"
"    </provider>\n"
"</spi>"
msgstr ""

msgid "Outgoing HTTPS request truststore"
msgstr ""

msgid "When {project_name} invokes on remote HTTPS endpoints, it has to validate the remote server's certificate in order to ensure it is connecting to a trusted server. This is necessary in order to prevent man-in-the-middle attacks.  The certificates of these remote server's or the CA that signed these certificates must be put in a truststore.  This truststore is managed by the {project_name} server."
msgstr ""

msgid "The truststore is used when connecting securely to identity brokers, LDAP identity providers, when sending emails, and for backchannel communication with client applications."
msgstr ""

msgid "By default, a truststore provider is not configured, and any https connections fall back to standard java truststore configuration as described in           https://docs.oracle.com/javase/8/docs/technotes/guides/security/jsse/JSSERefGuide.html[Java's JSSE Reference Guide].  If there is no trust           established, then these outgoing HTTPS requests will fail."
msgstr ""

msgid "You can use _keytool_ to create a new truststore file or add trusted host certificates to an existing one:"
msgstr ""

msgid ""
"\n"
"$ keytool -import -alias HOSTDOMAIN -keystore truststore.jks -file host-certificate.cer"
msgstr ""

msgid "The truststore is configured within the `standalone.xml`, `standalone-ha.xml`, or `domain.xml` file in your distribution.  The location of this file depends on your <<_operating-mode, operating mode>>. You can add your truststore configuration by using the following template:"
msgstr ""

msgid ""
"<spi name=\"truststore\">\n"
"    <provider name=\"file\" enabled=\"true\">\n"
"        <properties>\n"
"            <property name=\"file\" value=\"path to your .jks file containing public certificates\"/>\n"
"            <property name=\"password\" value=\"password\"/>\n"
"            <property name=\"hostname-verification-policy\" value=\"WILDCARD\"/>\n"
"        </properties>\n"
"    </provider>\n"
"</spi>\n"
msgstr ""

msgid "Possible configuration options for this setting are:"
msgstr ""

msgid "file"
msgstr ""

msgid "The path to a Java keystore file. HTTPS requests need a way to verify the host of the server they are talking to. This is what the trustore does. The keystore contains one or more trusted host certificates or certificate authorities. This truststore file should only contain public certificates of your secured hosts. This is _REQUIRED_ if any of these properties are defined."
msgstr ""

msgid "password"
msgstr ""

msgid "Password of the keystore. This is _REQUIRED_ if any of these properties are defined."
msgstr ""

msgid "hostname-verification-policy"
msgstr ""

msgid "`WILDCARD` by default. For HTTPS requests, this verifies the hostname of the server's certificate.  `ANY` means that the hostname is not verified. `WILDCARD` Allows wildcards in subdomain names i.e. *.foo.com. `STRICT` CN must match hostname exactly."
msgstr ""

msgid "Configuring {project_name} to run in a cluster"
msgstr ""

msgid "To configure {project_name} to run in a cluster, you perform these actions:"
msgstr ""

msgid "<<_operating-mode,Pick an operation mode>>"
msgstr ""

msgid "<<_database,Configure a shared external database>>"
msgstr ""

msgid "Set up a load balancer"
msgstr ""

msgid "Supplying a private network that supports IP multicast"
msgstr ""

msgid "Picking an operation mode and configuring a shared database have been discussed earlier in this guide.  This chapter describes setting up a load balancer and supplying a private network as well as booting up a host in the cluster."
msgstr ""

msgid "It is possible to cluster {project_name} without IP Multicast, but this topic is beyond the scope of this guide.  For more information, see link:{appserver_jgroups_link}[JGroups] chapter of the _{appserver_jgroups_name}_."
msgstr ""

msgid "Recommended network architecture"
msgstr ""

msgid "The recommended network architecture for deploying {project_name} is to set up an HTTP/HTTPS load balancer on a public IP address that routes requests to {project_name} servers sitting on a private network.  This isolates all clustering connections and provides a nice means of protecting the servers."
msgstr ""

msgid "By default, there is nothing to prevent unauthorized nodes from joining the cluster and broadcasting multicast messages.       This is why cluster nodes should be in a private network, with a firewall protecting them from outside attacks."
msgstr ""

msgid "Clustering example"
msgstr ""

msgid "{project_name} does come with an out of the box clustering demo that leverages domain mode.  Review the <<_clustered-domain-example, Clustered Domain Example>> chapter for more details."
msgstr ""

msgid "Setting Up a load balancer or proxy"
msgstr ""

msgid "This section discusses a number of things you need to configure before you can put a reverse proxy or load balancer in front of your clustered {project_name} deployment.  It also covers configuring the built-in load balancer that was <<_clustered-domain-example, Clustered Domain Example>>."
msgstr ""

msgid "The following diagram illustrates the use of a load balancer. In this example, the load balancer serves as a reverse proxy between three clients and a cluster of three {project_name} servers."
msgstr ""

msgid "Example Load Balancer Diagram"
msgstr ""

msgid "image:{project_images}/load_balancer.png[]"
msgstr ""

msgid "Identifying client IP addresses"
msgstr ""

msgid "A few features in {project_name} rely on the fact that the remote address of the HTTP client connecting to the authentication server is the real IP address of the client machine. Examples include:"
msgstr ""

msgid "Event logs - a failed login attempt would be logged with the wrong source IP address"
msgstr ""

msgid "SSL required - if the SSL required is set to external (the default) it should require SSL for all external requests"
msgstr ""

msgid "Authentication flows - a custom authentication flow that uses the IP address to for example show OTP only for external requests"
msgstr ""

msgid "Dynamic Client Registration"
msgstr ""

msgid "This can be problematic when you have a reverse proxy or loadbalancer in front of your {project_name} authentication server. The usual setup is that you have a frontend proxy sitting on a public network that load balances and forwards requests to backend {project_name} server instances located in a private network.  There is some extra configuration you have to do in this scenario so that the actual client IP address is forwarded to and processed by the {project_name} server instances.  Specifically:"
msgstr ""

msgid "Configure your reverse proxy or loadbalancer to properly set `X-Forwarded-For` and `X-Forwarded-Proto` HTTP headers."
msgstr ""

msgid "Configure your reverse proxy or loadbalancer to preserve the original 'Host' HTTP header."
msgstr ""

msgid "Configure the authentication server to read the client's IP address from `X-Forwarded-For` header."
msgstr ""

msgid "Configuring your proxy to generate the `X-Forwarded-For` and `X-Forwarded-Proto` HTTP headers and preserving the  original `Host` HTTP header is beyond the scope of this guide.  Take extra precautions to ensure that the `X-Forwarded-For` header is set by your proxy.  If your proxy isn't configured correctly, then _rogue_ clients can set this header themselves and trick {project_name} into thinking the client is connecting from a different IP address than it actually is.  This becomes really important if you are doing any black or white listing of IP addresses."
msgstr ""

msgid "Beyond the proxy itself, there are a few things you need to configure on the {project_name} side of things. If your proxy is forwarding requests via the HTTP protocol, then you need to configure {project_name} to pull the client's IP address from the `X-Forwarded-For` header rather than from the network packet. To do this, open up the profile configuration file (_standalone.xml_, _standalone-ha.xml_, or _domain.xml_ depending on your <<_operating-mode, operating mode>>) and look for the `{subsystem_undertow_xml_urn}` XML block."
msgstr ""

msgid "`X-Forwarded-For` HTTP Config"
msgstr ""

msgid ""
"<subsystem xmlns=\"{subsystem_undertow_xml_urn}\">\n"
"   <buffer-cache name=\"default\"/>\n"
"   <server name=\"default-server\">\n"
"      <ajp-listener name=\"ajp\" socket-binding=\"ajp\"/>\n"
"      <http-listener name=\"default\" socket-binding=\"http\" redirect-socket=\"https\"\n"
"          proxy-address-forwarding=\"true\"/>\n"
"      ...\n"
"   </server>\n"
"   ...\n"
"</subsystem>"
msgstr ""

msgid "Add the `proxy-address-forwarding` attribute to the `http-listener` element.  Set the value to `true`."
msgstr ""

msgid "If your proxy is using the AJP protocol instead of HTTP to forward requests (i.e. Apache HTTPD + mod-cluster), then you have to configure things a little differently.  Instead of modifying the `http-listener`, you need to add a filter to pull this information from the AJP packets."
msgstr ""

msgid "`X-Forwarded-For` AJP Config"
msgstr ""

msgid ""
"<subsystem xmlns=\"{subsystem_undertow_xml_urn}\">\n"
"     <buffer-cache name=\"default\"/>\n"
"     <server name=\"default-server\">\n"
"         <ajp-listener name=\"ajp\" socket-binding=\"ajp\"/>\n"
"         <http-listener name=\"default\" socket-binding=\"http\" redirect-socket=\"https\"/>\n"
"         <host name=\"default-host\" alias=\"localhost\">\n"
"             ...\n"
"             <filter-ref name=\"proxy-peer\"/>\n"
"         </host>\n"
"     </server>\n"
"        ...\n"
"     <filters>\n"
"         ...\n"
"         <filter name=\"proxy-peer\"\n"
"                 class-name=\"io.undertow.server.handlers.ProxyPeerAddressHandler\"\n"
"                 module=\"io.undertow.core\" />\n"
"     </filters>\n"
" </subsystem>"
msgstr ""

msgid "Enabling HTTPS/SSL with a reverse proxy"
msgstr ""

msgid "Assuming that your reverse proxy doesn't use port 8443 for SSL you also need to configure to what port the HTTPS traffic is redirected."
msgstr ""

msgid ""
"<subsystem xmlns=\"{subsystem_undertow_xml_urn}\">\n"
"    ...\n"
"    <http-listener name=\"default\" socket-binding=\"http\"\n"
"        proxy-address-forwarding=\"true\" redirect-socket=\"proxy-https\"/>\n"
"    ...\n"
"</subsystem>"
msgstr ""

msgid "Add the `redirect-socket` attribute to the `http-listener` element.  The value should be `proxy-https` which points to a socket binding you also need to define."
msgstr ""

msgid "Add a new `socket-binding` element to the `socket-binding-group` element:"
msgstr ""

msgid ""
"<socket-binding-group name=\"standard-sockets\" default-interface=\"public\"\n"
"    port-offset=\"${jboss.socket.binding.port-offset:0}\">\n"
"    ...\n"
"    <socket-binding name=\"proxy-https\" port=\"443\"/>\n"
"    ...\n"
"</socket-binding-group>"
msgstr ""

msgid "Verifying the configuration"
msgstr ""

msgid "You can verify the reverse proxy or load balancer configuration"
msgstr ""

msgid "Open the path `/auth/realms/master/.well-known/openid-configuration` through the reverse proxy."
msgstr ""

msgid "For example if the reverse proxy address is `\\https://acme.com/` then open the URL `\\https://acme.com/auth/realms/master/.well-known/openid-configuration`. This will show a JSON document listing a number of endpoints for {project_name}."
msgstr ""

msgid "Make sure the endpoints starts with the address (scheme, domain and port) of your reverse proxy or load balancer. By doing this you make sure that {project_name} is using the correct endpoint."
msgstr ""

msgid "Verify that {project_name} sees the correct source IP address for requests."
msgstr ""

msgid "To check this, you can try to login to the Admin Console with an invalid username and/or password. This should show a warning in the server log something like this:"
msgstr ""

msgid "08:14:21,287 WARN  XNIO-1 task-45 [org.keycloak.events] type=LOGIN_ERROR, realmId=master, clientId=security-admin-console, userId=8f20d7ba-4974-4811-a695-242c8fbd1bf8, ipAddress=X.X.X.X, error=invalid_user_credentials, auth_method=openid-connect, auth_type=code, redirect_uri=http://localhost:8080/auth/admin/master/console/?redirect_fragment=%2Frealms%2Fmaster%2Fevents-settings, code_id=a3d48b67-a439-4546-b992-e93311d6493e, username=admin"
msgstr ""

msgid "Check that the value of `ipAddress` is the IP address of the machine you tried to login with and not the IP address  of the reverse proxy or load balancer."
msgstr ""

msgid "Using the built-in load balancer"
msgstr ""

msgid "This section covers configuring the built-in load balancer that is discussed in the <<_clustered-domain-example, Clustered Domain Example>>."
msgstr ""

msgid "The <<_clustered-domain-example, Clustered Domain Example>> is only designed to run on one machine.  To bring up a slave on another host, you'll need to"
msgstr ""

msgid "Edit the _domain.xml_ file to point to your new host slave"
msgstr ""

msgid "Copy the server distribution.  You don't need the _domain.xml_, _host.xml_, or _host-master.xml_ files.  Nor do you need the _standalone/_ directory."
msgstr ""

msgid "Edit the _host-slave.xml_ file to change the bind addresses used or override them on the command line"
msgstr ""

msgid "Open  _domain.xml_ so you can registering the new host slave with the load balancer configuration."
msgstr ""

msgid "Go to the undertow configuration in the `load-balancer` profile.  Add a new `host` definition called `remote-host3` within the `reverse-proxy` XML block."
msgstr ""

msgid "domain.xml reverse-proxy config"
msgstr ""

msgid ""
"<subsystem xmlns=\"{subsystem_undertow_xml_urn}\">\n"
"  ...\n"
"  <handlers>\n"
"      <reverse-proxy name=\"lb-handler\">\n"
"         <host name=\"host1\" outbound-socket-binding=\"remote-host1\" scheme=\"ajp\" path=\"/\" instance-id=\"myroute1\"/>\n"
"         <host name=\"host2\" outbound-socket-binding=\"remote-host2\" scheme=\"ajp\" path=\"/\" instance-id=\"myroute2\"/>\n"
"         <host name=\"remote-host3\" outbound-socket-binding=\"remote-host3\" scheme=\"ajp\" path=\"/\" instance-id=\"myroute3\"/>\n"
"      </reverse-proxy>\n"
"  </handlers>\n"
"  ...\n"
"</subsystem>"
msgstr ""

msgid "The `output-socket-binding` is a logical name pointing to a `socket-binding` configured later in the _domain.xml_ file. The `instance-id` attribute must also be unique to the new host as this value is used by a cookie to enable sticky sessions when load balancing."
msgstr ""

msgid "Go down to the `load-balancer-sockets` `socket-binding-group` and add the `outbound-socket-binding` for `remote-host3`."
msgstr ""

msgid "This new binding needs to point to the host and port of the new host."
msgstr ""

msgid "domain.xml outbound-socket-binding"
msgstr ""

msgid ""
"<socket-binding-group name=\"load-balancer-sockets\" default-interface=\"public\">\n"
"    ...\n"
"    <outbound-socket-binding name=\"remote-host1\">\n"
"        <remote-destination host=\"localhost\" port=\"8159\"/>\n"
"    </outbound-socket-binding>\n"
"    <outbound-socket-binding name=\"remote-host2\">\n"
"        <remote-destination host=\"localhost\" port=\"8259\"/>\n"
"    </outbound-socket-binding>\n"
"    <outbound-socket-binding name=\"remote-host3\">\n"
"        <remote-destination host=\"192.168.0.5\" port=\"8259\"/>\n"
"    </outbound-socket-binding>\n"
"</socket-binding-group>"
msgstr ""

msgid "Master bind addresses"
msgstr ""

msgid "Next thing you'll have to do is to change the `public` and `management` bind addresses for the master host.  Either edit the _domain.xml_ file as discussed in the <<_bind-address, Bind Addresses>> chapter or specify these bind addresses on the command line as follows:"
msgstr ""

msgid "$ domain.sh --host-config=host-master.xml -Djboss.bind.address=192.168.0.2 -Djboss.bind.address.management=192.168.0.2"
msgstr ""

msgid "Host slave bind addresses"
msgstr ""

msgid "Next you'll have to change the `public`, `management`, and domain controller bind addresses (`jboss.domain.master-address`).  Either edit the _host-slave.xml_ file or specify them on the command line as follows:"
msgstr ""

msgid ""
"$ domain.sh --host-config=host-slave.xml\n"
"     -Djboss.bind.address=192.168.0.5\n"
"      -Djboss.bind.address.management=192.168.0.5\n"
"       -Djboss.domain.master.address=192.168.0.2"
msgstr ""

msgid "The values of `jboss.bind.address` and `jboss.bind.address.management` pertain to the host slave's IP address. The value of `jboss.domain.master.address` needs to be the IP address of the domain controller, which is the management address of the master host."
msgstr ""

msgid "Additional resources"
msgstr ""

msgid "See link:{appserver_loadbalancer_link}[the load balancing] section in the _{appserver_loadbalancer_name}_ for information how to use other software-based load balancers."
msgstr ""

msgid "Sticky sessions"
msgstr ""

msgid "Typical cluster deployment consists of the load balancer (reverse proxy) and 2 or more {project_name} servers on private network. For performance purposes, it may be useful if load balancer forwards all requests related to particular browser session to the same {project_name} backend node."
msgstr ""

msgid "The reason is, that {project_name} is using Infinispan distributed cache under the covers for save data related to current authentication session and user session. The Infinispan distributed caches are configured with one owner by default. That means that particular session is saved just on one cluster node and the other nodes need to lookup the session remotely if they want to access it."
msgstr ""

msgid "For example if authentication session with ID `123` is saved in the Infinispan cache on `node1`, and then `node2` needs to lookup this session, it needs to send the request to `node1` over the network to return the particular session entity."
msgstr ""

msgid "It is beneficial if particular session entity is always available locally, which can be done with the help of sticky sessions. The workflow in the cluster environment with the public frontend load balancer and two backend {project_name} nodes can be like this:"
msgstr ""

msgid "User sends initial request to see the {project_name} login screen"
msgstr ""

msgid "This request is served by the frontend load balancer, which forwards it to some random node (eg. node1). Strictly said, the node doesn't need to be random, but can be chosen according to some other criterias (client IP address etc). It all depends on the implementation and configuration of underlying load balancer (reverse proxy)."
msgstr ""

msgid "{project_name} creates authentication session with random ID (eg. 123) and saves it to the Infinispan cache."
msgstr ""

msgid "Infinispan distributed cache assigns the primary owner of the session based on the hash of session ID. See link:https://infinispan.org/docs/10.1.x/titles/configuring/configuring.html#clustered_caches[Infinispan documentation] for more details around this. Let's assume that Infinispan assigned `node2` to be the owner of this session."
msgstr ""

msgid "{project_name} creates the cookie `AUTH_SESSION_ID` with the format like `<session-id>.<owner-node-id>` . In our example case, it will be `123.node2` ."
msgstr ""

msgid "Response is returned to the user with the {project_name} login screen and the AUTH_SESSION_ID cookie in the browser"
msgstr ""

msgid "From this point, it is beneficial if load balancer forwards all the next requests to the `node2` as this is the node, who is owner of the authentication session with ID `123` and hence Infinispan can lookup this session locally. After authentication is finished, the authentication session is converted to user session, which will be also saved on `node2` because it has same ID `123` ."
msgstr ""

msgid "The sticky session is not mandatory for the cluster setup, however it is good for performance for the reasons mentioned above. You need to configure your loadbalancer to sticky over the `AUTH_SESSION_ID` cookie. How exactly do this is dependent on your loadbalancer."
msgstr ""

msgid "It is recommended on the {project_name} side to use the system property `jboss.node.name` during startup, with the value corresponding to the name of your route. For example, `-Djboss.node.name=node1` will use `node1` to identify the route. This route will be used by Infinispan caches and will be attached to the AUTH_SESSION_ID cookie when the node is the owner of the particular key. Here is an example of the start up command using this system property:"
msgstr ""

msgid ""
"cd $RHSSO_NODE1\n"
"./standalone.sh -c standalone-ha.xml -Djboss.socket.binding.port-offset=100 -Djboss.node.name=node1"
msgstr ""

msgid "Typically in production environment the route name should use the same name as your backend host, but it is not required. You can use a different route name. For example, if you want to hide the host name of your {project_name} server inside your private network."
msgstr ""

msgid "Disable adding the route"
msgstr ""

msgid "Some load balancers can be configured to add the route information by themselves instead of relying on the back end {project_name} node. However, as described above, adding the route by the {project_name} is recommended. This is because when done this way performance improves, since {project_name} is aware of the entity that is the owner of particular session and can route to that node, which is not necessarily the local node."
msgstr ""

msgid "You are permitted to disable adding route information to the AUTH_SESSION_ID cookie by {project_name}, if you prefer, by adding the following into your `RHSSO_HOME/standalone/configuration/standalone-ha.xml` file in the {project_name} subsystem configuration:"
msgstr ""

msgid ""
"<subsystem xmlns=\"urn:jboss:domain:keycloak-server:1.1\">\n"
"  ...\n"
"    <spi name=\"stickySessionEncoder\">\n"
"        <provider name=\"infinispan\" enabled=\"true\">\n"
"            <properties>\n"
"                <property name=\"shouldAttachRoute\" value=\"false\"/>\n"
"            </properties>\n"
"        </provider>\n"
"    </spi>\n"
"\n"
"</subsystem>"
msgstr ""

msgid "Setting up multicast networking"
msgstr ""

msgid "The default clustering support needs IP Multicast. Multicast is a network broadcast protocol. This protocol is used at boot time to discover and join the cluster. It is also used to broadcast messages for the replication and invalidation of distributed caches used by {project_name}."
msgstr ""

msgid "The clustering subsystem for {project_name} runs on the JGroups stack. Out of the box, the bind addresses for clustering are bound to a private network interface with 127.0.0.1 as default IP address."
msgstr ""

msgid "Edit your the _standalone-ha.xml_ or _domain.xml_ sections discussed in the <<_bind-address,Bind Address>> chapter."
msgstr ""

msgid "private network config"
msgstr ""

msgid ""
"    <interfaces>\n"
"        ...\n"
"        <interface name=\"private\">\n"
"            <inet-address value=\"${jboss.bind.address.private:127.0.0.1}\"/>\n"
"        </interface>\n"
"    </interfaces>\n"
"    <socket-binding-group name=\"standard-sockets\" default-interface=\"public\" port-offset=\"${jboss.socket.binding.port-offset:0}\">\n"
"        ...\n"
"        <socket-binding name=\"jgroups-mping\" interface=\"private\" port=\"0\" multicast-address=\"${jboss.default.multicast.address:230.0.0.4}\" multicast-port=\"45700\"/>\n"
"        <socket-binding name=\"jgroups-tcp\" interface=\"private\" port=\"7600\"/>\n"
"        <socket-binding name=\"jgroups-tcp-fd\" interface=\"private\" port=\"57600\"/>\n"
"        <socket-binding name=\"jgroups-udp\" interface=\"private\" port=\"55200\" multicast-address=\"${jboss.default.multicast.address:230.0.0.4}\" multicast-port=\"45688\"/>\n"
"        <socket-binding name=\"jgroups-udp-fd\" interface=\"private\" port=\"54200\"/>\n"
"        <socket-binding name=\"modcluster\" port=\"0\" multicast-address=\"224.0.1.105\" multicast-port=\"23364\"/>\n"
"        ...\n"
"    </socket-binding-group>"
msgstr ""

msgid "Configure the `jboss.bind.address.private` and `jboss.default.multicast.address` as well as the ports of the services on the clustering stack."
msgstr ""

msgid "It is possible to cluster {project_name} without IP Multicast, but this topic is beyond the scope of this guide. For more information, see link:{appserver_jgroups_link}[JGroups] in the _{appserver_jgroups_name}_."
msgstr ""

msgid "Secure cluster communication"
msgstr ""

msgid "When cluster nodes are isolated on a private network it requires access to the private network to be able to join a cluster or to view communication in the cluster. In addition you can also enable authentication and encryption for cluster communication. As long as your private network is secure it is not necessary to enable authentication and encryption. {project_name} does not send very sensitive information on the cluster in either case."
msgstr ""

msgid "If you want to enable authentication and encryption for clustering communication, see the 'High Availability Guide' in the link:{appserver_doc_base_url}/High_Availability_Guide.html[WildFly documentation]."
msgstr ""

msgid "Serialized cluster startup"
msgstr ""

msgid "{project_name} cluster nodes are allowed to boot concurrently. When {project_name} server instance boots up it may do some database migration, importing, or first time initializations. A DB lock is used to prevent start actions from conflicting with one another when cluster nodes boot up concurrently."
msgstr ""

msgid "By default, the maximum timeout for this lock is 900 seconds.  If a node is waiting on this lock for more than the timeout it will fail to boot. Typically you won't need to increase/decrease the default value, but just in case it's possible to configure it in `standalone.xml`, `standalone-ha.xml`, or `domain.xml` file in your distribution.  The location of this file depends on your <<_operating-mode, operating mode>>."
msgstr ""

msgid ""
"<spi name=\"dblock\">\n"
"    <provider name=\"jpa\" enabled=\"true\">\n"
"        <properties>\n"
"            <property name=\"lockWaitTimeout\" value=\"900\"/>\n"
"        </properties>\n"
"    </provider>\n"
"</spi>"
msgstr ""

msgid "Booting the cluster"
msgstr ""

msgid "Booting {project_name} in a cluster depends on your <<_operating-mode, operating mode>>"
msgstr ""

msgid "Standalone Mode"
msgstr ""

msgid "$ bin/standalone.sh --server-config=standalone-ha.xml"
msgstr ""

msgid "Domain Mode"
msgstr ""

msgid ""
"$ bin/domain.sh --host-config=host-master.xml\n"
"$ bin/domain.sh --host-config=host-slave.xml"
msgstr ""

msgid "You may need to use additional parameters or system properties. For example, the parameter `-b` for the binding host or the system property `jboss.node.name` to specify the name of the route, as described in <<sticky-sessions,Sticky Sessions >> section."
msgstr ""

msgid "Note that when you run a cluster, you should see message similar to this in the log of both cluster nodes:"
msgstr ""

msgid ""
"INFO  [org.infinispan.remoting.transport.jgroups.JGroupsTransport] (Incoming-10,shared=udp)\n"
"ISPN000094: Received new cluster view: [node1/keycloak|1] (2) [node1/keycloak, node2/keycloak]"
msgstr ""

msgid "If you see just one node mentioned, it's possible that your cluster hosts are not joined together."
msgstr ""

msgid "Usually it's best practice to have your cluster nodes on private network without firewall for communication among them. Firewall could be enabled just on public access point to your network instead. If for some reason you still need to have firewall enabled on cluster nodes, you will need to open some ports. Default values are UDP port 55200 and multicast port 45688 with multicast address 230.0.0.4. Note that you may need more ports opened if you want to enable additional features like diagnostics for your JGroups stack. {project_name} delegates most of the clustering work to Infinispan/JGroups. For more information, see link:{appserver_jgroups_link}[JGroups] in the _{appserver_jgroups_name}_."
msgstr ""

msgid "If you are interested in failover support (high availability), evictions, expiration and cache tuning, see <<cache-configuration>>."
msgstr ""

msgid "Server cache configuration"
msgstr ""

msgid "{project_name} has two types of caches.  One type of cache sits in front of the database to decrease load on the DB and to decrease overall response times by keeping data in memory.  Realm, client, role, and user metadata is kept in this type of cache. This cache is a local cache.  Local caches do not use replication even if you are in the cluster with more {project_name} servers. Instead, they only keep copies locally and if the entry is updated an invalidation message is sent to the rest of the cluster and the entry is evicted. There is separate replicated cache `work`, which task is to send the invalidation messages to the whole cluster about what entries  should be evicted from local caches. This greatly reduces network traffic, makes things efficient, and avoids transmitting sensitive metadata over the wire."
msgstr ""

msgid "The second type of cache handles managing user sessions, offline tokens, and keeping track of login failures so that the server can detect password phishing and other attacks.  The data held in these caches is temporary, in memory only, but is possibly replicated across the cluster."
msgstr ""

msgid "This chapter discusses some configuration options for these caches for both clustered and non-clustered deployments."
msgstr ""

msgid "More advanced configuration of these caches can be found in the  link:{appserver_caching_link}[Infinispan] section of the _{appserver_caching_name}_."
msgstr ""

msgid "Eviction and expiration"
msgstr ""

msgid "There are multiple different caches configured for {project_name}. There is a realm cache that holds information about secured applications, general security data, and configuration options. There is also a user cache that contains user metadata.  Both caches default to a maximum of 10000 entries and use a least recently used eviction strategy. Each of them is also tied to an object revisions cache that controls eviction in a clustered setup. This cache is created implicitly and has twice the configured size. The same applies for the `authorization` cache, which holds the authorization data. The `keys` cache holds data about external keys and does not need to have dedicated revisions cache. Rather it has `expiration` explicitly declared on it, so the keys are periodically expired and forced to be periodically downloaded from external clients or identity providers."
msgstr ""

msgid "The eviction policy and max entries for these caches can be configured in the _standalone.xml_, _standalone-ha.xml_, or _domain.xml_ depending on your <<_operating-mode, operating mode>>. In the configuration file, there is the part with infinispan subsystem, which looks similar to this:"
msgstr ""

msgid ""
"<subsystem xmlns=\"{subsystem_infinispan_xml_urn}\">\n"
"    <cache-container name=\"keycloak\">\n"
"        <local-cache name=\"realms\">\n"
"            <object-memory size=\"10000\"/>\n"
"        </local-cache>\n"
"        <local-cache name=\"users\">\n"
"            <object-memory size=\"10000\"/>\n"
"        </local-cache>\n"
"        ...\n"
"        <local-cache name=\"keys\">\n"
"            <object-memory size=\"1000\"/>\n"
"            <expiration max-idle=\"3600000\"/>\n"
"        </local-cache>\n"
"        ...\n"
"    </cache-container>"
msgstr ""

msgid "To limit or expand the number of allowed entries simply add or edit the `object` element or the `expiration` element of particular cache configuration."
msgstr ""

msgid "In addition, there are also separate caches `sessions`, `clientSessions`, `offlineSessions`, `offlineClientSessions`, `loginFailures` and `actionTokens`. These caches are distributed in cluster environment and they are unbounded in size by default. If they are bounded, it would then be possible that some sessions will be lost. Expired sessions are cleared internally by {project_name} itself to avoid growing the size of these caches without limit. If you see memory issues due to a large number of sessions, you can try to:"
msgstr ""

msgid "Increase the size of cluster (more nodes in cluster means that sessions are spread more equally among nodes)"
msgstr ""

msgid "Increase the memory for {project_name} server process"
msgstr ""

msgid "Decrease the number of owners to ensure that caches are saved in one single place. See <<_replication>> for more details"
msgstr ""

msgid "Disable l1-lifespan for distributed caches. See Infinispan documentation for more details"
msgstr ""

msgid "Decrease session timeouts, which could be done individually for each realm in {project_name} admin console. But this could affect usability for end users. See link:{adminguide_timeouts_link}[{adminguide_timeouts_name}] for more details."
msgstr ""

msgid "There is an additional replicated cache, `work`, which is mostly used to send messages among cluster nodes; it is also unbounded by default. However, this cache should not cause any memory issues as entries in this cache are very short-lived."
msgstr ""

msgid "Replication and failover"
msgstr ""

msgid "There are caches like `sessions`, `authenticationSessions`, `offlineSessions`, `loginFailures` and a few others (See <<_eviction>> for more details), which are configured as distributed caches when using a clustered setup. Entries are not replicated to every single node, but instead one or more nodes is chosen as an owner of that data.  If a node is not the owner of a specific cache entry it queries the cluster to obtain it.  What this means for failover is that if all the nodes that own a piece of data go down, that data is lost forever.  By default, {project_name} only specifies one owner for data.  So if that one node goes down that data is lost.  This usually means that users will be logged out and will have to login again."
msgstr ""

msgid "You can change the number of nodes that replicate a piece of data by change the `owners` attribute in the `distributed-cache` declaration."
msgstr ""

msgid "owners"
msgstr ""

msgid ""
"<subsystem xmlns=\"{subsystem_infinispan_xml_urn}\">\n"
"   <cache-container name=\"keycloak\">\n"
"       <distributed-cache name=\"sessions\" owners=\"2\"/>\n"
"..."
msgstr ""

msgid "Here we've changed it so at least two nodes will replicate one specific user login session."
msgstr ""

msgid "The number of owners recommended is really dependent on your deployment.  If you do not care if users are logged       out when a node goes down, then one owner is good enough and you will avoid replication."
msgstr ""

msgid "It is generally wise to configure your environment to use loadbalancer with sticky sessions. It is beneficial for performance      as {project_name} server, where the particular request is served, will be usually the owner of the data from the distributed cache      and will therefore be able to look up the data locally. See <<sticky-sessions>> for more details."
msgstr ""

msgid "Disabling caching"
msgstr ""

msgid "You can disable the realm or user cache."
msgstr ""

msgid "Edit the `standalone.xml`, `standalone-ha.xml`,  or `domain.xml` file in your distribution."
msgstr ""

msgid "The location of this file depends on your <<_operating-mode, operating mode>>. Here is a sample config file."
msgstr ""

msgid ""
"\n"
"    <spi name=\"userCache\">\n"
"        <provider name=\"default\" enabled=\"true\"/>\n"
"    </spi>\n"
"\n"
"    <spi name=\"realmCache\">\n"
"        <provider name=\"default\" enabled=\"true\"/>\n"
"    </spi>\n"
msgstr ""

msgid "Set the `enabled` attribute to false for the cache you want to disable."
msgstr ""

msgid "Reboot your server for this change to take effect."
msgstr ""

msgid "Clearing cache at runtime"
msgstr ""

msgid "You can clear the realm cache, user cache, or the external public keys."
msgstr ""

msgid "Log into the Admin Console."
msgstr ""

msgid "Click *Realm Settings*."
msgstr ""

msgid "Click the *Cache* tab."
msgstr ""

msgid "Clear the realm cache, the user cache or cache of external public keys."
msgstr ""

msgid "The cache will be cleared for all realms!"
msgstr ""

msgid "{project_operator}"
msgstr ""

msgid "The {project_operator} automates {project_name} administration in Kubernetes or Openshift. You use this Operator to create custom resources (CRs), which automate administrative tasks. For example, instead of creating a client or a user in the {project_name} admin console, you can create custom resources to perform those tasks. A custom resource is a YAML file that defines the parameters for the administrative task."
msgstr ""

msgid "You can create custom resources to perform the following tasks:"
msgstr ""

msgid "xref:_keycloak_cr[Install {project_name}]"
msgstr ""

msgid "xref:_realm-cr[Create realms]"
msgstr ""

msgid "xref:_client-cr[Create clients]"
msgstr ""

msgid "xref:_user-cr[Create users]"
msgstr ""

msgid "xref:_external_database[Connect to an external database]"
msgstr ""

msgid "xref:_backup-cr[Schedule database backups]"
msgstr ""

msgid "xref:_operator-extensions[Install extensions and themes]"
msgstr ""

msgid "After you create custom resources for realms, clients, and users, you can manage them by using the {project_name} admin console or as custom resources using the `{create_cmd_brief}` command.  However, you cannot use both methods, because the Operator performs a one way sync for custom resources that you modify.  For example, if you modify a realm custom resource, the changes show up in the admin console. However, if you modify the realm using the admin console, those changes have no effect on the custom resource."
msgstr ""

msgid "Begin using the Operator by xref:_installing-operator[Installing the {project_operator} on a cluster]."
msgstr ""

msgid "Installing the {project_operator} on a cluster"
msgstr ""

msgid "To install the {project_operator}, you can use:"
msgstr ""

msgid "xref:_install_by_olm[The Operator Lifecycle Manager (OLM)]"
msgstr ""

msgid "xref:_install_by_command[Command line installation]"
msgstr ""

msgid "Installing using the Operator Lifecycle Manager"
msgstr ""

msgid "You can install the Operator on an xref:_openshift-olm[OpenShift] or xref:_kubernetes-olm[Kubernetes] cluster."
msgstr ""

msgid "Installation on an OpenShift cluster"
msgstr ""

msgid "You have cluster-admin permission or an equivalent level of permissions granted by an administrator."
msgstr ""

msgid "Perform this procedure on an OpenShift cluster."
msgstr ""

msgid "Open the OpenShift Container Platform web console."
msgstr ""

msgid "In the left column, click `Operators, OperatorHub`."
msgstr ""

msgid "Search for {project_name} Operator."
msgstr ""

msgid "OperatorHub tab in OpenShift"
msgstr ""

msgid "image:{project_images}/operator-openshift-operatorhub.png[]"
msgstr ""

msgid "Click the {project_name} Operator icon."
msgstr ""

msgid "An Install page opens."
msgstr ""

msgid "Operator Install page on OpenShift"
msgstr ""

msgid "image:{project_images}/operator-olm-installation.png[]"
msgstr ""

msgid "Click `Install`."
msgstr ""

msgid "Select a namespace and click Subscribe."
msgstr ""

msgid "Namespace selection in OpenShift"
msgstr ""

msgid "image:images/installed-namespace.png[]"
msgstr ""

msgid "The Operator starts installing."
msgstr ""

msgid "When the Operator installation completes, you are ready to create your first custom resource. See xref:_keycloak_cr[{project_name} installation using a custom resource]. However, if you want to start tracking all Operator activities before creating custom resources, see the xref:_monitoring-operator[Application Monitoring Operator]."
msgstr ""

msgid "For more information on OpenShift Operators, see the link:https://docs.openshift.com/container-platform/4.4/operators/olm-what-operators-are.html[OpenShift Operators guide]."
msgstr ""

msgid "Installation on a Kubernetes cluster"
msgstr ""

msgid "For a Kubernetes cluster, perform these steps."
msgstr ""

msgid "Go to link:https://operatorhub.io/operator/keycloak-operator[Keycloak Operator on OperatorHub.io]."
msgstr ""

msgid "Follow the instructions on the screen."
msgstr ""

msgid "Operator Install page on Kubernetes"
msgstr ""

msgid "image:{project_images}/operator-operatorhub-install.png[]"
msgstr ""

msgid "For more information on a Kubernetes installation, see link:https://operatorhub.io/how-to-install-an-operator[How to install an Operator from OperatorHub.io]."
msgstr ""

msgid "Installing from the command line"
msgstr ""

msgid "You can install the {project_operator} from the command line."
msgstr ""

msgid "Obtain the software to install from this location: link:{operatorRepo_link}[Github repo]."
msgstr ""

msgid "Install all required custom resource definitions:"
msgstr ""

msgid "$ {create_cmd} -f deploy/crds/"
msgstr ""

msgid "Create a new namespace (or reuse an existing one) such as the namespace `myproject`:"
msgstr ""

msgid "$ {create_cmd_brief} create namespace myproject"
msgstr ""

msgid "Deploy a role, role binding, and service account for the Operator:"
msgstr ""

msgid ""
"$ {create_cmd} -f deploy/role.yaml -n myproject\n"
"$ {create_cmd} -f deploy/role_binding.yaml -n myproject\n"
"$ {create_cmd} -f deploy/service_account.yaml -n myproject"
msgstr ""

msgid "Deploy the Operator:"
msgstr ""

msgid "$ {create_cmd} -f deploy/operator.yaml -n myproject"
msgstr ""

msgid "Confirm that the Operator is running:"
msgstr ""

msgid ""
"$ {create_cmd_brief} get deployment keycloak-operator -n myproject\n"
"NAME                READY   UP-TO-DATE   AVAILABLE   AGE\n"
"keycloak-operator   1/1     1            1           41s"
msgstr ""

msgid "Using the {project_operator} in production environment"
msgstr ""

msgid "The usage of embedded DB is not supported in a production environment."
msgstr ""

msgid "Backup CRD is deprecated and not supported in a production environment."
msgstr ""

msgid "We fully support using the rest of the CRDs in production, despite the `v1alpha1` version. We do not plan to make any breaking changes in this CRDs version."
msgstr ""

msgid "The {application_monitoring_operator}"
msgstr ""

msgid "Before using the Operator to install {project_name} or create components, we recommend that you install the {application_monitoring_operator}, which tracks Operator activity. To view metrics for the Operator, you can use the Grafana Dashboard and Prometheus Alerts from the {application_monitoring_operator}. For example, you can view metrics such as the number of controller runtime reconciliation loops, the reconcile loop time, and errors."
msgstr ""

msgid "The {project_operator} integration with the {application_monitoring_operator} requires no action. You only need to install the {application_monitoring_operator} in the cluster."
msgstr ""

msgid "Installing the {application_monitoring_operator}"
msgstr ""

msgid "The {project_operator} is installed."
msgstr ""

msgid "Install the {application_monitoring_operator} by using the link:{application_monitoring_operator_installation_link}[documentation]."
msgstr ""

msgid "Annotate the namespace used for the {project_operator} installation. For example:"
msgstr ""

msgid "{create_cmd_brief} label namespace <namespace> monitoring-key=middleware"
msgstr ""

msgid "Log into the OpenShift web console."
msgstr ""

msgid "Confirm monitoring is working by searching for Prometheus and Grafana route in the `application-monitoring` namespace."
msgstr ""

msgid "Routes in OpenShift web console"
msgstr ""

msgid "image:{project_images}/operator-application-monitoring-routes.png[]"
msgstr ""

msgid "Viewing Operator Metrics"
msgstr ""

msgid "Grafana and Promotheus each provide graphical information about Operator activities."
msgstr ""

msgid "The Operator installs a pre-defined Grafana Dashboard as shown here:"
msgstr ""

msgid "Grafana Dashboard"
msgstr ""

msgid "image:{project_images}/operator-graphana-dashboard.png[]"
msgstr ""

msgid "If you make customizations, we recommend that you clone the Grafana Dashboard so that your changes are not overwritten during an upgrade."
msgstr ""

msgid "The Operator installs a set of pre-defined Prometheus Alerts as shown here:"
msgstr ""

msgid "Prometheus Alerts"
msgstr ""

msgid "image:{project_images}/operator-prometheus-alerts.png[]"
msgstr ""

msgid "For more information, see link:https://docs.openshift.com/container-platform/latest/monitoring/cluster_monitoring/prometheus-alertmanager-and-grafana.html[Accessing Prometheus, Alertmanager, and Grafana]."
msgstr ""

msgid "Installing {project_name} using a custom resource"
msgstr ""

msgid "You can use the Operator to automate the installation of {project_name} by creating a Keycloak custom resource. When you use a custom resource to install {project_name}, you create the components and services that are described here and illustrated in the graphic that follows."
msgstr ""

msgid "`keycloak-db-secret` - Stores properties such as the database username, password, and external address (if you connect to an external database)"
msgstr ""

msgid "`credentials-<CR-Name>` - Admin username and password to log into the {project_name} admin console (the `<CR-Name>` is based on the `Keycloak` custom resource name)"
msgstr ""

msgid "`keycloak` - Keycloak deployment specification that is implemented as a StatefulSet with high availability support"
msgstr ""

msgid "`keycloak-postgresql` - Starts a PostgreSQL database installation"
msgstr ""

msgid "`keycloak-discovery` Service - Performs `JDBC_PING` discovery"
msgstr ""

msgid "`keycloak` Service - Connects to {project_name} through HTTPS (HTTP is not supported)"
msgstr ""

msgid "`keycloak-postgresql` Service - Connects an internal and external, if used, database instance"
msgstr ""

msgid "`keycloak` Route - The URL for accessing the {project_name} admin console from OpenShift"
msgstr ""

msgid "`keycloak` Ingress - The URL for accessing the {project_name} admin console from Kubernetes"
msgstr ""

msgid "How Operator components and services interact"
msgstr ""

msgid "image:{project_images}/operator-components.png[]"
msgstr ""

msgid "The Keycloak custom resource"
msgstr ""

msgid "The Keycloak custom resource is a YAML file that defines the parameters for installation.  This file contains three properties."
msgstr ""

msgid "`instances` - controls the number of instances running in high availability mode."
msgstr ""

msgid "`externalAccess` - if the `enabled` is `True`, the Operator creates a route for OpenShift or an Ingress for Kubernetes for the {project_name} cluster. You can set `host` to override the automatically chosen host name for Route or default value `keycloak.local` set for Ingress."
msgstr ""

msgid "`externalDatabase` - in order to connect to an externally hosted database. That topic is covered in the xref:_external_database[external database] section of this guide. Setting it to false should be used only for testing purposes and will install an embedded PostgreSQL database. Be aware that externalDatabase:false is *NOT* supported in production environments."
msgstr ""

msgid "Example YAML file for a Keycloak custom resource"
msgstr ""

msgid ""
"apiVersion: keycloak.org/v1alpha1\n"
"kind: Keycloak\n"
"metadata:\n"
"  name: example-keycloak\n"
"  labels:\n"
"   app: example-keycloak\n"
"spec:\n"
"  instances: 1\n"
"  externalAccess:\n"
"    enabled: True"
msgstr ""

msgid "You can update the YAML file and the changes appear in the {project_name} admin console, however changes to the admin console do not update the custom resource."
msgstr ""

msgid "Creating a Keycloak custom resource on OpenShift"
msgstr ""

msgid "On OpenShift, you use the custom resource to create a route, which is the URL of the admin console, and find the secret, which holds the username and password for the admin console."
msgstr ""

msgid "You have a YAML file for this custom resource."
msgstr ""

msgid "If you want to start tracking all Operator activities now, install the monitoring application before you create this custom resource. See xref:_monitoring-operator[The Application Monitoring Operator]."
msgstr ""

msgid "Create a route using your YAML file: `{create_cmd} -f <filename>.yaml -n <namespace>`. For example:"
msgstr ""

msgid ""
"$ {create_cmd} -f keycloak.yaml -n keycloak\n"
"keycloak.keycloak.org/example-keycloak created"
msgstr ""

msgid "A route is created in OpenShift."
msgstr ""

msgid "Select `Networking`, `Routes` and search for Keycloak."
msgstr ""

msgid "Routes screen in OpenShift web console"
msgstr ""

msgid "image:images/route-ocp.png[]"
msgstr ""

msgid "On the screen with the Keycloak route, click the URL under `Location`."
msgstr ""

msgid "The {project_name} admin console login screen appears."
msgstr ""

msgid "Admin console login screen"
msgstr ""

msgid "image:images/login-empty.png[]"
msgstr ""

msgid "Locate the username and password for the admin console in the OpenShift web console; under `Workloads`, click `Secrets` and search for Keycloak."
msgstr ""

msgid "Secrets screen in OpenShift web console"
msgstr ""

msgid "image:images/secrets-ocp.png[]"
msgstr ""

msgid "Enter the username and password into the admin console login screen."
msgstr ""

msgid "image:images/login-complete.png[]"
msgstr ""

msgid "You are now logged into an instance of {project_name} that was installed by a Keycloak custom resource. You are ready to create custom resources for realms, clients, and users."
msgstr ""

msgid "{project_name} master realm"
msgstr ""

msgid "image:images/new_install_cr.png[]"
msgstr ""

msgid "Check the status of the custom resource:"
msgstr ""

msgid "$ {create_cmd_brief} describe keycloak <CR-name>"
msgstr ""

msgid "Creating a Keycloak custom resource on Kubernetes"
msgstr ""

msgid "On Kubernetes, you use the custom resource to create an ingress, which is the IP address of the admin console, and find the secret, which holds the username and password for that console."
msgstr ""

msgid "Create the ingress using your YAML file. `{create_cmd} -f <filename>.yaml -n <namespace>`.  For example:"
msgstr ""

msgid "Find the ingress: `{create_cmd_brief} get ingress -n <CR-name>`. For example:"
msgstr ""

msgid ""
"$ {create_cmd_brief} get ingress -n example-keycloak\n"
"NAME       HOSTS                 ADDRESS     PORTS   AGE\n"
"keycloak   keycloak.redhat.com   192.0.2.0   80      3m"
msgstr ""

msgid "Copy and paste the ADDRESS (the ingress) into a web browser."
msgstr ""

msgid "Locate the username and password."
msgstr ""

msgid "$ {create_cmd_brief} get secret credential-<CR-Name> -o go-template='{{range $k,$v := .data}}{{printf \"%s: \" $k}}{{if not $v}}{{$v}}{{else}}{{$v | base64decode}}{{end}}{{\"\\n\"}}{{end}}'"
msgstr ""

msgid "Enter the username and password in the admin console login screen."
msgstr ""

msgid "You are now logged into an instance of {project_name} that was installed by a Keycloak custom resource.  You are ready to create custom resources for realms, clients, and users."
msgstr ""

msgid "Admin console master realm"
msgstr ""

msgid "Results"
msgstr ""

msgid "After the Operator processes the custom resource, view the status with this command:"
msgstr ""

msgid "Keycloak custom resource Status"
msgstr ""

msgid ""
"Name:         example-keycloak\n"
"Namespace:    keycloak\n"
"Labels:       app=example-keycloak\n"
"Annotations:  <none>\n"
"API Version:  keycloak.org/v1alpha1\n"
"Kind:         Keycloak\n"
"Spec:\n"
"  External Access:\n"
"    Enabled:  true\n"
"  Instances:  1\n"
"Status:\n"
"  Credential Secret:  credential-example-keycloak\n"
"  Internal URL:       https://<External URL to the deployed instance>\n"
"  Message:\n"
"  Phase:              reconciling\n"
"  Ready:              true\n"
"  Secondary Resources:\n"
"    Deployment:\n"
"      keycloak-postgresql\n"
"    Persistent Volume Claim:\n"
"      keycloak-postgresql-claim\n"
"    Prometheus Rule:\n"
"      keycloak\n"
"    Route:\n"
"      keycloak\n"
"    Secret:\n"
"      credential-example-keycloak\n"
"      keycloak-db-secret\n"
"    Service:\n"
"      keycloak-postgresql\n"
"      keycloak\n"
"      keycloak-discovery\n"
"    Service Monitor:\n"
"      keycloak\n"
"    Stateful Set:\n"
"      keycloak\n"
"  Version:\n"
"Events:"
msgstr ""

msgid "Once the installation of {project_name} completes, you are ready to xref:_realm-cr[create a realm custom resource]."
msgstr ""

msgid "An external database is the supported option and needs to be enabled in the Keycloak custom resource. You can disable this option only for testing and enable it when you switch to a production environment. See xref:_external_database[Connecting to an external database]."
msgstr ""

msgid "Creating a realm custom resource"
msgstr ""

msgid "You can use the Operator to create realms in {project_name} as defined by a custom resource. You define the properties of the realm custom resource in a YAML file."
msgstr ""

msgid "You can update the YAML file and changes appear in the {project_name} admin console, however changes to the admin console do not update the custom resource."
msgstr ""

msgid "Example YAML file for a `Realm` custom resource"
msgstr ""

msgid ""
"apiVersion: keycloak.org/v1alpha1\n"
"kind: KeycloakRealm\n"
"metadata:\n"
"  name: test\n"
"  labels:\n"
"    app: example-keycloak\n"
"spec:\n"
"  realm:\n"
"    id: \"basic\"\n"
"    realm: \"basic\"\n"
"    enabled: True\n"
"    displayName: \"Basic Realm\"\n"
"  instanceSelector:\n"
"    matchLabels:\n"
"      app: example-keycloak\n"
msgstr ""

msgid "In the YAML file,  the `app` under `instanceSelector` matches the label of a Keycloak custom resource. Matching these values ensures that you create the realm in the right instance of {project_name}."
msgstr ""

msgid "Use this command on the YAML file that you created: `{create_cmd} -f <realm-name>.yaml`. For example:"
msgstr ""

msgid ""
"$ {create_cmd} -f initial_realm.yaml\n"
"keycloak.keycloak.org/test created"
msgstr ""

msgid "Log into the admin console for the related instance of {project_name}."
msgstr ""

msgid "Click Select Realm and locate the realm that you created."
msgstr ""

msgid "The new realm opens."
msgstr ""

msgid "image:images/test-realm-cr.png[]"
msgstr ""

msgid "Realm custom resource status"
msgstr ""

msgid ""
"Name:         example-keycloakrealm\n"
"Namespace:    keycloak\n"
"Labels:       app=example-keycloak\n"
"Annotations:  <none>\n"
"API Version:  keycloak.org/v1alpha1\n"
"Kind:         KeycloakRealm\n"
"Metadata:\n"
"  Creation Timestamp:  2019-12-03T09:46:02Z\n"
"  Finalizers:\n"
"    realm.cleanup\n"
"  Generation:        1\n"
"  Resource Version:  804596\n"
"  Self Link:         /apis/keycloak.org/v1alpha1/namespaces/keycloak/keycloakrealms/example-keycloakrealm\n"
"  UID:               b7b2f883-15b1-11ea-91e6-02cb885627a6\n"
"Spec:\n"
"  Instance Selector:\n"
"    Match Labels:\n"
"      App: example-keycloak\n"
"  Realm:\n"
"    Display Name:  Basic Realm\n"
"    Enabled:       true\n"
"    Id:            basic\n"
"    Realm:         basic\n"
"Status:\n"
"  Login URL:\n"
"  Message:\n"
"  Phase:      reconciling\n"
"  Ready:      true\n"
"Events:       <none>\n"
msgstr ""

msgid "When the realm creation completes, you are ready to xref:_client-cr[create a client custom resource]."
msgstr ""

msgid "Creating a client custom resource"
msgstr ""

msgid "You can use the Operator to create clients in {project_name} as defined by a custom resource.  You define the properties of the realm in a YAML file."
msgstr ""

msgid "Example YAML file for a Client custom resource"
msgstr ""

msgid ""
"apiVersion: keycloak.org/v1alpha1\n"
"kind: KeycloakClient\n"
"metadata:\n"
"  name: example-client\n"
"  labels:\n"
"    app: app=example-keycloak\n"
"spec:\n"
"  realmSelector:\n"
"     matchLabels:\n"
"      app: <matching labels for KeycloakRealm custom resource>\n"
"  client:\n"
"    # auto-generated if not supplied\n"
"    #id: 123\n"
"    clientId: client-secret\n"
"    secret: client-secret\n"
"    # ...\n"
"    # other properties of Keycloak Client"
msgstr ""

msgid "Use this command on the YAML file that you created: `{create_cmd} -f <client-name>.yaml`. For example:"
msgstr ""

msgid ""
"$ {create_cmd} -f initial_client.yaml\n"
"keycloak.keycloak.org/example-client created"
msgstr ""

msgid "Log into the {project_name} admin console for the related instance of {project_name}."
msgstr ""

msgid "Click Clients."
msgstr ""

msgid "The new client appears in the list of clients."
msgstr ""

msgid "image:images/clients.png[]"
msgstr ""

msgid "After a client is created, the Operator creates a Secret containing the `Client ID` and the client's secret using the following naming pattern: `keycloak-client-secret-<custom resource name>`. For example:"
msgstr ""

msgid "Client's Secret"
msgstr ""

msgid ""
"apiVersion: v1\n"
"data:\n"
"  CLIENT_ID: <base64 encoded Client ID>\n"
"  CLIENT_SECRET: <base64 encoded Client Secret>\n"
"kind: Secret"
msgstr ""

msgid "Client custom resource Status"
msgstr ""

msgid ""
"Name:         client-secret\n"
"Namespace:    keycloak\n"
"Labels:       app=example-keycloak\n"
"API Version:  keycloak.org/v1alpha1\n"
"Kind:         KeycloakClient\n"
"Spec:\n"
"  Client:\n"
"    Client Authenticator Type:     client-secret\n"
"    Client Id:                     client-secret\n"
"    Id:                            keycloak-client-secret\n"
"  Realm Selector:\n"
"    Match Labels:\n"
"      App:  keycloak\n"
"Status:\n"
"  Message:\n"
"  Phase:    reconciling\n"
"  Ready:    true\n"
"  Secondary Resources:\n"
"    Secret:\n"
"      keycloak-client-secret-client-secret\n"
"Events:  <none>"
msgstr ""

msgid "When the client creation completes, you are ready to xref:_user-cr[create a user custom resource]."
msgstr ""

msgid "Creating a user custom resource"
msgstr ""

msgid "You can use the Operator to create users in {project_name} as defined by a custom resource. You define the properties of the user custom resource in a YAML file."
msgstr ""

msgid "You can update properties, except for the password, in the YAML file and changes appear in the {project_name} admin console, however changes to the admin console do not update the custom resource."
msgstr ""

msgid "Example YAML file for a user custom resource"
msgstr ""

msgid ""
"apiVersion: keycloak.org/v1alpha1\n"
"kind: KeycloakUser\n"
"metadata:\n"
"  name: example-user\n"
"spec:\n"
"  user:\n"
"    username: \"realm_user\"\n"
"    firstName: \"John\"\n"
"    lastName: \"Doe\"\n"
"    email: \"user@example.com\"\n"
"    enabled: True\n"
"    emailVerified: False\n"
"    credentials:\n"
"      - type: \"password\"\n"
"        value: \"12345\"\n"
"    realmRoles:\n"
"      - \"offline_access\"\n"
"    clientRoles:\n"
"      account:\n"
"        - \"manage-account\"\n"
"      realm-management:\n"
"        - \"manage-users\"\n"
"  realmSelector:\n"
"    matchLabels:\n"
"      app: example-keycloak"
msgstr ""

msgid "The `realmSelector` matches the labels of an existing realm custom resource."
msgstr ""

msgid "Use this command on the YAML file that you created: `{create_cmd} -f <user_cr>.yaml`. For example:"
msgstr ""

msgid ""
"$ {create_cmd} -f initial_user.yaml\n"
"keycloak.keycloak.org/example-user created"
msgstr ""

msgid "Click Users."
msgstr ""

msgid "Search for the user that you defined in the YAML file."
msgstr ""

msgid "You may need to switch to a different realm to find the user."
msgstr ""

msgid "image:images/realm_user.png[]"
msgstr ""

msgid "After a user is created, the Operator creates a Secret using the following naming pattern: `credential-<realm name>-<username>-<namespace>`, containing the username and, if it has been specified in the CR `credentials` attribute, the password."
msgstr ""

msgid "Here's an example:"
msgstr ""

msgid "`KeycloakUser` Secret"
msgstr ""

msgid ""
"kind: Secret\n"
"apiVersion: v1\n"
"data:\n"
"  password: <base64 encoded password>\n"
"  username: <base64 encoded username>\n"
"type: Opaque"
msgstr ""

msgid "Once the Operator processes the custom resource, view the status with this command:"
msgstr ""

msgid "User custom resource Status"
msgstr ""

msgid ""
"Name:         example-realm-user\n"
"Namespace:    keycloak\n"
"Labels:       app=example-keycloak\n"
"API Version:  keycloak.org/v1alpha1\n"
"Kind:         KeycloakUser\n"
"Spec:\n"
"  Realm Selector:\n"
"    Match Labels:\n"
"      App: example-keycloak\n"
"  User:\n"
"    Email:           realm_user@redhat.com\n"
"    Credentials:\n"
"      Type:          password\n"
"      Value:         <user password>\n"
"    Email Verified:  false\n"
"    Enabled:         true\n"
"    First Name:      John\n"
"    Last Name:       Doe\n"
"    Username:        realm_user\n"
"Status:\n"
"  Message:\n"
"  Phase:    reconciled\n"
"Events:     <none>"
msgstr ""

msgid "If you have an external database, you can modify the Keycloak custom resource to support it. See xref:_external_database[Connecting to an external database]."
msgstr ""

msgid "To back up your database using custom resources, see xref:_backup-cr[schedule database backups]."
msgstr ""

msgid "Connecting to an external database"
msgstr ""

msgid "You can use the Operator to connect to an external PostgreSQL database by creating a `keycloak-db-secret` YAML file and setting Keycloak CR externalDatabase property to enabled. Note that values are Base64 encoded."
msgstr ""

msgid "Example YAML file for `keycloak-db-secret`"
msgstr ""

msgid ""
"apiVersion: v1\n"
"kind: Secret\n"
"metadata:\n"
"    name: keycloak-db-secret\n"
"    namespace: keycloak\n"
"stringData:\n"
"    POSTGRES_DATABASE: <Database Name>\n"
"    POSTGRES_EXTERNAL_ADDRESS: <External Database IP or URL (resolvable by K8s)>\n"
"    POSTGRES_EXTERNAL_PORT: <External Database Port>\n"
"    POSTGRES_PASSWORD: <Database Password>\n"
"    # Required for AWS Backup functionality\n"
"    POSTGRES_SUPERUSER: \"true\"\n"
"    POSTGRES_USERNAME: <Database Username>\n"
"    SSLMODE: <TLS configuration for the Database connection>\n"
"type: Opaque"
msgstr ""

msgid "The following properties set the hostname or IP address and port of the database."
msgstr ""

msgid "`POSTGRES_EXTERNAL_ADDRESS` - an IP address or a hostname of the external database. This address needs be resolvable in a Kubernetes cluster."
msgstr ""

msgid "`POSTGRES_EXTERNAL_PORT` - (Optional) A database port."
msgstr ""

msgid "The other properties work in the same way for a hosted or external database. Set them as follows:"
msgstr ""

msgid "`POSTGRES_DATABASE` - Database name to be used."
msgstr ""

msgid "`POSTGRES_USERNAME` - Database username"
msgstr ""

msgid "`POSTGRES_PASSWORD` - Database password"
msgstr ""

msgid "`POSTGRES_SUPERUSER` - Indicates whether backups should run as super user. Typically `true`."
msgstr ""

msgid "`SSL_MODE` - Indicates whether to use TLS on the connection to the external PostgreSQL database. Check the possible https://www.postgresql.org/docs/current/libpq-ssl.html[values]"
msgstr ""

msgid "When `SSL_MODE` is enabled, the operator searches for a secret called `keycloak-db-ssl-cert-secret` containing the `root.crt` that has been used by the PostgreSQL database. Creating the secret is optional and the secret is used only when you want to verify the Database's certificate (for example `SSLMODE: verify-ca`). Here is an example :"
msgstr ""

msgid "Example YAML file for `TLS Secret` to be used by the operator."
msgstr ""

msgid ""
"apiVersion: v1\n"
"kind: Secret\n"
"metadata:\n"
"  name: keycloak-db-ssl-cert-secret\n"
"  namespace: keycloak\n"
"type: Opaque\n"
"data:\n"
"  root.crt: {root.crt base64}"
msgstr ""

msgid "The Operator will create a Service named `keycloak-postgresql`. This Service is configured by the Operator to expose the external database based on the content of `POSTGRES_EXTERNAL_ADDRESS`. {project_name} uses this Service to connect to the Database, which means it does not connect to the Database directly but rather through this Service."
msgstr ""

msgid "The Keycloak custom resource requires updates to enable external database support."
msgstr ""

msgid "Example YAML file for `Keycloak` custom resource that supports an external database"
msgstr ""

msgid ""
"apiVersion: keycloak.org/v1alpha1\n"
"kind: Keycloak\n"
"metadata:\n"
"  labels:\n"
"      app: example-keycloak\n"
"  name: example-keycloak\n"
"  namespace: keycloak\n"
"spec:\n"
"  externalDatabase:\n"
"    enabled: true\n"
"  instances: 1"
msgstr ""

msgid "You have a YAML file for `keycloak-db-secret`."
msgstr ""

msgid "You have modified the Keycloak custom resource to set `externalDatabase` to `true`."
msgstr ""

msgid "Locate the secret for your PostgreSQL database: `{create_cmd_brief} get secret <secret_for_db> -o yaml`. For example:"
msgstr ""

msgid ""
"$ {create_cmd_brief} get secret keycloak-db-secret -o yaml\n"
"apiVersion: v1\n"
"data\n"
"  POSTGRES_DATABASE: cm9vdA==\n"
"  POSTGRES_EXTERNAL_ADDRESS: MTcyLjE3LjAuMw==\n"
"  POSTGRES_EXTERNAL_PORT: NTQzMg=="
msgstr ""

msgid "The `POSTGRES_EXTERNAL_ADDRESS` is in Base64 format."
msgstr ""

msgid "Decode the value for the secret: `echo \"<encoded_secret>\" | base64 -decode`. For example:"
msgstr ""

msgid ""
"$ echo \"MTcyLjE3LjAuMw==\" | base64 -decode\n"
"192.0.2.3"
msgstr ""

msgid "Confirm that the decoded value matches the IP address for your database:"
msgstr ""

msgid ""
"$ {create_cmd_brief} get pods -o wide\n"
"NAME                        READY  STATUS    RESTARTS   AGE   IP\n"
"keycloak-0                  1/1    Running   0          13m   192.0.2.0\n"
"keycloak-postgresql-c8vv27m 1/1    Running   0          24m   192.0.2.3"
msgstr ""

msgid "Confirm that `keycloak-postgresql` appears in a list of running services:"
msgstr ""

msgid ""
"$ {create_cmd_brief} get svc\n"
"NAME                 TYPE       CLUSTER-IP     EXTERNAL-IP  PORT(S)   AGE\n"
"keycloak             ClusterIP  203.0.113.0    <none>       8443/TCP  27m\n"
"keycloak-discovery   ClusterIP  None           <none>       8080/TCP  27m\n"
"keycloak-postgresql  ClusterIP  203.0.113.1    <none>       5432/TCP  27m"
msgstr ""

msgid "The `keycloak-postgresql` service sends requests to a set of IP addresses in the backend.  These IP addresses are called endpoints."
msgstr ""

msgid "View the endpoints used by the `keycloak-postgresql` service to confirm that they use the IP addresses for your database:"
msgstr ""

msgid ""
"$ {create_cmd_brief} get endpoints keycloak-postgresql\n"
"NAME                  ENDPOINTS         AGE\n"
"keycloak-postgresql   192.0.2.3.5432    27m"
msgstr ""

msgid "Confirm that {project_name} is running with the external database. This example shows that everything is running:"
msgstr ""

msgid ""
"$ {create_cmd_brief} get pods\n"
"NAME                        READY  STATUS    RESTARTS   AGE   IP\n"
"keycloak-0                  1/1    Running   0          26m   192.0.2.0\n"
"keycloak-postgresql-c8vv27m 1/1    Running   0          36m   192.0.2.3"
msgstr ""

msgid "Additional Resources"
msgstr ""

msgid "To back up your database using custom resources, see xref:_backup-cr[Scheduling database backups]."
msgstr ""

msgid "For more information on Base64 encoding, see the https://kubernetes.io/docs/concepts/configuration/secret/[Kubernetes Secrets manual]."
msgstr ""

msgid "Connecting to an external {project_name}"
msgstr ""

msgid "This operator can also be used to partially manage an external {project_name} instance. In it's current state, it will only be able to create clients."
msgstr ""

msgid "To do this, you'll need to create unmanaged versions of the `Keycloak` and `KeycloakRealm` CRDs to use for targeting and configuration."
msgstr ""

msgid "Example YAML file for `external-keycloak`"
msgstr ""

msgid ""
"apiVersion: keycloak.org/v1alpha1\n"
"kind: Keycloak\n"
"metadata:\n"
"  name: external-ref\n"
"  labels:\n"
"    app: external-keycloak\n"
"spec:\n"
"  unmanaged: true\n"
"  external:\n"
"    enabled: true\n"
"    url: https://some.external.url"
msgstr ""

msgid "In order to authenticate against this keycloak, the operator infers the secret name from the CRD by prefixing the CRD name with `credential-`."
msgstr ""

msgid "Example YAML file for `credential-external-ref`"
msgstr ""

msgid ""
"apiVersion: v1\n"
"kind: Secret\n"
"metadata:\n"
"  name: credential-external-ref\n"
"type: Opaque\n"
"data:\n"
"  ADMIN_USERNAME: YWRtaW4=\n"
"  ADMIN_PASSWORD: cGFzcw=="
msgstr ""

msgid "Example YAML file for `external-realm`"
msgstr ""

msgid ""
"apiVersion: keycloak.org/v1alpha1\n"
"kind: KeycloakRealm\n"
"metadata:\n"
"  name: external-realm\n"
"  labels:\n"
"    app: external-keycloak\n"
"spec:\n"
"  unmanaged: true\n"
"  realm:\n"
"    id: \"basic\"\n"
"    realm: \"basic\"\n"
"  instanceSelector:\n"
"    matchLabels:\n"
"      app: external-keycloak"
msgstr ""

msgid "You can now use the realm reference in your client as usual, and it will create the client on the external {project_name} instance."
msgstr ""

msgid "Scheduling database backups"
msgstr ""

msgid "Backup CR is *deprecated* and could be removed in future releases."
msgstr ""

msgid "You can use the Operator to schedule automatic backups of the database as defined by custom resources. The custom resource triggers a backup job (or a `CronJob` in the case of Periodic Backups) and reports back its status."
msgstr ""

msgid "Two options exist to schedule backups:"
msgstr ""

msgid "xref:_backups-cr-aws[Backing up to AWS S3 storage]"
msgstr ""

msgid "xref:_backups-local-cr[Backing up to local storage]"
msgstr ""

msgid "If you have AWS S3 storage, you can perform a one-time backup or periodic backups. If you do not have AWS S3 storage, you can back up to local storage."
msgstr ""

msgid "Backing up to AWS S3 storage"
msgstr ""

msgid "You can back up your database to AWS S3 storage one time or periodically. To back up your data periodically, enter a valid `CronJob` into the `schedule`."
msgstr ""

msgid "For AWS S3 storage, you create a YAML file for the backup custom resource and a YAML file for the AWS secret. The backup custom resource requires a YAML file with the following structure:"
msgstr ""

msgid ""
"apiVersion: keycloak.org/v1alpha1\n"
"kind: KeycloakBackup\n"
"metadata:\n"
"  name: <CR Name>\n"
"spec:\n"
"  aws:\n"
"    # Optional - used only for Periodic Backups.\n"
"    # Follows usual crond syntax (for example, use \"0 1 * * *\" to perform the backup every day at 1 AM.)\n"
"    schedule: <Cron Job Schedule>\n"
"    # Required - the name of the secret containing the credentials to access the S3 storage\n"
"    credentialsSecretName: <A Secret containing S3 credentials>"
msgstr ""

msgid "The AWS secret requires a YAML file with the following structure:"
msgstr ""

msgid "AWS S3 `Secret`"
msgstr ""

msgid ""
"apiVersion: v1\n"
"kind: Secret\n"
"metadata:\n"
"  name: <Secret Name>\n"
"type: Opaque\n"
"stringData:\n"
"  AWS_S3_BUCKET_NAME: <S3 Bucket Name>\n"
"  AWS_ACCESS_KEY_ID: <AWS Access Key ID>\n"
"  AWS_SECRET_ACCESS_KEY: <AWS Secret Key>"
msgstr ""

msgid "Your Backup custom resource YAML file includes a `credentialsSecretName` that references a `Secret` containing AWS S3 credentials."
msgstr ""

msgid "Your `KeycloakBackup` custom resource has `aws` sub-properties."
msgstr ""

msgid "You have a YAML file for the AWS S3 Secret that includes a `<Secret Name>` that matches the one identified in the backup custom resource."
msgstr ""

msgid "Create the secret with credentials: `{create_cmd} -f <secret_for_aws>.yaml`. For example:"
msgstr ""

msgid ""
"$ {create_cmd} -f secret.yaml\n"
"keycloak.keycloak.org/aws_s3_secret created"
msgstr ""

msgid "Create a backup job: `{create_cmd} -f <backup_crname>.yaml`. For example:"
msgstr ""

msgid ""
"$ {create_cmd} -f aws_one-time-backup.yaml\n"
"keycloak.keycloak.org/aws_s3_backup created"
msgstr ""

msgid "View a list of backup jobs:"
msgstr ""

msgid ""
"$ {create_cmd_brief} get jobs\n"
"NAME                   COMPLETIONS     DURATION     AGE\n"
"aws_s3_backup    0/1             6s           6s"
msgstr ""

msgid "View the list of executed backup jobs."
msgstr ""

msgid ""
"$ {create_cmd_brief} get pods\n"
"NAME                               READY    STATUS       RESTARTS    AGE\n"
"aws_s3_backup-5b4rfdd              0/1      Completed    0           24s\n"
"keycloak-0                         1/1      Running      0           52m\n"
"keycloak-postgresql-c824c6-vv27m   1/1      Running      0           71m"
msgstr ""

msgid "View the log of your completed backup job:"
msgstr ""

msgid ""
"$ {create_cmd_brief} logs aws_s3_backup-5b4rf\n"
"==> Component data dump completed\n"
".\n"
".\n"
".\n"
".\n"
"[source,bash,subs=+attributes]"
msgstr ""

msgid "The status of the backup job also appears in the AWS console."
msgstr ""

msgid "Backing up to Local Storage"
msgstr ""

msgid "You can use Operator to create a backup job that performs a one-time backup to a local Persistent Volume."
msgstr ""

msgid "Example YAML file for a Backup custom resource"
msgstr ""

msgid ""
"apiVersion: keycloak.org/v1alpha1\n"
"kind: KeycloakBackup\n"
"metadata:\n"
"  name: test-backup"
msgstr ""

msgid "You have a YAML file for this custom resource. Be sure to omit the `aws` sub-properties from this file."
msgstr ""

msgid "You have a `PersistentVolume` with a `claimRef` to reserve it only for a `PersistentVolumeClaim` created by the {project_name} Operator."
msgstr ""

msgid "Create a backup job: `{create_cmd} -f <backup_crname>`. For example:"
msgstr ""

msgid ""
"$ {create_cmd} -f one-time-backup.yaml\n"
"keycloak.keycloak.org/test-backup"
msgstr ""

msgid "The Operator creates a `PersistentVolumeClaim` with the following naming scheme:  `Keycloak-backup-<CR-name>`."
msgstr ""

msgid "View a list of volumes:"
msgstr ""

msgid ""
"$ {create_cmd_brief} get pvc\n"
"NAME                          STATUS   VOLUME\n"
"keycloak-backup-test-backup   Bound    pvc-e242-ew022d5-093q-3134n-41-adff\n"
"keycloak-postresql-claim      Bound    pvc-e242-vs29202-9bcd7-093q-31-zadj"
msgstr ""

msgid ""
"$ {create_cmd_brief} get jobs\n"
"NAME           COMPLETIONS     DURATION     AGE\n"
"test-backup    0/1             6s           6s"
msgstr ""

msgid "View the list of executed backup jobs:"
msgstr ""

msgid ""
"$ {create_cmd_brief} get pods\n"
"NAME                               READY    STATUS       RESTARTS    AGE\n"
"test-backup-5b4rf                  0/1      Completed    0           24s\n"
"keycloak-0                         1/1      Running      0           52m\n"
"keycloak-postgresql-c824c6-vv27m   1/1      Running      0           71m"
msgstr ""

msgid ""
"$ {create_cmd_brief} logs test-backup-5b4rf\n"
"==> Component data dump completed\n"
".\n"
".\n"
".\n"
"."
msgstr ""

msgid "For more details on persistent volumes, see link:https://docs.openshift.com/container-platform/4.4/storage/understanding-persistent-storage.html[Understanding persistent storage]."
msgstr ""

msgid "Installing extensions and themes"
msgstr ""

msgid "You can use the operator to install extensions and themes that you need for your company or organization. The extension or theme can be anything that {project_name} can consume. For example, you can add a metrics extension. You add the extension or theme to the Keycloak custom resource."
msgstr ""

msgid ""
"apiVersion: keycloak.org/v1alpha1\n"
"kind: Keycloak\n"
"metadata:\n"
"  name: example-keycloak\n"
"  labels:\n"
"   app: keycloak\n"
"spec:\n"
"  instances: 1\n"
"  extensions:\n"
"   - <url_for_extension_or_theme>\n"
"  externalAccess:\n"
"    enabled: True"
msgstr ""

msgid "You can package and deploy themes in the same way as any other extensions. See {developerguide_deploying_themes}[Deploying Themes] manual entry for more information."
msgstr ""

msgid "You have a YAML file for the Keycloak custom resource."
msgstr ""

msgid "Edit the YAML file for the Keycloak custom resource: `{create_cmd_brief} edit <CR-name>`"
msgstr ""

msgid "Add a line called `extensions:` after the `instances` line."
msgstr ""

msgid "Add a URL to a JAR file for your custom extension or theme."
msgstr ""

msgid "Save the file."
msgstr ""

msgid "The Operator downloads the extension or theme and installs it."
msgstr ""

msgid "Command options for managing custom resources"
msgstr ""

msgid "After you create a custom request, you can edit it or delete using the `{create_cmd_brief}` command."
msgstr ""

msgid "To edit a custom request, use this command: `{create_cmd_brief} edit <CR-name>`"
msgstr ""

msgid "To delete a custom request, use this command: `{create_cmd_brief} delete <CR-name>`"
msgstr ""

msgid "For example, to edit a realm custom request named `test-realm`, use this command:"
msgstr ""

msgid "$ {create_cmd_brief} edit test-realm"
msgstr ""

msgid "A window opens where you can make changes."
msgstr ""

msgid "Upgrade strategy"
msgstr ""

msgid "You can configure how the operator performs {project_name} upgrades. You can choose from the following upgrade strategies."
msgstr ""

msgid "`recreate`: This is the default strategy. The operator removes all {project_name} replicas, optionally creates a backup and then creates the replicas based on a newer {project_name} image. This strategy is suitable for major upgrades as a single {project_name} version is accessing the underlying database. The downside is {project_name} needs to be shut down during the upgrade."
msgstr ""

msgid "`rolling`: The operator removes one replica at a time and creates it again based on a newer {project_name} image. This ensures a zero-downtime upgrade but is more suitable for minor version upgrades that do not require database migration since the database is accessed by multiple {project_name} versions concurrently. Automatic backups are not supported with this strategy."
msgstr ""

msgid ""
"apiVersion: keycloak.org/v1alpha1\n"
"kind: Keycloak\n"
"metadata:\n"
"  name: example-keycloak\n"
"  labels:\n"
"   app: keycloak\n"
"spec:\n"
"  instances: 2\n"
"  migration:\n"
"    strategy: recreate\n"
"    backups:\n"
"      enabled: True\n"
"  externalAccess:\n"
"    enabled: True"
msgstr ""

msgid "For more information on rolling updates, see the https://kubernetes.io/docs/tutorials/stateful-application/basic-stateful-set/#rolling-update[Updating StatefulSets manual]."
msgstr ""
